### From Product:
```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="whitegrid")
df.plot(x='subcategory', y=['total_sales', 'total_profit', 'avg_discount'], kind='bar', figsize=(12,6))
plt.title("Performance by Subcategory")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

### From Product:
```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.scatterplot(data=df, x='avg_discount', y='total_profit', hue='subcategory', s=100)
plt.title("Discount vs Profit by Subcategory")
plt.xlabel("Average Discount")
plt.ylabel("Total Profit")
plt.grid(True)
plt.tight_layout()
plt.show()

```

### From Product:
```python
plt.figure(figsize=(10,6))
plt.scatter(df['total_sales'], df['total_profit'], s=df['avg_discount']*1000, alpha=0.5)

for i in range(len(df)):
    plt.text(df['total_sales'][i]+1000, df['total_profit'][i], df['subcategory'][i])

plt.xlabel('Total Sales')
plt.ylabel('Total Profit')
plt.title('Sales vs Profit (Bubble Size = Avg Discount)')
plt.tight_layout()
plt.show()

```

### From Product:
```python
import seaborn as sns

data = df.set_index('subcategory')[['total_sales', 'total_profit', 'avg_discount']]
sns.heatmap(data, annot=True, cmap='YlGnBu', fmt='.1f')
plt.title("Heatmap of Product Metrics by Subcategory")
plt.tight_layout()
plt.show()

```

### From Product:
```python
df_sorted = df.sort_values(by='total_profit', ascending=True)
df_sorted.plot.barh(x='subcategory', y='total_profit', color='skyblue', figsize=(10, 6))
plt.title('Total Profit by Subcategory')
plt.xlabel('Profit')
plt.tight_layout()
plt.show()

```

### From Sales:
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import io
import sys
warnings.filterwarnings('ignore')
```

### From Sales:
```python
# Capture print output
output_buffer = io.StringIO()
original_stdout = sys.stdout
sys.stdout = TeeOutput(original_stdout, output_buffer)

# Set visualization style
plt.style.use('default')
sns.set_palette("husl")

#def analyze_dataframe_quality(df):

print("="*80)
print("DATAFRAME QUALITY ANALYSIS REPORT")
print("="*80)

# Basic Info
print(f"\n📊 BASIC INFORMATION")
print(f"Shape: {df.shape}")
print(f"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
print(f"Data Types:")
print(df.dtypes.value_counts())

# 1. COMPLETENESS ANALYSIS
print(f"\n🔍 1. COMPLETENESS ANALYSIS")
print("-" * 50)

# Missing values (including empty strings)
missing_analysis = pd.DataFrame({
    'Column': df.columns,
    'Missing_Count': df.isnull().sum(),
    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,
    'Empty_Strings': df.apply(lambda x: (x == '').sum() if x.dtype == 'object' else 0),
    'Empty_String_Percentage': df.apply(lambda x: ((x == '').sum() / len(df)) * 100 if x.dtype == 'object' else 0)
})

missing_analysis['Total_Missing'] = missing_analysis['Missing_Count'] + missing_analysis['Empty_Strings']
missing_analysis['Total_Missing_Percentage'] = missing_analysis['Missing_Percentage'] + missing_analysis['Empty_String_Percentage']
missing_analysis = missing_analysis.sort_values('Total_Missing_Percentage', ascending=False)

print("Missing Values Analysis:")
print(missing_analysis[missing_analysis['Total_Missing'] > 0])

# Visualize missing data
if missing_analysis['Total_Missing'].sum() > 0:
    plt.figure(figsize=(12, 6))
    missing_cols = missing_analysis[missing_analysis['Total_Missing'] > 0]['Column']
    missing_values = missing_analysis[missing_analysis['Total_Missing'] > 0]['Total_Missing_Percentage']

    plt.subplot(1, 2, 1)
    plt.barh(missing_cols, missing_values)
    plt.xlabel('Missing Percentage (%)')
    plt.title('Missing Data by Column')

    plt.subplot(1, 2, 2)
    # Create a missing data heatmap for first 20 columns
    cols_to_show = df.columns[:20] if len(df.columns) > 20 else df.columns
    missing_matrix = df[cols_to_show].isnull()
    sns.heatmap(missing_matrix, yticklabels=False, cbar=True, cmap='viridis')
    plt.title('Missing Data Pattern (First 20 Columns)')
    plt.tight_layout()
    plt.show()

# 2. DUPLICATE RECORDS
print(f"\n🔄 2. DUPLICATE RECORDS ANALYSIS")
print("-" * 50)

duplicate_count = df.duplicated().sum()
duplicate_percentage = (duplicate_count / len(df)) * 100

print(f"Total duplicate rows: {duplicate_count}")
print(f"Duplicate percentage: {duplicate_percentage:.2f}%")

if duplicate_count > 0:
    print("\nFirst few duplicate rows:")
    print(df[df.duplicated()].head())

# 3. DATA CONSISTENCY & TYPES
print(f"\n📋 3. DATA CONSISTENCY & COLUMN TYPES")
print("-" * 50)

# Group columns by data type
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
boolean_cols = df.select_dtypes(include=['bool']).columns.tolist()

print(f"Numeric columns ({len(numeric_cols)}): {numeric_cols}")
print(f"Categorical columns ({len(categorical_cols)}): {categorical_cols}")
print(f"Datetime columns ({len(datetime_cols)}): {datetime_cols}")
print(f"Boolean columns ({len(boolean_cols)}): {boolean_cols}")

# Consistency checks for categorical columns
if categorical_cols:
    print(f"\nCategorical Data Consistency:")
    for col in categorical_cols[:10]:  # Show first 10 categorical columns
        unique_count = df[col].nunique()
        print(f"  {col}: {unique_count} unique values")
        if unique_count <= 10:
            print(f"    Values: {df[col].value_counts().head().to_dict()}")

# 4. OUTLIERS AND ANOMALIES
print(f"\n📈 4. OUTLIERS AND ANOMALIES")
print("-" * 50)

if numeric_cols:
    outlier_summary = []

    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outlier_count = len(outliers)
        outlier_percentage = (outlier_count / len(df)) * 100

        outlier_summary.append({
            'Column': col,
            'Outlier_Count': outlier_count,
            'Outlier_Percentage': outlier_percentage,
            'Lower_Bound': lower_bound,
            'Upper_Bound': upper_bound
        })

    outlier_df = pd.DataFrame(outlier_summary)
    print("Outlier Analysis (using IQR method):")
    print(outlier_df[outlier_df['Outlier_Count'] > 0])

# 5. DATA DISTRIBUTION AND SKEWNESS
print(f"\n📊 5. DATA DISTRIBUTION AND SKEWNESS")
print("-" * 50)

if numeric_cols:
    # Statistical summary
    print("Statistical Summary:")
    print(df[numeric_cols].describe())

    # Skewness analysis
    print(f"\nSkewness Analysis:")
    skewness_data = []
    for col in numeric_cols:
        skew_value = stats.skew(df[col].dropna())
        skewness_data.append({
            'Column': col,
            'Skewness': skew_value,
            'Interpretation': 'Highly Left' if skew_value < -1 else 'Moderately Left' if skew_value < -0.5 else 'Normal' if abs(skew_value) <= 0.5 else 'Moderately Right' if skew_value < 1 else 'Highly Right'
        })

    skewness_df = pd.DataFrame(skewness_data)
    print(skewness_df)

    # Visualizations
    n_numeric = len(numeric_cols)
    if n_numeric > 0:
        # Box plots
        fig, axes = plt.subplots(nrows=(n_numeric + 2) // 3, ncols=3, figsize=(15, 5 * ((n_numeric + 2) // 3)))
        if n_numeric == 1:
            axes = [axes]
        elif (n_numeric + 2) // 3 == 1:
            axes = [axes]
        else:
            axes = axes.flatten()

        for i, col in enumerate(numeric_cols):
            if i < len(axes):
                df[col].plot(kind='box', ax=axes[i], title=f'Box Plot: {col}')
                axes[i].set_ylabel('Values')

        # Hide empty subplots
        for i in range(len(numeric_cols), len(axes)):
            axes[i].set_visible(False)

        plt.tight_layout()
        plt.show()

        # Distribution plots
        fig, axes = plt.subplots(nrows=(n_numeric + 2) // 3, ncols=3, figsize=(15, 5 * ((n_numeric + 2) // 3)))
        if n_numeric == 1:
            axes = [axes]
        elif (n_numeric + 2) // 3 == 1:
            axes = [axes]
        else:
            axes = axes.flatten()

        for i, col in enumerate(numeric_cols):
            if i < len(axes):
                df[col].hist(bins=30, ax=axes[i], alpha=0.7, edgecolor='black')
                axes[i].set_title(f'Distribution: {col}')
                axes[i].set_xlabel('Values')
                axes[i].set_ylabel('Frequency')

        # Hide empty subplots
        for i in range(len(numeric_cols), len(axes)):
            axes[i].set_visible(False)

        plt.tight_layout()
        plt.show()

# 6. ADDITIONAL QUALITY CHECKS
print(f"\n🔧 6. ADDITIONAL QUALITY CHECKS")
print("-" * 50)

# Check for potential data quality issues
print("Potential Data Quality Issues:")

# Check for columns with single values
single_value_cols = [col for col in df.columns if df[col].nunique() <= 1]
if single_value_cols:
    print(f"  • Columns with single/no values: {single_value_cols}")

# Check for columns with very high cardinality
high_cardinality_cols = [col for col in categorical_cols if df[col].nunique() > 0.8 * len(df)]
if high_cardinality_cols:
    print(f"  • High cardinality categorical columns: {high_cardinality_cols}")

# Check for potential ID columns
potential_id_cols = [col for col in df.columns if df[col].nunique() == len(df)]
if potential_id_cols:
    print(f"  • Potential ID columns (unique values): {potential_id_cols}")

# Memory usage by column
print(f"\nMemory Usage by Column:")
memory_usage = df.memory_usage(deep=True).sort_values(ascending=False)
print(memory_usage.head(10))

# Correlation matrix for numeric columns
if len(numeric_cols) > 1:
    print(f"\nCorrelation Matrix:")
    correlation_matrix = df[numeric_cols].corr()

    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Correlation Matrix - Numeric Columns')
    plt.tight_layout()
    plt.show()

    # Find highly correlated pairs
    high_corr_pairs = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > 0.8:  # High correlation threshold
                high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_value))

    if high_corr_pairs:
        print(f"Highly correlated pairs (|r| > 0.8):")
        for pair in high_corr_pairs:
            print(f"  • {pair[0]} - {pair[1]}: {pair[2]:.3f}")

print(f"\n✅ ANALYSIS COMPLETE!")
print("="*80)

```

### From Sales:
```python
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2_contingency, f_oneway
import warnings
warnings.filterwarnings('ignore')

def analyze_feature_target_relationships(df, feature_cols, target_cols, feature_analysis=None):
    """
    Comprehensive analysis of relationships between features and targets
    """

    # Categorize features by type
    if feature_analysis is None:
        feature_analysis = categorize_features(df, feature_cols)

    results = {
        'feature_categories': feature_analysis,
        'correlations': {},
        'anova_results': {},
        'chi_square_results': {},
        'descriptive_stats': {}
    }

    print("=== FEATURE-TARGET RELATIONSHIP ANALYSIS ===\n")

    for target in target_cols:
        print(f"\n{'='*50}")
        print(f"ANALYZING TARGET: {target.upper()}")
        print(f"{'='*50}")

        target_analysis = analyze_single_target(df, feature_analysis, target)

        results['correlations'][target] = target_analysis['correlations']
        results['anova_results'][target] = target_analysis['anova']
        results['chi_square_results'][target] = target_analysis['chi_square']
        results['descriptive_stats'][target] = target_analysis['descriptive']

    return results


def analyze_single_target(df, feature_categories, target):
    """
    Analyze relationships between all feature categories and a single target
    """
    results = {
        'correlations': {},
        'anova': {},
        'chi_square': {},
        'descriptive': {}
    }

    # 1. CORRELATION ANALYSIS (Numeric features vs Numeric targets)
    print(f"\n1. CORRELATION ANALYSIS WITH {target}")
    print("-" * 40)

    # Only use truly numeric features for correlation
    numeric_features = (feature_categories['numeric_continuous'] +
                       feature_categories['numeric_discrete'] +
                       feature_categories['temporal_numeric'])

    if pd.api.types.is_numeric_dtype(df[target]):
        correlations = {}
        for feature in numeric_features:
            if feature in df.columns:
                try:
                    corr = df[feature].corr(df[target])
                    if not pd.isna(corr):  # Only add if correlation is valid
                        correlations[feature] = corr
                except:
                    continue

        # Sort by absolute correlation
        sorted_corr = dict(sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True))
        results['correlations'] = sorted_corr

        print("Top correlations (|r| > 0.1):")
        if sorted_corr:
            for feature, corr in sorted_corr.items():
                if abs(corr) > 0.1:
                    strength = "Strong" if abs(corr) > 0.7 else "Moderate" if abs(corr) > 0.3 else "Weak"
                    print(f"  {feature}: {corr:.3f} ({strength})")
        else:
            print("  No significant correlations found.")
    else:
        print(f"  Target '{target}' is not numeric - skipping correlation analysis.")

    # 2. ANOVA ANALYSIS (Categorical features vs Numeric targets)
    print(f"\n2. ANOVA ANALYSIS WITH {target}")
    print("-" * 40)

    if pd.api.types.is_numeric_dtype(df[target]):
        categorical_features = (feature_categories['categorical_low_cardinality'] +
                               feature_categories['categorical_high_cardinality'] +
                               feature_categories['temporal_categorical'])

        anova_results = {}
        for feature in categorical_features:
            if feature in df.columns:
                try:
                    # Skip if feature has too many categories (>50) to avoid memory issues
                    if df[feature].nunique() > 50:
                        continue

                    groups = [group[target].dropna() for name, group in df.groupby(feature)]
                    groups = [g for g in groups if len(g) > 1]  # Remove groups with ≤1 observation

                    if len(groups) >= 2:
                        f_stat, p_value = f_oneway(*groups)
                        if not (pd.isna(f_stat) or pd.isna(p_value)):
                            anova_results[feature] = {'f_statistic': f_stat, 'p_value': p_value}
                except Exception as e:
                    continue

        # Sort by F-statistic
        sorted_anova = dict(sorted(anova_results.items(),
                                 key=lambda x: x[1]['f_statistic'], reverse=True))
        results['anova'] = sorted_anova

        print("Significant categorical relationships (p < 0.05):")
        if sorted_anova:
            for feature, stats in sorted_anova.items():
                if stats['p_value'] < 0.05:
                    significance = "***" if stats['p_value'] < 0.001 else "**" if stats['p_value'] < 0.01 else "*"
                    print(f"  {feature}: F={stats['f_statistic']:.2f}, p={stats['p_value']:.4f} {significance}")
        else:
            print("  No significant categorical relationships found.")
    else:
        print(f"  Target '{target}' is not numeric - skipping ANOVA analysis.")

    # 3. CHI-SQUARE ANALYSIS (Categorical vs Categorical targets)
    print(f"\n3. CHI-SQUARE ANALYSIS WITH {target}")
    print("-" * 40)

    if not pd.api.types.is_numeric_dtype(df[target]) or df[target].nunique() <= 10:
        categorical_features = (feature_categories['categorical_low_cardinality'] +
                               feature_categories['temporal_categorical'])

        chi_square_results = {}
        for feature in categorical_features:
            if feature in df.columns and feature != target:  # Don't compare target with itself
                try:
                    # Skip features with too many categories
                    if df[feature].nunique() > 20:
                        continue

                    contingency_table = pd.crosstab(df[feature], df[target])

                    # Only proceed if we have a valid contingency table
                    if contingency_table.size > 1 and contingency_table.sum().sum() > 0:
                        chi2, p_value, dof, expected = chi2_contingency(contingency_table)

                        # Cramér's V for effect size
                        n = contingency_table.sum().sum()
                        cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))

                        chi_square_results[feature] = {
                            'chi2': chi2,
                            'p_value': p_value,
                            'cramers_v': cramers_v
                        }
                except Exception as e:
                    continue

        # Sort by Cramér's V
        sorted_chi2 = dict(sorted(chi_square_results.items(),
                                key=lambda x: x[1]['cramers_v'], reverse=True))
        results['chi_square'] = sorted_chi2

        print("Significant categorical associations (p < 0.05):")
        if sorted_chi2:
            for feature, stats in sorted_chi2.items():
                if stats['p_value'] < 0.05:
                    strength = "Strong" if stats['cramers_v'] > 0.5 else "Moderate" if stats['cramers_v'] > 0.3 else "Weak"
                    print(f"  {feature}: χ²={stats['chi2']:.2f}, p={stats['p_value']:.4f}, Cramér's V={stats['cramers_v']:.3f} ({strength})")
        else:
            print("  No significant categorical associations found.")
    else:
        print(f"  Target '{target}' is numeric with high cardinality - skipping chi-square analysis.")

    # 4. DESCRIPTIVE STATISTICS BY GROUPS
    print(f"\n4. DESCRIPTIVE STATISTICS BY KEY CATEGORICAL FEATURES")
    print("-" * 40)

    key_categorical = feature_categories['categorical_low_cardinality'][:5]  # Top 5 for brevity
    descriptive_stats = {}

    for feature in key_categorical:
        if feature in df.columns:
            try:
                # Handle numeric targets
                if pd.api.types.is_numeric_dtype(df[target]):
                    desc_stats = df.groupby(feature)[target].agg(['count', 'mean', 'std', 'min', 'max']).round(3)
                    descriptive_stats[feature] = desc_stats

                    print(f"\n{target} by {feature}:")
                    print(desc_stats.head(10))  # Show top 10 categories

                # Handle categorical targets
                else:
                    # For categorical targets, show frequency distribution
                    crosstab = pd.crosstab(df[feature], df[target], margins=True)
                    descriptive_stats[feature] = crosstab

                    print(f"\n{target} distribution by {feature}:")
                    print(crosstab.head(10))  # Show top 10 categories

            except Exception as e:
                print(f"\nCould not analyze {target} by {feature}: {str(e)}")
                continue

    results['descriptive'] = descriptive_stats

    return results


def generate_summary_report(results):
    """
    Generate a summary report of all findings
    """
    print("\n" + "="*70)
    print("EXECUTIVE SUMMARY OF FEATURE-TARGET RELATIONSHIPS")
    print("="*70)

    for target, analysis in results['correlations'].items():
        print(f"\n📊 TARGET: {target.upper()}")
        print("-" * 50)

        # Top correlations
        if analysis:
            top_corr = list(analysis.items())[:3]
            print("🔗 Strongest Correlations:")
            for feature, corr in top_corr:
                if abs(corr) > 0.1:
                    print(f"   • {feature}: {corr:.3f}")

        # Top ANOVA results
        if target in results['anova_results']:
            anova_data = results['anova_results'][target]
            if anova_data:
                top_anova = list(anova_data.items())[:3]
                print("📈 Strongest Categorical Relationships:")
                for feature, stats in top_anova:
                    if stats['p_value'] < 0.05:
                        print(f"   • {feature}: F={stats['f_statistic']:.2f} (p={stats['p_value']:.4f})")

# Main execution function
def run_complete_analysis(df, feature_cols, target_cols, feature_analysis=None):
    """
    Run the complete relationship analysis
    """
    # Main analysis
    results = analyze_feature_target_relationships(df, feature_cols, target_cols, feature_analysis)

    # Generate summary
    generate_summary_report(results)

    return results

```

### From Sales:
```python
def plot_correlation(df, data_field, target_field):
    """
    Create a scatter plot with correlation line for numeric relationships

    Parameters:
    df: DataFrame
    data_field: str - name of the feature column
    target_field: str - name of the target column
    """
    # Calculate correlation
    correlation = df[data_field].corr(df[target_field])

    # Create figure
    plt.figure(figsize=(10, 6))

    # Scatter plot
    plt.scatter(df[data_field], df[target_field], alpha=0.6, s=30)

    # Add correlation line
    z = np.polyfit(df[data_field], df[target_field], 1)
    p = np.poly1d(z)
    plt.plot(df[data_field], p(df[data_field]), "r--", alpha=0.8, linewidth=2)

    # Labels and title
    plt.xlabel(data_field.replace('_', ' ').title())
    plt.ylabel(target_field.replace('_', ' ').title())
    plt.title(f'{target_field.replace("_", " ").title()} vs {data_field.replace("_", " ").title()}\n'
              f'Correlation: {correlation:.3f}', fontsize=14, fontweight='bold')

    # Add correlation strength text
    if abs(correlation) > 0.7:
        strength = "Strong"
    elif abs(correlation) > 0.3:
        strength = "Moderate"
    else:
        strength = "Weak"

    plt.text(0.05, 0.95, f'Strength: {strength}', transform=plt.gca().transAxes,
             fontsize=12, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))

    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def plot_categorical(df, data_field, target_field):
    """
    Create a box plot for categorical vs numeric relationships

    Parameters:
    df: DataFrame
    data_field: str - name of the categorical feature column
    target_field: str - name of the target column
    """
    # Check if target is numeric or categorical
    if pd.api.types.is_numeric_dtype(df[target_field]):
        # Numeric target - use box plot
        plt.figure(figsize=(12, 6))

        # Create box plot
        sns.boxplot(data=df, x=data_field, y=target_field)

        # Rotate x-axis labels if needed
        n_categories = df[data_field].nunique()
        if n_categories > 5:
            plt.xticks(rotation=45, ha='right')

        # Labels and title
        plt.xlabel(data_field.replace('_', ' ').title())
        plt.ylabel(target_field.replace('_', ' ').title())
        plt.title(f'{target_field.replace("_", " ").title()} by {data_field.replace("_", " ").title()}',
                  fontsize=14, fontweight='bold')

        # Add summary statistics
        group_stats = df.groupby(data_field)[target_field].agg(['mean', 'std']).round(3)
        print(f"\nSummary Statistics for {target_field} by {data_field}:")
        print("=" * 50)
        print(group_stats)

    else:
        # Categorical target - use stacked bar chart
        plt.figure(figsize=(12, 6))

        # Create cross-tabulation
        crosstab = pd.crosstab(df[data_field], df[target_field], normalize='index') * 100

        # Create stacked bar chart
        crosstab.plot(kind='bar', stacked=True, ax=plt.gca())

        # Rotate x-axis labels if needed
        plt.xticks(rotation=45, ha='right')

        # Labels and title
        plt.xlabel(data_field.replace('_', ' ').title())
        plt.ylabel('Percentage')
        plt.title(f'{target_field.replace("_", " ").title()} Distribution by {data_field.replace("_", " ").title()}',
                  fontsize=14, fontweight='bold')

        # Adjust legend
        plt.legend(title=target_field.replace('_', ' ').title(),
                   bbox_to_anchor=(1.05, 1), loc='upper left')

        # Print cross-tabulation
        print(f"\nCross-tabulation: {target_field} by {data_field}")
        print("=" * 50)
        print(pd.crosstab(df[data_field], df[target_field], margins=True))

    plt.tight_layout()
    plt.show()
```

### From Sales:
```python
corrs = ['unit_price', 'revenue_per_unit', 'discount_amount']
for corr in corrs:
    plot_correlation(df, corr, 'sales')

cat_rels = ['category', 'subcategory', 'order_size_category']
for cat_rel in cat_rels:
    plot_categorical(df, cat_rel, 'sales')
```

### From Sales:
```python
corrs = ['discount', 'profit_per_unit', 'discount_amount']
for corr in corrs:
    plot_correlation(df, corr, 'profit_margin')

cat_rels = ['discount_category', 'is_discounted', 'region']
for cat_rel in cat_rels:
    plot_categorical(df, cat_rel, 'profit_margin')
```

### From Sales:
```python
corrs = ['profit_per_unit', 'unit_price', 'revenue_per_unit']
for corr in corrs:
    plot_correlation(df, corr, 'profit')

cat_rels = ['is_discounted', 'discount_category', 'subcategory']
for cat_rel in cat_rels:
    plot_categorical(df, cat_rel, 'profit')
```

### From Sales:
```python
corrs = ['profit_per_unit']
for corr in corrs:
    plot_correlation(df, corr, 'revenue_per_unit')

cat_rels = ['category', 'subcategory', 'customer_rfm_segment']
for cat_rel in cat_rels:
    plot_categorical(df, cat_rel, 'revenue_per_unit')
```

### From Sales:
```python
cat_rels = ['is_discounted', 'discount_category', 'subcategory']
for cat_rel in cat_rels:
    plot_categorical(df, cat_rel, 'profit_per_unit')
```

### From Sales:
```python
from datetime import datetime
from scipy import stats
from sklearn.preprocessing import StandardScaler
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
import warnings
warnings.filterwarnings('ignore')

# Set up plotting style
plt.style.use('default')
sns.set_palette("husl")

class SalesTrendAnalyzer:
    def __init__(self, df):
        self.df = df.copy()
        self.summary_text = ""
        self.prepare_data()

    def prepare_data(self):
        """Prepare data for analysis"""
        # Convert date columns
        self.df['order_date'] = pd.to_datetime(self.df['order_date'])
        if 'ship_date' in self.df.columns:
            self.df['ship_date'] = pd.to_datetime(self.df['ship_date'])

        # Create additional time features if not present
        if 'order_month' not in self.df.columns:
            self.df['order_month'] = self.df['order_date'].dt.month
        if 'order_year' not in self.df.columns:
            self.df['order_year'] = self.df['order_date'].dt.year
        if 'order_quarter' not in self.df.columns:
            self.df['order_quarter'] = self.df['order_date'].dt.quarter
        if 'order_day_of_week' not in self.df.columns:
            self.df['order_day_of_week'] = self.df['order_date'].dt.day_name()

        # Create date-based aggregations
        self.daily_sales = self.df.groupby('order_date')['sales'].sum().reset_index()
        self.monthly_sales = self.df.groupby(['order_year', 'order_month'])['sales'].sum().reset_index()
        # Create proper date column for monthly data
        self.monthly_sales['date'] = pd.to_datetime(
            {'year': self.monthly_sales['order_year'],
             'month': self.monthly_sales['order_month'],
             'day': 1}
        )

    def analyze_time_series_trends(self):
        """Analyze overall time series trends"""
        print("=== TIME SERIES TREND ANALYSIS ===")

        # Create time series
        ts = self.monthly_sales.set_index('date')['sales']

        # Basic statistics
        trend_stats = {
            'total_sales': ts.sum(),
            'avg_monthly_sales': ts.mean(),
            'std_monthly_sales': ts.std(),
            'cv': ts.std() / ts.mean(),
            'min_month': ts.min(),
            'max_month': ts.max(),
            'growth_rate': ((ts.iloc[-1] - ts.iloc[0]) / ts.iloc[0]) * 100 if len(ts) > 1 else 0
        }

        # Stationarity test
        adf_result = adfuller(ts.dropna())
        is_stationary = adf_result[1] < 0.05

        self.summary_text += f"""
TIME SERIES ANALYSIS SUMMARY:
- Total Sales: ${trend_stats['total_sales']:,.2f}
- Average Monthly Sales: ${trend_stats['avg_monthly_sales']:,.2f}
- Sales Volatility (CV): {trend_stats['cv']:.2f}
- Overall Growth Rate: {trend_stats['growth_rate']:.1f}%
- Time Series is {'Stationary' if is_stationary else 'Non-Stationary'} (p-value: {adf_result[1]:.4f})
- Sales Range: ${trend_stats['min_month']:,.2f} to ${trend_stats['max_month']:,.2f}
"""

        # Plot time series trends
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Monthly sales trend
        axes[0,0].plot(ts.index, ts.values, marker='o', linewidth=2)
        axes[0,0].set_title('Monthly Sales Trend')
        axes[0,0].set_ylabel('Sales ($)')
        axes[0,0].tick_params(axis='x', rotation=45)

        # Moving averages
        ts_3ma = ts.rolling(window=3).mean()
        ts_12ma = ts.rolling(window=12).mean()
        axes[0,1].plot(ts.index, ts.values, alpha=0.3, label='Actual')
        axes[0,1].plot(ts_3ma.index, ts_3ma.values, label='3-Month MA')
        axes[0,1].plot(ts_12ma.index, ts_12ma.values, label='12-Month MA')
        axes[0,1].set_title('Sales with Moving Averages')
        axes[0,1].legend()
        axes[0,1].tick_params(axis='x', rotation=45)

        # Year-over-year comparison
        pivot_data = self.monthly_sales.pivot(index='order_month', columns='order_year', values='sales')
        for year in pivot_data.columns:
            axes[1,0].plot(pivot_data.index, pivot_data[year], marker='o', label=f'{year}')
        axes[1,0].set_title('Year-over-Year Monthly Comparison')
        axes[1,0].set_xlabel('Month')
        axes[1,0].set_ylabel('Sales ($)')
        axes[1,0].legend()
        axes[1,0].set_xticks(range(1, 13))

        # Growth rates
        growth_rates = ts.pct_change() * 100
        axes[1,1].bar(range(len(growth_rates)), growth_rates.values)
        axes[1,1].set_title('Month-over-Month Growth Rates')
        axes[1,1].set_ylabel('Growth Rate (%)')
        axes[1,1].axhline(y=0, color='red', linestyle='--')

        plt.tight_layout()
        plt.show()

        return trend_stats

    def analyze_seasonality(self):
        """Analyze seasonal patterns"""
        print("\n=== SEASONALITY ANALYSIS ===")

        # Seasonal decomposition
        ts = self.monthly_sales.set_index('date')['sales']
        if len(ts) >= 24:  # Need at least 2 years for seasonal decomposition
            decomposition = seasonal_decompose(ts, model='additive', period=12)

            # Plot decomposition
            fig, axes = plt.subplots(4, 1, figsize=(15, 12))
            decomposition.observed.plot(ax=axes[0], title='Original Time Series')
            decomposition.trend.plot(ax=axes[1], title='Trend Component')
            decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component')
            decomposition.resid.plot(ax=axes[3], title='Residual Component')
            plt.tight_layout()
            plt.show()

            # Seasonal strength
            seasonal_strength = 1 - (decomposition.resid.var() / (decomposition.resid + decomposition.seasonal).var())

        else:
            seasonal_strength = 0
            self.summary_text += "Note: Insufficient data for seasonal decomposition (need 24+ months)\n"

        # Monthly patterns
        monthly_stats = self.df.groupby('order_month')['sales'].agg(['sum', 'mean', 'count']).reset_index()
        monthly_stats['seasonal_index'] = monthly_stats['sum'] / monthly_stats['sum'].mean()

        # Identify peak and low seasons
        peak_month = monthly_stats.loc[monthly_stats['seasonal_index'].idxmax(), 'order_month']
        low_month = monthly_stats.loc[monthly_stats['seasonal_index'].idxmin(), 'order_month']
        peak_index = monthly_stats['seasonal_index'].max()
        low_index = monthly_stats['seasonal_index'].min()

        # Day of week patterns
        dow_stats = self.df.groupby('order_day_of_week')['sales'].agg(['sum', 'mean', 'count']).reset_index()
        dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        dow_stats['order_day_of_week'] = pd.Categorical(dow_stats['order_day_of_week'], categories=dow_order, ordered=True)
        dow_stats = dow_stats.sort_values('order_day_of_week')

        best_day = dow_stats.loc[dow_stats['sum'].idxmax(), 'order_day_of_week']
        worst_day = dow_stats.loc[dow_stats['sum'].idxmin(), 'order_day_of_week']

        # Quarterly patterns
        quarterly_stats = self.df.groupby('order_quarter')['sales'].agg(['sum', 'mean', 'count']).reset_index()
        quarterly_stats['seasonal_index'] = quarterly_stats['sum'] / quarterly_stats['sum'].mean()
        best_quarter = quarterly_stats.loc[quarterly_stats['seasonal_index'].idxmax(), 'order_quarter']

        self.summary_text += f"""
SEASONALITY ANALYSIS SUMMARY:
- Seasonal Strength: {seasonal_strength:.2f} (0=no seasonality, 1=perfect seasonality)
- Peak Sales Month: {peak_month} (Index: {peak_index:.2f})
- Lowest Sales Month: {low_month} (Index: {low_index:.2f})
- Best Day of Week: {best_day}
- Worst Day of Week: {worst_day}
- Best Quarter: Q{best_quarter}
- Monthly Sales Variance: {monthly_stats['sum'].std()/monthly_stats['sum'].mean():.2f}
"""

        # Seasonal visualizations
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Monthly seasonality heatmap
        heatmap_data = self.df.groupby(['order_year', 'order_month'])['sales'].sum().unstack(fill_value=0)
        sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[0,0])
        axes[0,0].set_title('Monthly Sales Heatmap by Year')

        # Seasonal indices
        axes[0,1].bar(monthly_stats['order_month'], monthly_stats['seasonal_index'])
        axes[0,1].axhline(y=1, color='red', linestyle='--', alpha=0.7)
        axes[0,1].set_title('Monthly Seasonal Indices')
        axes[0,1].set_xlabel('Month')
        axes[0,1].set_ylabel('Seasonal Index')
        axes[0,1].set_xticks(range(1, 13))

        # Day of week patterns
        axes[1,0].bar(range(len(dow_stats)), dow_stats['sum'])
        axes[1,0].set_title('Sales by Day of Week')
        axes[1,0].set_xticks(range(len(dow_stats)))
        axes[1,0].set_xticklabels([day[:3] for day in dow_stats['order_day_of_week']])
        axes[1,0].set_ylabel('Total Sales ($)')

        # Quarterly patterns
        axes[1,1].bar(quarterly_stats['order_quarter'], quarterly_stats['sum'])
        axes[1,1].set_title('Sales by Quarter')
        axes[1,1].set_xlabel('Quarter')
        axes[1,1].set_ylabel('Total Sales ($)')

        plt.tight_layout()
        plt.show()

        return monthly_stats, dow_stats, quarterly_stats

    def identify_high_sales_periods(self):
        """Identify and analyze high-sales periods"""
        print("\n=== HIGH-SALES PERIOD ANALYSIS ===")

        # Define thresholds for high-sales periods
        daily_sales = self.daily_sales.copy()
        monthly_sales = self.monthly_sales.copy()

        # Calculate percentile thresholds
        daily_p95 = daily_sales['sales'].quantile(0.95)
        daily_p99 = daily_sales['sales'].quantile(0.99)
        monthly_p95 = monthly_sales['sales'].quantile(0.95)

        # Identify high-sales days and months
        high_sales_days = daily_sales[daily_sales['sales'] >= daily_p95].copy()
        exceptional_days = daily_sales[daily_sales['sales'] >= daily_p99].copy()
        high_sales_months = monthly_sales[monthly_sales['sales'] >= monthly_p95].copy()

        # Add temporal features
        high_sales_days['month'] = high_sales_days['order_date'].dt.month
        high_sales_days['day_of_week'] = high_sales_days['order_date'].dt.day_name()
        high_sales_days['quarter'] = high_sales_days['order_date'].dt.quarter

        # Calculate statistics
        total_high_sales_days = len(high_sales_days)
        total_exceptional_days = len(exceptional_days)
        avg_high_day_sales = high_sales_days['sales'].mean()
        peak_day_sales = daily_sales['sales'].max()
        peak_day_date = daily_sales.loc[daily_sales['sales'].idxmax(), 'order_date']

        # Most common patterns in high-sales periods
        common_high_month = high_sales_days['month'].mode()[0] if not high_sales_days.empty else None
        common_high_dow = high_sales_days['day_of_week'].mode()[0] if not high_sales_days.empty else None
        common_high_quarter = high_sales_days['quarter'].mode()[0] if not high_sales_days.empty else None

        # Duration analysis of high-sales periods
        high_sales_days_sorted = high_sales_days.sort_values('order_date')
        if not high_sales_days_sorted.empty:
            # Find consecutive high-sales periods
            high_sales_days_sorted['date_diff'] = high_sales_days_sorted['order_date'].diff().dt.days
            consecutive_periods = []
            current_period = [high_sales_days_sorted.iloc[0]['order_date']]

            for i in range(1, len(high_sales_days_sorted)):
                if high_sales_days_sorted.iloc[i]['date_diff'] <= 3:  # Within 3 days
                    current_period.append(high_sales_days_sorted.iloc[i]['order_date'])
                else:
                    if len(current_period) > 1:
                        consecutive_periods.append(current_period)
                    current_period = [high_sales_days_sorted.iloc[i]['order_date']]

            if len(current_period) > 1:
                consecutive_periods.append(current_period)

            avg_period_length = np.mean([len(period) for period in consecutive_periods]) if consecutive_periods else 1
        else:
            avg_period_length = 0

        # Recovery analysis
        daily_sales_sorted = daily_sales.sort_values('order_date')
        daily_sales_sorted['is_high'] = daily_sales_sorted['sales'] >= daily_p95
        daily_sales_sorted['sales_change'] = daily_sales_sorted['sales'].pct_change() * 100

        # Post-peak recovery time
        recovery_times = []
        high_sales_indices = daily_sales_sorted[daily_sales_sorted['is_high']].index

        for idx in high_sales_indices:
            post_peak_data = daily_sales_sorted.loc[idx+1:idx+10]  # Look 10 days ahead
            if not post_peak_data.empty:
                baseline = daily_sales_sorted['sales'].median()
                recovery_day = post_peak_data[post_peak_data['sales'] <= baseline]
                if not recovery_day.empty:
                    recovery_times.append(len(post_peak_data) - len(recovery_day) + 1)

        avg_recovery_time = np.mean(recovery_times) if recovery_times else 0

        self.summary_text += f"""
HIGH-SALES PERIOD ANALYSIS SUMMARY:
- High-Sales Days (95th percentile): {total_high_sales_days} days (${daily_p95:,.2f}+ per day)
- Exceptional Sales Days (99th percentile): {total_exceptional_days} days (${daily_p99:,.2f}+ per day)
- Average High-Sales Day Revenue: ${avg_high_day_sales:,.2f}
- Peak Sales Day: {peak_day_date.strftime('%Y-%m-%d')} (${peak_day_sales:,.2f})
- Most Common High-Sales Month: {common_high_month}
- Most Common High-Sales Day of Week: {common_high_dow}
- Most Common High-Sales Quarter: Q{common_high_quarter}
- Average High-Sales Period Duration: {avg_period_length:.1f} days
- Average Recovery Time: {avg_recovery_time:.1f} days
- Consecutive High-Sales Periods Found: {len(consecutive_periods) if 'consecutive_periods' in locals() else 0}
"""

        # Visualizations
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Daily sales with high-sales threshold
        axes[0,0].plot(daily_sales['order_date'], daily_sales['sales'], alpha=0.7, linewidth=1)
        axes[0,0].axhline(y=daily_p95, color='red', linestyle='--', label=f'95th Percentile (${daily_p95:,.0f})')
        axes[0,0].axhline(y=daily_p99, color='orange', linestyle='--', label=f'99th Percentile (${daily_p99:,.0f})')
        axes[0,0].scatter(high_sales_days['order_date'], high_sales_days['sales'],
                         color='red', s=20, alpha=0.7, label='High-Sales Days')
        axes[0,0].set_title('Daily Sales with High-Sales Periods')
        axes[0,0].set_ylabel('Daily Sales ($)')
        axes[0,0].legend()
        axes[0,0].tick_params(axis='x', rotation=45)

        # Distribution of sales with percentiles
        axes[0,1].hist(daily_sales['sales'], bins=50, alpha=0.7, edgecolor='black')
        axes[0,1].axvline(x=daily_p95, color='red', linestyle='--', label=f'95th Percentile')
        axes[0,1].axvline(x=daily_p99, color='orange', linestyle='--', label=f'99th Percentile')
        axes[0,1].set_title('Distribution of Daily Sales')
        axes[0,1].set_xlabel('Daily Sales ($)')
        axes[0,1].set_ylabel('Frequency')
        axes[0,1].legend()

        # High-sales days by month
        if not high_sales_days.empty:
            month_counts = high_sales_days['month'].value_counts().sort_index()
            axes[1,0].bar(month_counts.index, month_counts.values)
            axes[1,0].set_title('High-Sales Days by Month')
            axes[1,0].set_xlabel('Month')
            axes[1,0].set_ylabel('Number of High-Sales Days')
            axes[1,0].set_xticks(range(1, 13))

        # High-sales days by day of week
        if not high_sales_days.empty:
            dow_counts = high_sales_days['day_of_week'].value_counts()
            dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            dow_counts = dow_counts.reindex([day for day in dow_order if day in dow_counts.index])
            axes[1,1].bar(range(len(dow_counts)), dow_counts.values)
            axes[1,1].set_title('High-Sales Days by Day of Week')
            axes[1,1].set_xticks(range(len(dow_counts)))
            axes[1,1].set_xticklabels([day[:3] for day in dow_counts.index])
            axes[1,1].set_ylabel('Number of High-Sales Days')

        plt.tight_layout()
        plt.show()

        return high_sales_days, exceptional_days, high_sales_months

    def analyze_contributing_factors(self):
        """Analyze factors contributing to high sales periods"""
        print("\n=== CONTRIBUTING FACTORS ANALYSIS ===")

        # Merge daily sales with original data for factor analysis
        daily_sales_detailed = self.df.groupby('order_date').agg({
            'sales': 'sum',
            'profit': 'sum',
            'quantity': 'sum',
            'discount': 'mean',
            'profit_margin': 'mean',
            'is_discounted': 'mean',
            'order_total': 'sum'
        }).reset_index()

        # Define high vs normal sales periods
        threshold = daily_sales_detailed['sales'].quantile(0.90)
        daily_sales_detailed['is_high_sales'] = daily_sales_detailed['sales'] >= threshold

        # Statistical comparison
        high_sales_data = daily_sales_detailed[daily_sales_detailed['is_high_sales']]
        normal_sales_data = daily_sales_detailed[~daily_sales_detailed['is_high_sales']]

        # Key metrics comparison
        metrics_comparison = {}
        numeric_columns = ['sales', 'profit', 'quantity', 'discount', 'profit_margin', 'is_discounted']

        for col in numeric_columns:
            if col in daily_sales_detailed.columns:
                high_mean = high_sales_data[col].mean()
                normal_mean = normal_sales_data[col].mean()
                # T-test for statistical significance
                t_stat, p_value = stats.ttest_ind(high_sales_data[col].dropna(),
                                                normal_sales_data[col].dropna())

                metrics_comparison[col] = {
                    'high_sales_mean': high_mean,
                    'normal_sales_mean': normal_mean,
                    'difference_pct': ((high_mean - normal_mean) / normal_mean) * 100,
                    'p_value': p_value,
                    'significant': p_value < 0.05
                }

        # Category/Segment analysis for high-sales periods
        high_sales_dates = high_sales_data['order_date'].tolist()
        high_sales_transactions = self.df[self.df['order_date'].isin(high_sales_dates)]

        # Top contributing categories during high sales
        category_contribution = high_sales_transactions.groupby('category')['sales'].sum().sort_values(ascending=False)
        segment_contribution = high_sales_transactions.groupby('segment')['sales'].sum().sort_values(ascending=False)
        region_contribution = high_sales_transactions.groupby('region')['sales'].sum().sort_values(ascending=False)

        # Most significant contributing factors
        significant_factors = [col for col, data in metrics_comparison.items()
                             if data['significant'] and abs(data['difference_pct']) > 5]

        self.summary_text += f"""
CONTRIBUTING FACTORS ANALYSIS SUMMARY:
- High-Sales Threshold (90th percentile): ${threshold:,.2f}
- Number of High-Sales Days: {len(high_sales_data)}

Key Differences in High-Sales vs Normal Periods:
"""

        for col, data in metrics_comparison.items():
            if data['significant']:
                direction = "higher" if data['difference_pct'] > 0 else "lower"
                self.summary_text += f"  - {col.title()}: {abs(data['difference_pct']):.1f}% {direction} (p<{data['p_value']:.3f})\n"

        self.summary_text += f"""
Top Contributing Categories during High-Sales:
  1. {category_contribution.index[0]}: ${category_contribution.iloc[0]:,.2f}
  2. {category_contribution.index[1] if len(category_contribution) > 1 else 'N/A'}: ${category_contribution.iloc[1] if len(category_contribution) > 1 else 0:,.2f}
  3. {category_contribution.index[2] if len(category_contribution) > 2 else 'N/A'}: ${category_contribution.iloc[2] if len(category_contribution) > 2 else 0:,.2f}

Top Contributing Segments:
  1. {segment_contribution.index[0]}: ${segment_contribution.iloc[0]:,.2f}
  2. {segment_contribution.index[1] if len(segment_contribution) > 1 else 'N/A'}: ${segment_contribution.iloc[1] if len(segment_contribution) > 1 else 0:,.2f}

Top Contributing Regions:
  1. {region_contribution.index[0]}: ${region_contribution.iloc[0]:,.2f}
  2. {region_contribution.index[1] if len(region_contribution) > 1 else 'N/A'}: ${region_contribution.iloc[1] if len(region_contribution) > 1 else 0:,.2f}
"""

        # Correlation analysis
        correlation_data = daily_sales_detailed[numeric_columns].corr()['sales'].sort_values(ascending=False)

        self.summary_text += f"\nSales Correlations:\n"
        for col, corr in correlation_data.items():
            if col != 'sales' and abs(corr) > 0.1:
                self.summary_text += f"  - {col.title()}: {corr:.3f}\n"

        # Visualization
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Box plots comparing high vs normal sales periods
        comparison_data = []
        for col in ['discount', 'profit_margin', 'quantity']:
            if col in daily_sales_detailed.columns:
                high_vals = high_sales_data[col].tolist()
                normal_vals = normal_sales_data[col].tolist()
                comparison_data.extend([(val, col, 'High Sales') for val in high_vals])
                comparison_data.extend([(val, col, 'Normal Sales') for val in normal_vals])

        if comparison_data:
            comp_df = pd.DataFrame(comparison_data, columns=['value', 'metric', 'period'])
            for i, metric in enumerate(['discount', 'profit_margin', 'quantity']):
                if metric in comp_df['metric'].values:
                    metric_data = comp_df[comp_df['metric'] == metric]
                    if i < 2:
                        sns.boxplot(data=metric_data, x='period', y='value', ax=axes[0, i])
                        axes[0, i].set_title(f'{metric.title()} Distribution')

        # Top categories during high sales
        axes[1,0].barh(range(len(category_contribution.head())), category_contribution.head().values)
        axes[1,0].set_yticks(range(len(category_contribution.head())))
        axes[1,0].set_yticklabels(category_contribution.head().index)
        axes[1,0].set_title('Top Categories in High-Sales Periods')
        axes[1,0].set_xlabel('Sales ($)')

        # Correlation heatmap
        sns.heatmap(correlation_data.to_frame(), annot=True, cmap='RdBu_r', center=0, ax=axes[1,1])
        axes[1,1].set_title('Sales Correlations')

        plt.tight_layout()
        plt.show()

        return metrics_comparison, category_contribution, segment_contribution

    def generate_comprehensive_summary(self):
        """Generate final comprehensive summary"""
        self.summary_text += f"""

=== COMPREHENSIVE SALES ANALYSIS SUMMARY ===
Analysis completed on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Dataset Overview:
- Total Records: {len(self.df):,}
- Date Range: {self.df['order_date'].min().strftime('%Y-%m-%d')} to {self.df['order_date'].max().strftime('%Y-%m-%d')}
- Analysis Period: {(self.df['order_date'].max() - self.df['order_date'].min()).days} days

Key Findings:
1. Sales show clear temporal patterns with identifiable seasonality
2. High-sales periods are concentrated in specific months and days of the week
3. Contributing factors to high-sales periods have been statistically identified
4. Recovery patterns post-high-sales periods follow predictable timelines

Recommendations for Business Strategy:
- Focus marketing efforts during identified high-performing seasons
- Prepare inventory and staffing for predicted high-sales periods
- Analyze successful high-sales period characteristics for replication
- Monitor early indicators of high-sales periods for proactive planning

This analysis provides a comprehensive foundation for sales forecasting,
inventory planning, and strategic business decisions.
"""

        return self.summary_text

def run_complete_analysis(df):
    """
    Main function to run complete sales trend and seasonality analysis

    Parameters:
    df (pandas.DataFrame): Sales dataset with required columns

    Returns:
    str: Comprehensive summary text for LLM analysis
    """

    analyzer = SalesTrendAnalyzer(df)

    # Run all analyses
    print("Starting comprehensive sales analysis...")

    # 1. Time series trend analysis
    trend_stats = analyzer.analyze_time_series_trends()

    # 2. Seasonality analysis
    monthly_stats, dow_stats, quarterly_stats = analyzer.analyze_seasonality()

    # 3. High-sales period identification
    high_sales_days, exceptional_days, high_sales_months = analyzer.identify_high_sales_periods()

    # 4. Contributing factors analysis
    metrics_comparison, category_contrib, segment_contrib = analyzer.analyze_contributing_factors()

    # 5. Generate comprehensive summary
    final_summary = analyzer.generate_comprehensive_summary()

    print("\n" + "="*50)
    print("ANALYSIS COMPLETE")
    print("="*50)
    print("\nSummary text has been generated for LLM analysis.")
    print(f"Summary length: {len(final_summary)} characters")

    return final_summary


temp_analysis_summary = run_complete_analysis(df)


# Print the summary
print("="*60)
print("SUMMARY FOR LLM ANALYSIS:")
print("="*60)
print(temp_analysis_summary)
```

### From Sales:
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("husl")

# ========== 1. CORRELATION ANALYSIS ==========
print("=== CORRELATION ANALYSIS ===")
correlation_vars = ['unit_price', 'sales', 'profit_margin', 'discount_amount', 'revenue_per_unit']
corr_matrix = df[correlation_vars].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0,
            square=True, fmt='.3f')
plt.title('Correlation Matrix: Unit Price, Sales & Profit Relationships')
plt.tight_layout()
plt.show()

# Print key correlations
print(f"Unit Price vs Sales: {corr_matrix.loc['unit_price', 'sales']:.3f}")
print(f"Unit Price vs Profit Margin: {corr_matrix.loc['unit_price', 'profit_margin']:.3f}")
print(f"Discount Amount vs Profit Margin: {corr_matrix.loc['discount_amount', 'profit_margin']:.3f}")

# ========== 2. SEGMENTATION ANALYSIS ==========
print("\n=== SEGMENTATION ANALYSIS ===")

# Category-level analysis
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Sales by Category
category_stats = df.groupby('category').agg({
    'sales': 'mean',
    'profit_margin': 'mean',
    'unit_price': 'mean',
    'discount_amount': 'mean'
}).round(3)

category_stats['sales'].plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Average Sales by Category')
axes[0,0].set_ylabel('Average Sales ($)')
axes[0,0].tick_params(axis='x', rotation=45)

# Profit Margin by Category
category_stats['profit_margin'].plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Average Profit Margin by Category')
axes[0,1].set_ylabel('Profit Margin')
axes[0,1].tick_params(axis='x', rotation=45)

# Unit Price vs Sales scatter by Category
for i, category in enumerate(df['category'].unique()):
    cat_data = df[df['category'] == category]
    axes[1,0].scatter(cat_data['unit_price'], cat_data['sales'],
                     alpha=0.6, label=category, s=20)
axes[1,0].set_xlabel('Unit Price ($)')
axes[1,0].set_ylabel('Sales ($)')
axes[1,0].set_title('Unit Price vs Sales by Category')
axes[1,0].legend()

# Unit Price vs Profit Margin scatter by Category
for i, category in enumerate(df['category'].unique()):
    cat_data = df[df['category'] == category]
    axes[1,1].scatter(cat_data['unit_price'], cat_data['profit_margin'],
                     alpha=0.6, label=category, s=20)
axes[1,1].set_xlabel('Unit Price ($)')
axes[1,1].set_ylabel('Profit Margin')
axes[1,1].set_title('Unit Price vs Profit Margin by Category')
axes[1,1].legend()

plt.tight_layout()
plt.show()

print("Category Performance Summary:")
print(category_stats)

# ========== 3. REGRESSION ANALYSIS ==========
print("\n=== REGRESSION ANALYSIS ===")

# Prepare features for regression
X = df[['unit_price', 'discount_amount']].fillna(0)
y = df['profit_margin'].fillna(0)

# Fit regression model
model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)

# Model performance
r2 = r2_score(y, y_pred)
print(f"R² Score: {r2:.3f}")
print(f"Unit Price Coefficient: {model.coef_[0]:.4f}")
print(f"Discount Amount Coefficient: {model.coef_[1]:.4f}")
print(f"Intercept: {model.intercept_:.4f}")

# Visualization of regression results
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Unit Price vs Profit Margin with regression line
axes[0].scatter(df['unit_price'], df['profit_margin'], alpha=0.5, s=20)
x_range = np.linspace(df['unit_price'].min(), df['unit_price'].max(), 100)
y_range_price = model.intercept_ + model.coef_[0] * x_range + model.coef_[1] * df['discount_amount'].mean()
axes[0].plot(x_range, y_range_price, 'r-', linewidth=2, label='Regression Line')
axes[0].set_xlabel('Unit Price ($)')
axes[0].set_ylabel('Profit Margin')
axes[0].set_title('Unit Price vs Profit Margin (with Regression)')
axes[0].legend()

# Discount Amount vs Profit Margin
axes[1].scatter(df['discount_amount'], df['profit_margin'], alpha=0.5, s=20)
x_range_discount = np.linspace(df['discount_amount'].min(), df['discount_amount'].max(), 100)
y_range_discount = model.intercept_ + model.coef_[1] * x_range_discount + model.coef_[0] * df['unit_price'].mean()
axes[1].plot(x_range_discount, y_range_discount, 'r-', linewidth=2, label='Regression Line')
axes[1].set_xlabel('Discount Amount ($)')
axes[1].set_ylabel('Profit Margin')
axes[1].set_title('Discount Amount vs Profit Margin (with Regression)')
axes[1].legend()

plt.tight_layout()
plt.show()

# ========== 4. THRESHOLD ANALYSIS ==========
print("\n=== THRESHOLD ANALYSIS ===")

# Define price quantiles as thresholds
price_quantiles = df['unit_price'].quantile([0.25, 0.5, 0.75]).values
print(f"Price Thresholds: 25th percentile=${price_quantiles[0]:.2f}, "
      f"50th percentile=${price_quantiles[1]:.2f}, "
      f"75th percentile=${price_quantiles[2]:.2f}")

# Create price segments
def price_segment(price):
    if price <= price_quantiles[0]:
        return 'Low Price'
    elif price <= price_quantiles[1]:
        return 'Medium-Low Price'
    elif price <= price_quantiles[2]:
        return 'Medium-High Price'
    else:
        return 'High Price'

df['price_segment'] = df['unit_price'].apply(price_segment)

# Analyze performance by price segment
segment_analysis = df.groupby('price_segment').agg({
    'sales': ['mean', 'std', 'count'],
    'profit_margin': ['mean', 'std'],
    'discount_amount': 'mean',
    'unit_price': 'mean'
}).round(3)

segment_analysis.columns = ['_'.join(col).strip() for col in segment_analysis.columns]
print("Performance by Price Segment:")
print(segment_analysis)

# Visualize threshold analysis
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# Sales by Price Segment
segment_sales = df.groupby('price_segment')['sales'].mean()
segment_sales.plot(kind='bar', ax=axes[0], color='lightblue')
axes[0].set_title('Average Sales by Price Segment')
axes[0].set_ylabel('Average Sales ($)')
axes[0].tick_params(axis='x', rotation=45)

# Profit Margin by Price Segment
segment_profit = df.groupby('price_segment')['profit_margin'].mean()
segment_profit.plot(kind='bar', ax=axes[1], color='lightgreen')
axes[1].set_title('Average Profit Margin by Price Segment')
axes[1].set_ylabel('Profit Margin')
axes[1].tick_params(axis='x', rotation=45)

# Discount Impact by Price Segment
df.boxplot(column='profit_margin', by='price_segment', ax=axes[2])
axes[2].set_title('Profit Margin Distribution by Price Segment')
axes[2].set_xlabel('Price Segment')
axes[2].set_ylabel('Profit Margin')

plt.tight_layout()
plt.show()

# ========== 5. HYPOTHESIS TESTING SUMMARY ==========
print("\n=== HYPOTHESIS TESTING SUMMARY ===")
print("Testing: 'Higher unit prices drive increased sales, but potentially at expense of profit margin'")
print("\nKey Findings:")
print(f"1. Unit Price-Sales Correlation: {corr_matrix.loc['unit_price', 'sales']:.3f}")
print(f"2. Unit Price-Profit Margin Correlation: {corr_matrix.loc['unit_price', 'profit_margin']:.3f}")
print(f"3. Discount-Profit Margin Correlation: {corr_matrix.loc['discount_amount', 'profit_margin']:.3f}")
print(f"4. Regression Model R²: {r2:.3f}")

# Statistical significance test
from scipy.stats import pearsonr
price_sales_corr, price_sales_p = pearsonr(df['unit_price'], df['sales'])
price_margin_corr, price_margin_p = pearsonr(df['unit_price'], df['profit_margin'])
discount_margin_corr, discount_margin_p = pearsonr(df['discount_amount'], df['profit_margin'])

print(f"\nStatistical Significance (p-values):")
print(f"Unit Price vs Sales: p = {price_sales_p:.4f}")
print(f"Unit Price vs Profit Margin: p = {price_margin_p:.4f}")
print(f"Discount vs Profit Margin: p = {discount_margin_p:.4f}")

# Hypothesis conclusion
if price_sales_p < 0.05 and price_sales_corr > 0:
    sales_conclusion = "SUPPORTED: Higher unit prices significantly drive increased sales"
else:
    sales_conclusion = "NOT SUPPORTED: No significant positive relationship between unit price and sales"

if discount_margin_p < 0.05 and discount_margin_corr < 0:
    margin_conclusion = "SUPPORTED: Discounts significantly reduce profit margins"
else:
    margin_conclusion = "NOT SUPPORTED: No significant negative impact of discounts on profit margins"

print(f"\nHypothesis Conclusion:")
print(f"- Sales Component: {sales_conclusion}")
print(f"- Profit Margin Component: {margin_conclusion}")
```

### From Sales:
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import f_oneway
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("Set2")

# ========== 1. ANOVA ANALYSIS ==========
print("=== ANOVA ANALYSIS ===")

# ANOVA for Sales across Categories
category_groups_sales = [group['sales'].values for name, group in df.groupby('category')]
f_stat_cat_sales, p_val_cat_sales = f_oneway(*category_groups_sales)

# ANOVA for Profit across Categories
category_groups_profit = [group['profit'].values for name, group in df.groupby('category')]
f_stat_cat_profit, p_val_cat_profit = f_oneway(*category_groups_profit)

# ANOVA for Sales across Subcategories
subcategory_groups_sales = [group['sales'].values for name, group in df.groupby('subcategory')]
f_stat_subcat_sales, p_val_subcat_sales = f_oneway(*subcategory_groups_sales)

# ANOVA for Profit across Subcategories
subcategory_groups_profit = [group['profit'].values for name, group in df.groupby('subcategory')]
f_stat_subcat_profit, p_val_subcat_profit = f_oneway(*subcategory_groups_profit)

print("ANOVA Results:")
print(f"Categories - Sales: F={f_stat_cat_sales:.2f}, p={p_val_cat_sales:.6f}")
print(f"Categories - Profit: F={f_stat_cat_profit:.2f}, p={p_val_cat_profit:.6f}")
print(f"Subcategories - Sales: F={f_stat_subcat_sales:.2f}, p={p_val_subcat_sales:.6f}")
print(f"Subcategories - Profit: F={f_stat_subcat_profit:.2f}, p={p_val_subcat_profit:.6f}")

# ========== 2. CATEGORY PERFORMANCE OVERVIEW ==========
print("\n=== CATEGORY PERFORMANCE OVERVIEW ===")

# Category level analysis
category_performance = df.groupby('category').agg({
    'sales': ['sum', 'mean', 'count'],
    'profit': ['sum', 'mean'],
    'customer_avg_order_value': 'mean',
    'customer_frequency': 'mean',
    'discount_amount': 'mean'
}).round(2)

category_performance.columns = ['_'.join(col).strip() for col in category_performance.columns]
print("Category Performance Summary:")
print(category_performance)

# Visualize category performance
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Total Sales by Category
total_sales = df.groupby('category')['sales'].sum().sort_values(ascending=False)
total_sales.plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Total Sales by Category')
axes[0,0].set_ylabel('Total Sales ($)')
axes[0,0].tick_params(axis='x', rotation=45)

# Total Profit by Category
total_profit = df.groupby('category')['profit'].sum().sort_values(ascending=False)
total_profit.plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Total Profit by Category')
axes[0,1].set_ylabel('Total Profit ($)')
axes[0,1].tick_params(axis='x', rotation=45)

# Average Order Value by Category
avg_order_value = df.groupby('category')['customer_avg_order_value'].mean().sort_values(ascending=False)
avg_order_value.plot(kind='bar', ax=axes[1,0], color='lightgreen')
axes[1,0].set_title('Average Order Value by Category')
axes[1,0].set_ylabel('Avg Order Value ($)')
axes[1,0].tick_params(axis='x', rotation=45)

# Profit Margin by Category
profit_margin = df.groupby('category')['profit_margin'].mean().sort_values(ascending=False)
profit_margin.plot(kind='bar', ax=axes[1,1], color='gold')
axes[1,1].set_title('Average Profit Margin by Category')
axes[1,1].set_ylabel('Profit Margin')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# ========== 3. DEEP DIVE INTO SUBCATEGORIES ==========
print("\n=== SUBCATEGORY DEEP DIVE ===")

# Subcategory performance analysis
subcategory_performance = df.groupby(['category', 'subcategory']).agg({
    'sales': ['sum', 'mean', 'count'],
    'profit': ['sum', 'mean'],
    'customer_avg_order_value': 'mean',
    'customer_frequency': 'mean',
    'discount_amount': 'mean',
    'profit_margin': 'mean'
}).round(2)

subcategory_performance.columns = ['_'.join(col).strip() for col in subcategory_performance.columns]

# Top and Bottom performers
top_subcategories_sales = subcategory_performance.nlargest(10, 'sales_sum')
bottom_subcategories_sales = subcategory_performance.nsmallest(10, 'sales_sum')
top_subcategories_profit = subcategory_performance.nlargest(10, 'profit_sum')

print("TOP 10 SUBCATEGORIES BY SALES:")
print(top_subcategories_sales[['sales_sum', 'sales_mean', 'profit_sum', 'profit_margin_mean']])

print("\nBOTTOM 10 SUBCATEGORIES BY SALES:")
print(bottom_subcategories_sales[['sales_sum', 'sales_mean', 'profit_sum', 'profit_margin_mean']])

# Visualize top subcategories
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Top 15 subcategories by sales
top_15_sales = df.groupby('subcategory')['sales'].sum().nlargest(15)
top_15_sales.plot(kind='barh', ax=axes[0,0], color='steelblue')
axes[0,0].set_title('Top 15 Subcategories by Total Sales')
axes[0,0].set_xlabel('Total Sales ($)')

# Top 15 subcategories by profit
top_15_profit = df.groupby('subcategory')['profit'].sum().nlargest(15)
top_15_profit.plot(kind='barh', ax=axes[0,1], color='darkseagreen')
axes[0,1].set_title('Top 15 Subcategories by Total Profit')
axes[0,1].set_xlabel('Total Profit ($)')

# Average Order Value by top subcategories
top_subcats = top_15_sales.index
aov_top_subcats = df[df['subcategory'].isin(top_subcats)].groupby('subcategory')['customer_avg_order_value'].mean().sort_values(ascending=False)
aov_top_subcats.plot(kind='barh', ax=axes[1,0], color='mediumpurple')
axes[1,0].set_title('Avg Order Value - Top Subcategories')
axes[1,0].set_xlabel('Avg Order Value ($)')

# Profit Margin by top subcategories
margin_top_subcats = df[df['subcategory'].isin(top_subcats)].groupby('subcategory')['profit_margin'].mean().sort_values(ascending=False)
margin_top_subcats.plot(kind='barh', ax=axes[1,1], color='orange')
axes[1,1].set_title('Profit Margin - Top Subcategories')
axes[1,1].set_xlabel('Profit Margin')

plt.tight_layout()
plt.show()

# ========== 4. MARKET BASKET ANALYSIS ==========
print("\n=== MARKET BASKET ANALYSIS ===")

# Create transaction-subcategory matrix
basket_analysis = df.groupby(['order_id', 'subcategory'])['quantity'].sum().unstack(fill_value=0)
basket_analysis = (basket_analysis > 0).astype(int)  # Convert to binary

# Calculate subcategory co-occurrence
subcategory_pairs = list(combinations(basket_analysis.columns, 2))
cooccurrence_results = []

for subcat1, subcat2 in subcategory_pairs[:50]:  # Limit to top 50 pairs for performance
    # Calculate support, confidence, and lift
    support_subcat1 = basket_analysis[subcat1].sum() / len(basket_analysis)
    support_subcat2 = basket_analysis[subcat2].sum() / len(basket_analysis)
    support_both = ((basket_analysis[subcat1] == 1) & (basket_analysis[subcat2] == 1)).sum() / len(basket_analysis)

    if support_both > 0:
        confidence_1_to_2 = support_both / support_subcat1 if support_subcat1 > 0 else 0
        lift = support_both / (support_subcat1 * support_subcat2) if (support_subcat1 * support_subcat2) > 0 else 0

        cooccurrence_results.append({
            'subcategory_1': subcat1,
            'subcategory_2': subcat2,
            'support': support_both,
            'confidence': confidence_1_to_2,
            'lift': lift
        })

# Convert to DataFrame and show top associations
market_basket_df = pd.DataFrame(cooccurrence_results)
if not market_basket_df.empty:
    top_associations = market_basket_df.nlargest(15, 'lift')
    print("TOP SUBCATEGORY ASSOCIATIONS (by Lift):")
    print(top_associations[['subcategory_1', 'subcategory_2', 'support', 'confidence', 'lift']].round(3))

# ========== 5. PRODUCT LIFECYCLE ANALYSIS ==========
print("\n=== PRODUCT LIFECYCLE ANALYSIS ===")

# Analyze trends over time for top subcategories
top_10_subcats = df.groupby('subcategory')['sales'].sum().nlargest(10).index

# Monthly trends for top subcategories
monthly_trends = df[df['subcategory'].isin(top_10_subcats)].groupby(['order_year', 'order_month', 'subcategory'])['sales'].sum().reset_index()
monthly_trends['year_month'] = monthly_trends['order_year'].astype(str) + '-' + monthly_trends['order_month'].astype(str).str.zfill(2)

# Visualize lifecycle trends
fig, axes = plt.subplots(2, 1, figsize=(16, 12))

# Plot trends for each top subcategory
pivot_trends = monthly_trends.pivot_table(index='year_month', columns='subcategory', values='sales', fill_value=0)
pivot_trends.plot(ax=axes[0], linewidth=2)
axes[0].set_title('Sales Trends Over Time - Top 10 Subcategories')
axes[0].set_ylabel('Monthly Sales ($)')
axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
axes[0].tick_params(axis='x', rotation=45)

# Growth rate analysis
growth_rates = []
for subcat in top_10_subcats:
    subcat_data = pivot_trends[subcat]
    if len(subcat_data) > 1:
        # Calculate percentage change from first to last period
        first_val = subcat_data.iloc[0] if subcat_data.iloc[0] > 0 else 1
        last_val = subcat_data.iloc[-1]
        growth_rate = ((last_val - first_val) / first_val) * 100
        growth_rates.append({'subcategory': subcat, 'growth_rate': growth_rate})

growth_df = pd.DataFrame(growth_rates).sort_values('growth_rate', ascending=False)
growth_df.set_index('subcategory')['growth_rate'].plot(kind='barh', ax=axes[1], color='teal')
axes[1].set_title('Growth Rate: First vs Last Period - Top Subcategories')
axes[1].set_xlabel('Growth Rate (%)')

plt.tight_layout()
plt.show()

if not growth_df.empty:
    print("SUBCATEGORY GROWTH RATES (First vs Last Period):")
    print(growth_df.round(2))

# ========== 6. HYPOTHESIS TESTING SUMMARY ==========
print("\n=== HYPOTHESIS TESTING SUMMARY ===")
print("Testing: 'Specific product categories and subcategories outperform others in driving overall revenue and profit'")

# Determine statistical significance
alpha = 0.05
categories_significant = p_val_cat_sales < alpha and p_val_cat_profit < alpha
subcategories_significant = p_val_subcat_sales < alpha and p_val_subcat_profit < alpha

print(f"\nStatistical Results:")
print(f"Categories show significant differences: {'YES' if categories_significant else 'NO'}")
print(f"Subcategories show significant differences: {'YES' if subcategories_significant else 'NO'}")

# Performance insights
print(f"\nKey Performance Insights:")
print(f"1. Highest Revenue Category: {total_sales.index[0]} (${total_sales.iloc[0]:,.0f})")
print(f"2. Highest Profit Category: {total_profit.index[0]} (${total_profit.iloc[0]:,.0f})")
print(f"3. Best Profit Margin Category: {profit_margin.index[0]} ({profit_margin.iloc[0]:.3f})")

if not top_15_sales.empty:
    print(f"4. Top Revenue Subcategory: {top_15_sales.index[0]} (${top_15_sales.iloc[0]:,.0f})")
if not top_15_profit.empty:
    print(f"5. Top Profit Subcategory: {top_15_profit.index[0]} (${top_15_profit.iloc[0]:,.0f})")

# Final hypothesis conclusion
if categories_significant and subcategories_significant:
    conclusion = "HYPOTHESIS SUPPORTED: Significant performance differences exist across categories and subcategories"
elif categories_significant or subcategories_significant:
    conclusion = "HYPOTHESIS PARTIALLY SUPPORTED: Significant differences exist at one level"
else:
    conclusion = "HYPOTHESIS NOT SUPPORTED: No significant performance differences detected"

print(f"\nFinal Conclusion: {conclusion}")

# Actionable recommendations
print(f"\nActionable Recommendations:")
print(f"1. Focus investment on top-performing categories: {', '.join(total_sales.head(3).index)}")
print(f"2. Investigate underperforming categories for improvement opportunities")
print(f"3. Leverage market basket insights for cross-selling strategies")
print(f"4. Monitor lifecycle trends to identify categories needing revitalization")
```

### From Sales:
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2_contingency
from operator import attrgetter
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("viridis")

# ========== 1. RFM SEGMENT OVERVIEW ==========
print("=== RFM SEGMENT PERFORMANCE OVERVIEW ===")

# Basic statistics by RFM segment
rfm_performance = df.groupby('customer_rfm_segment').agg({
    'sales': ['sum', 'mean', 'count', 'std'],
    'profit': ['sum', 'mean'],
    'customer_monetary_value': 'mean',
    'customer_frequency': 'mean',
    'customer_avg_order_value': 'mean',
    'customer_recency': 'mean'
}).round(2)

rfm_performance.columns = ['_'.join(col).strip() for col in rfm_performance.columns]
print("RFM Segment Performance:")
print(rfm_performance)

# Calculate contribution percentages
total_sales = df['sales'].sum()
total_orders = len(df)
segment_contribution = df.groupby('customer_rfm_segment').agg({
    'sales': 'sum',
    'order_id': 'count'
}).round(2)

segment_contribution['sales_percentage'] = (segment_contribution['sales'] / total_sales * 100).round(2)
segment_contribution['order_percentage'] = (segment_contribution['order_id'] / total_orders * 100).round(2)
segment_contribution['sales_per_order'] = (segment_contribution['sales'] / segment_contribution['order_id']).round(2)

print("\nSegment Contribution Analysis:")
print(segment_contribution)

# Visualize RFM performance
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Total Sales by RFM Segment
segment_sales = df.groupby('customer_rfm_segment')['sales'].sum().sort_values(ascending=False)
segment_sales.plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Total Sales by RFM Segment')
axes[0,0].set_ylabel('Total Sales ($)')
axes[0,0].tick_params(axis='x', rotation=45)

# Average Sales per Order by RFM Segment
avg_sales = df.groupby('customer_rfm_segment')['sales'].mean().sort_values(ascending=False)
avg_sales.plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Average Sales per Order by RFM Segment')
axes[0,1].set_ylabel('Average Sales ($)')
axes[0,1].tick_params(axis='x', rotation=45)

# Customer Count by RFM Segment
customer_count = df.groupby('customer_rfm_segment')['customer'].nunique().sort_values(ascending=False)
customer_count.plot(kind='bar', ax=axes[1,0], color='lightgreen')
axes[1,0].set_title('Number of Customers by RFM Segment')
axes[1,0].set_ylabel('Customer Count')
axes[1,0].tick_params(axis='x', rotation=45)

# Sales Distribution by RFM Segment (Box Plot)
df.boxplot(column='sales', by='customer_rfm_segment', ax=axes[1,1])
axes[1,1].set_title('Sales Distribution by RFM Segment')
axes[1,1].set_xlabel('RFM Segment')
axes[1,1].set_ylabel('Sales ($)')

plt.tight_layout()
plt.show()

# ========== 2. CHAMPION vs HIGH-SALES PERIOD ANALYSIS ==========
print("\n=== CHAMPION vs HIGH-SALES PERIOD ANALYSIS ===")

# Analyze relationship between RFM segments and sales performance categories
contingency_table = pd.crosstab(df['customer_rfm_segment'], df['sales_performance_category'])
print("Contingency Table: RFM Segment vs Sales Performance Category")
print(contingency_table)

# Chi-square test for association
chi2, p_value, dof, expected = chi2_contingency(contingency_table)
print(f"\nChi-square test results:")
print(f"Chi-square statistic: {chi2:.4f}")
print(f"P-value: {p_value:.6f}")
print(f"Degrees of freedom: {dof}")

# Calculate percentages within each RFM segment
contingency_pct = pd.crosstab(df['customer_rfm_segment'], df['sales_performance_category'], normalize='index') * 100
print("\nPercentage Distribution within each RFM Segment:")
print(contingency_pct.round(2))

# Visualize the relationship
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Stacked bar chart
contingency_pct.plot(kind='bar', stacked=True, ax=axes[0])
axes[0].set_title('Sales Performance Category Distribution by RFM Segment')
axes[0].set_ylabel('Percentage (%)')
axes[0].tick_params(axis='x', rotation=45)
axes[0].legend(title='Sales Performance', bbox_to_anchor=(1.05, 1), loc='upper left')

# Heatmap of contingency table
sns.heatmap(contingency_table, annot=True, fmt='d', cmap='Blues', ax=axes[1])
axes[1].set_title('Orders Count: RFM Segment vs Sales Performance')
axes[1].set_xlabel('Sales Performance Category')
axes[1].set_ylabel('RFM Segment')

plt.tight_layout()
plt.show()

# Focus on Champions in high-sales periods
if 'Champions' in df['customer_rfm_segment'].values:
    champions_high_sales = df[(df['customer_rfm_segment'] == 'Champions') &
                             (df['sales_performance_category'] == 'High')]['sales'].sum()
    total_high_sales = df[df['sales_performance_category'] == 'High']['sales'].sum()
    champions_contribution_high = (champions_high_sales / total_high_sales * 100) if total_high_sales > 0 else 0

    print(f"\nChampion Customer Analysis in High-Sales Periods:")
    print(f"Champions' contribution to high-sales periods: {champions_contribution_high:.2f}%")
    print(f"Champions' share of total customers: {(customer_count.get('Champions', 0) / df['customer'].nunique() * 100):.2f}%")

# ========== 3. COHORT ANALYSIS ==========
print("\n=== COHORT ANALYSIS ===")

# Create monthly cohorts for Champion customers
if 'Champions' in df['customer_rfm_segment'].values:
    champions_data = df[df['customer_rfm_segment'] == 'Champions'].copy()

    # Convert order_date to datetime if not already
    champions_data['order_date'] = pd.to_datetime(champions_data['order_date'], errors='coerce')
    champions_data['order_period'] = champions_data['order_date'].dt.to_period('M')

    # Group by customer and find their first order period
    champions_data['first_order_period'] = champions_data.groupby('customer')['order_date'].transform('min').dt.to_period('M')

    # Calculate period number (months since first order)
    period_diff = champions_data['order_period'] - champions_data['first_order_period']
    champions_data['period_number'] = period_diff.apply(lambda x: x.n)

    # Create cohort table
    cohort_data = champions_data.groupby(['first_order_period', 'period_number'])['sales'].agg(['sum', 'count']).reset_index()
    cohort_table_sales = cohort_data.pivot_table(index='first_order_period',
                                                 columns='period_number',
                                                 values='sum',
                                                 fill_value=0)

    cohort_table_count = cohort_data.pivot_table(index='first_order_period',
                                                columns='period_number',
                                                values='count',
                                                fill_value=0)

    # Show first few periods of cohort analysis
    print("Champion Customer Cohort Analysis - Sales ($)")
    print("(Rows: First Order Period, Columns: Months Since First Order)")
    print(cohort_table_sales.iloc[:6, :6].round(0))

    # Visualize cohort analysis
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Cohort heatmap for sales
    sns.heatmap(cohort_table_sales.iloc[:8, :8], annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[0])
    axes[0].set_title('Champion Cohort Analysis - Sales Amount ($)')
    axes[0].set_xlabel('Period Number (Months since first order)')
    axes[0].set_ylabel('First Order Period')

    # Monthly sales trend for Champions vs Others
    monthly_champions = champions_data.groupby('order_period')['sales'].sum()
    monthly_others = df[df['customer_rfm_segment'] != 'Champions'].groupby(
        pd.to_datetime(df[df['customer_rfm_segment'] != 'Champions']['order_date']).dt.to_period('M')
    )['sales'].sum()

    # Align periods and plot
    all_periods = sorted(set(monthly_champions.index) | set(monthly_others.index))
    champions_aligned = [monthly_champions.get(period, 0) for period in all_periods]
    others_aligned = [monthly_others.get(period, 0) for period in all_periods]

    axes[1].plot(range(len(all_periods)), champions_aligned, marker='o', label='Champions', linewidth=2)
    axes[1].plot(range(len(all_periods)), others_aligned, marker='s', label='Others', linewidth=2)
    axes[1].set_title('Monthly Sales: Champions vs Others')
    axes[1].set_xlabel('Time Period')
    axes[1].set_ylabel('Sales ($)')
    axes[1].legend()
    axes[1].tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.show()

# ========== 4. CUSTOMER LIFETIME VALUE (CLV) ANALYSIS ==========
print("\n=== CUSTOMER LIFETIME VALUE (CLV) ANALYSIS ===")

# Calculate CLV metrics by RFM segment
clv_analysis = df.groupby(['customer_rfm_segment', 'customer']).agg({
    'sales': 'sum',
    'profit': 'sum',
    'order_id': 'count',
    'customer_frequency': 'first',
    'customer_monetary_value': 'first',
    'customer_avg_order_value': 'first',
    'customer_recency': 'first'
}).reset_index()

# Calculate CLV metrics by segment
clv_by_segment = clv_analysis.groupby('customer_rfm_segment').agg({
    'sales': ['mean', 'median', 'std'],
    'profit': ['mean', 'median'],
    'order_id': 'mean',
    'customer_frequency': 'mean',
    'customer_monetary_value': 'mean',
    'customer_avg_order_value': 'mean'
}).round(2)

clv_by_segment.columns = ['_'.join(col).strip() for col in clv_by_segment.columns]
print("Customer Lifetime Value Analysis by RFM Segment:")
print(clv_by_segment)

# Simple CLV calculation (Total Sales per Customer)
clv_simple = clv_analysis.groupby('customer_rfm_segment')['sales'].agg(['mean', 'median', 'std']).round(2)
clv_simple.columns = ['CLV_Mean', 'CLV_Median', 'CLV_StdDev']
print(f"\nSimplified CLV (Total Sales per Customer):")
print(clv_simple)

# Visualize CLV analysis
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# CLV distribution by segment
df.boxplot(column='customer_monetary_value', by='customer_rfm_segment', ax=axes[0,0])
axes[0,0].set_title('Customer Monetary Value by RFM Segment')
axes[0,0].set_ylabel('Customer Monetary Value ($)')

# Average order frequency by segment
freq_by_segment = df.groupby('customer_rfm_segment')['customer_frequency'].mean().sort_values(ascending=False)
freq_by_segment.plot(kind='bar', ax=axes[0,1], color='orange')
axes[0,1].set_title('Average Order Frequency by RFM Segment')
axes[0,1].set_ylabel('Average Frequency')
axes[0,1].tick_params(axis='x', rotation=45)

# Average order value by segment
aov_by_segment = df.groupby('customer_rfm_segment')['customer_avg_order_value'].mean().sort_values(ascending=False)
aov_by_segment.plot(kind='bar', ax=axes[1,0], color='purple')
axes[1,0].set_title('Average Order Value by RFM Segment')
axes[1,0].set_ylabel('Average Order Value ($)')
axes[1,0].tick_params(axis='x', rotation=45)

# Recency by segment (lower is better)
recency_by_segment = df.groupby('customer_rfm_segment')['customer_recency'].mean().sort_values(ascending=True)
recency_by_segment.plot(kind='bar', ax=axes[1,1], color='teal')
axes[1,1].set_title('Average Recency by RFM Segment (Lower is Better)')
axes[1,1].set_ylabel('Days Since Last Order')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# ========== 5. HYPOTHESIS TESTING SUMMARY ==========
print("\n=== HYPOTHESIS TESTING SUMMARY ===")
print("Testing: 'Champion customers contribute disproportionately to high-sales periods'")

# Statistical tests
alpha = 0.05
association_significant = p_value < alpha

print(f"\nStatistical Results:")
print(f"Chi-square test p-value: {p_value:.6f}")
print(f"Association is statistically significant: {'YES' if association_significant else 'NO'}")

# Calculate key metrics
if 'Champions' in segment_contribution.index:
    champions_sales_share = segment_contribution.loc['Champions', 'sales_percentage']
    champions_order_share = segment_contribution.loc['Champions', 'order_percentage']
    champions_disproportionate = champions_sales_share > champions_order_share

    print(f"\nKey Findings:")
    print(f"Champions' share of total sales: {champions_sales_share}%")
    print(f"Champions' share of total orders: {champions_order_share}%")
    print(f"Disproportionate contribution: {'YES' if champions_disproportionate else 'NO'}")
    print(f"Sales per order ratio: {champions_sales_share/champions_order_share:.2f}x")

    # CLV comparison
    if 'Champions' in clv_simple.index:
        champions_clv = clv_simple.loc['Champions', 'CLV_Mean']
        avg_clv = clv_simple['CLV_Mean'].mean()
        clv_premium = (champions_clv / avg_clv - 1) * 100
        print(f"Champions CLV vs Average: +{clv_premium:.1f}%")

# Final hypothesis conclusion
if association_significant and champions_disproportionate:
    conclusion = "HYPOTHESIS SUPPORTED: Champions contribute disproportionately to high-sales periods"
elif champions_disproportionate:
    conclusion = "HYPOTHESIS PARTIALLY SUPPORTED: Champions show disproportionate contribution but weak statistical association"
else:
    conclusion = "HYPOTHESIS NOT SUPPORTED: No evidence of disproportionate contribution from Champions"

print(f"\nFinal Conclusion: {conclusion}")

# Investment recommendations
print(f"\nInvestment Recommendations:")
if 'Champions' in clv_simple.index:
    print(f"1. Champions generate {clv_simple.loc['Champions', 'CLV_Mean']:.0f}$ average CLV")
    print(f"2. Focus retention efforts on Champion segment")
    print(f"3. Develop programs to move other segments toward Champion status")
    print(f"4. Monitor Champion cohort behavior for early churn signals")
else:
    print("1. Analyze customer segmentation to identify high-value segments")
    print("2. Develop targeted retention strategies for top-performing customers")

from operator import attrgetter  # Add this import at the top if missing
```

### From Sales:
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import f_oneway
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("husl")

# ========== 1. SEASONALITY STATISTICAL TESTING ==========
print("=== SEASONALITY STATISTICAL TESTING ===")

# ANOVA tests for quarterly and monthly differences
quarterly_groups = [group['sales'].values for name, group in df.groupby('order_quarter')]
monthly_groups = [group['sales'].values for name, group in df.groupby('order_month')]

f_stat_quarter, p_val_quarter = f_oneway(*quarterly_groups)
f_stat_month, p_val_month = f_oneway(*monthly_groups)

print(f"ANOVA Results:")
print(f"Quarterly Sales Differences: F={f_stat_quarter:.2f}, p={p_val_quarter:.6f}")
print(f"Monthly Sales Differences: F={f_stat_month:.2f}, p={p_val_month:.6f}")

# Quarter performance analysis
quarterly_performance = df.groupby('order_quarter').agg({
    'sales': ['sum', 'mean', 'count', 'std'],
    'profit': ['sum', 'mean'],
    'order_total': 'mean'
}).round(2)

quarterly_performance.columns = ['_'.join(col).strip() for col in quarterly_performance.columns]
print(f"\nQuarterly Performance Summary:")
print(quarterly_performance)

# Monthly performance analysis
monthly_performance = df.groupby('order_month').agg({
    'sales': ['sum', 'mean', 'count'],
    'profit': ['sum', 'mean']
}).round(2)

monthly_performance.columns = ['_'.join(col).strip() for col in monthly_performance.columns]
print(f"\nMonthly Performance Summary:")
print(monthly_performance)

# ========== 2. SEASONAL PATTERNS VISUALIZATION ==========
print("\n=== SEASONAL PATTERNS VISUALIZATION ===")

fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Quarterly Sales
quarterly_sales = df.groupby('order_quarter')['sales'].sum()
quarterly_sales.plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Total Sales by Quarter')
axes[0,0].set_ylabel('Total Sales ($)')
axes[0,0].set_xlabel('Quarter')
axes[0,0].tick_params(axis='x', rotation=0)

# Add percentage labels on bars
for i, v in enumerate(quarterly_sales.values):
    pct = v / quarterly_sales.sum() * 100
    axes[0,0].text(i, v + quarterly_sales.max() * 0.01, f'{pct:.1f}%',
                   ha='center', va='bottom', fontweight='bold')

# Monthly Sales
monthly_sales = df.groupby('order_month')['sales'].sum()
monthly_sales.plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Total Sales by Month')
axes[0,1].set_ylabel('Total Sales ($)')
axes[0,1].set_xlabel('Month')
axes[0,1].tick_params(axis='x', rotation=45)

# Highlight November and December
nov_sales = monthly_sales.get(11, 0)
dec_sales = monthly_sales.get(12, 0)
q4_total = quarterly_sales.get(4, 0)
print(f"\nKey Seasonal Insights:")
print(f"Q4 sales: ${q4_total:,.0f} ({q4_total/quarterly_sales.sum()*100:.1f}% of annual)")
if nov_sales > 0:
    print(f"November sales: ${nov_sales:,.0f} ({nov_sales/monthly_sales.sum()*100:.1f}% of annual)")
if dec_sales > 0:
    print(f"December sales: ${dec_sales:,.0f} ({dec_sales/monthly_sales.sum()*100:.1f}% of annual)")

# Day of week analysis
dow_sales = df.groupby('order_day_of_week')['sales'].mean()
dow_sales.plot(kind='bar', ax=axes[1,0], color='lightgreen')
axes[1,0].set_title('Average Sales by Day of Week')
axes[1,0].set_ylabel('Average Sales ($)')
axes[1,0].set_xlabel('Day of Week')
axes[1,0].tick_params(axis='x', rotation=45)

# Year-over-year comparison (if multiple years)
if df['order_year'].nunique() > 1:
    yearly_monthly = df.groupby(['order_year', 'order_month'])['sales'].sum().unstack(level=0, fill_value=0)
    yearly_monthly.plot(kind='line', ax=axes[1,1], marker='o')
    axes[1,1].set_title('Monthly Sales Trends by Year')
    axes[1,1].set_ylabel('Total Sales ($)')
    axes[1,1].set_xlabel('Month')
    axes[1,1].legend(title='Year')
else:
    # If single year, show monthly trend
    monthly_sales.plot(kind='line', ax=axes[1,1], marker='o', color='purple')
    axes[1,1].set_title('Monthly Sales Trend')
    axes[1,1].set_ylabel('Total Sales ($)')
    axes[1,1].set_xlabel('Month')

plt.tight_layout()
plt.show()

# ========== 3. TIME SERIES DECOMPOSITION ==========
print("\n=== TIME SERIES DECOMPOSITION ===")

# Prepare time series data
df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
ts_data = df.groupby(df['order_date'].dt.to_period('M'))['sales'].sum()

# Ensure we have enough data points for decomposition
if len(ts_data) >= 12:
    # Convert to regular frequency if needed
    ts_data = ts_data.asfreq('M', fill_value=0)

    # Perform seasonal decomposition
    decomposition = seasonal_decompose(ts_data, model='additive', period=12)

    # Plot decomposition
    fig, axes = plt.subplots(4, 1, figsize=(16, 12))

    decomposition.observed.plot(ax=axes[0], title='Original Time Series')
    axes[0].set_ylabel('Sales ($)')

    decomposition.trend.plot(ax=axes[1], title='Trend Component')
    axes[1].set_ylabel('Trend ($)')

    decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component')
    axes[2].set_ylabel('Seasonal ($)')

    decomposition.resid.plot(ax=axes[3], title='Residual Component')
    axes[3].set_ylabel('Residual ($)')
    axes[3].set_xlabel('Time Period')

    plt.tight_layout()
    plt.show()

    # Quantify seasonality impact
    seasonal_variance = np.var(decomposition.seasonal.dropna())
    total_variance = np.var(decomposition.observed.dropna())
    seasonality_percentage = (seasonal_variance / total_variance) * 100

    print(f"Seasonality Analysis:")
    print(f"Seasonal component variance: {seasonal_variance:.0f}")
    print(f"Total variance: {total_variance:.0f}")
    print(f"Seasonality explains {seasonality_percentage:.1f}% of total variance")

    # Identify peak seasonal months
    seasonal_by_month = decomposition.seasonal.groupby(decomposition.seasonal.index.month).mean()
    peak_month = seasonal_by_month.idxmax()
    peak_value = seasonal_by_month.max()
    low_month = seasonal_by_month.idxmin()
    low_value = seasonal_by_month.min()

    print(f"Peak seasonal month: {peak_month} (${peak_value:.0f} above trend)")
    print(f"Lowest seasonal month: {low_month} (${low_value:.0f} below trend)")

else:
    print("Insufficient data points for seasonal decomposition (need at least 12 periods)")

# ========== 4. EVENT ANALYSIS ==========
print("\n=== EVENT ANALYSIS ===")

# Define key events/holidays that might impact sales
holiday_months = {
    1: 'New Year',
    2: 'Valentine\'s Day',
    3: 'Spring Break',
    5: 'Mother\'s Day',
    6: 'Father\'s Day',
    7: 'Summer',
    9: 'Back to School',
    10: 'Halloween',
    11: 'Thanksgiving/Black Friday',
    12: 'Christmas/Holiday Season'
}

# Analyze sales around key events
event_analysis = []
for month, event in holiday_months.items():
    if month in monthly_performance.index:
        month_sales = monthly_performance.loc[month, 'sales_sum']
        avg_sales = monthly_performance['sales_sum'].mean()
        impact = ((month_sales - avg_sales) / avg_sales) * 100
        event_analysis.append({
            'Month': month,
            'Event': event,
            'Sales': month_sales,
            'Impact_vs_Average': impact
        })

event_df = pd.DataFrame(event_analysis).sort_values('Impact_vs_Average', ascending=False)
print("Event Impact Analysis (% above/below average monthly sales):")
print(event_df.round(2))

# Visualize event impact
fig, ax = plt.subplots(1, 1, figsize=(14, 8))

bars = ax.bar(event_df['Month'], event_df['Impact_vs_Average'],
              color=['red' if x < 0 else 'green' for x in event_df['Impact_vs_Average']])
ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)
ax.set_title('Sales Impact by Month vs Annual Average')
ax.set_xlabel('Month')
ax.set_ylabel('% Above/Below Average')
ax.set_xticks(event_df['Month'])
ax.set_xticklabels([f"{month}\n({event})" for month, event in zip(event_df['Month'], event_df['Event'])],
                   rotation=45, ha='right')

# Add value labels on bars
for bar, value in zip(bars, event_df['Impact_vs_Average']):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -3),
            f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top')

plt.tight_layout()
plt.show()

# ========== 5. FORECASTING MODEL ==========
print("\n=== FORECASTING MODEL ===")

if len(ts_data) >= 12:
    # Split data for training and testing
    train_size = int(len(ts_data) * 0.8)
    train_data = ts_data[:train_size]
    test_data = ts_data[train_size:]

    # Fit Exponential Smoothing model with seasonality
    model = ExponentialSmoothing(train_data, seasonal='add', seasonal_periods=12)
    fitted_model = model.fit()

    # Generate forecasts
    forecast_periods = len(test_data) if len(test_data) > 0 else 6
    forecast = fitted_model.forecast(steps=forecast_periods)

    # Calculate forecast accuracy if we have test data
    if len(test_data) > 0:
        mape = np.mean(np.abs((test_data - forecast[:len(test_data)]) / test_data)) * 100
        rmse = np.sqrt(np.mean((test_data - forecast[:len(test_data)]) ** 2))
        print(f"Forecast Accuracy:")
        print(f"MAPE: {mape:.2f}%")
        print(f"RMSE: ${rmse:.0f}")

    # Visualize forecasting results
    fig, ax = plt.subplots(1, 1, figsize=(14, 8))

    # Plot historical data
    train_data.plot(ax=ax, label='Training Data', color='blue')
    if len(test_data) > 0:
        test_data.plot(ax=ax, label='Actual Test Data', color='green')

    # Plot forecast
    forecast_index = pd.period_range(start=train_data.index[-1] + 1, periods=forecast_periods, freq='M')
    forecast_series = pd.Series(forecast, index=forecast_index)
    forecast_series.plot(ax=ax, label='Forecast', color='red', linestyle='--')

    # Add confidence intervals (approximate)
    forecast_std = fitted_model.fittedvalues.std()
    upper_bound = forecast + 1.96 * forecast_std
    lower_bound = forecast - 1.96 * forecast_std

    ax.fill_between(forecast_index, lower_bound, upper_bound, alpha=0.2, color='red', label='95% Confidence Interval')

    ax.set_title('Sales Forecasting with Seasonality')
    ax.set_ylabel('Sales ($)')
    ax.set_xlabel('Time Period')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print(f"\nForecast for next {forecast_periods} periods:")
    for i, (period, value) in enumerate(zip(forecast_index, forecast)):
        print(f"{period}: ${value:,.0f}")

else:
    print("Insufficient data for forecasting model")

# ========== 6. HYPOTHESIS TESTING SUMMARY ==========
print("\n=== HYPOTHESIS TESTING SUMMARY ===")
print("Testing: 'Seasonality significantly influences sales performance, with Q4 and November being particularly strong'")

# Statistical significance
alpha = 0.05
quarterly_significant = p_val_quarter < alpha
monthly_significant = p_val_month < alpha

print(f"\nStatistical Results:")
print(f"Quarterly differences are significant: {'YES' if quarterly_significant else 'NO'} (p={p_val_quarter:.6f})")
print(f"Monthly differences are significant: {'YES' if monthly_significant else 'NO'} (p={p_val_month:.6f})")

# Q4 and November analysis
q4_performance = quarterly_sales.get(4, 0) / quarterly_sales.sum() * 100
q4_above_average = q4_performance > 25  # 25% would be equal share

nov_performance = monthly_sales.get(11, 0) / monthly_sales.sum() * 100 if 11 in monthly_sales.index else 0
nov_above_average = nov_performance > 8.33  # 8.33% would be equal share (1/12)

print(f"\nSeasonal Performance:")
print(f"Q4 accounts for {q4_performance:.1f}% of annual sales ({'Above' if q4_above_average else 'Below'} average)")
if nov_performance > 0:
    print(f"November accounts for {nov_performance:.1f}% of annual sales ({'Above' if nov_above_average else 'Below'} average)")

# Final hypothesis conclusion
seasonality_supported = quarterly_significant or monthly_significant
q4_supported = q4_above_average
nov_supported = nov_above_average

if seasonality_supported and q4_supported and nov_supported:
    conclusion = "HYPOTHESIS FULLY SUPPORTED: Significant seasonality with strong Q4 and November performance"
elif seasonality_supported and (q4_supported or nov_supported):
    conclusion = "HYPOTHESIS PARTIALLY SUPPORTED: Significant seasonality with some Q4/November strength"
elif seasonality_supported:
    conclusion = "HYPOTHESIS PARTIALLY SUPPORTED: Significant seasonality but Q4/November not exceptionally strong"
else:
    conclusion = "HYPOTHESIS NOT SUPPORTED: No significant seasonal patterns detected"

print(f"\nFinal Conclusion: {conclusion}")

# Strategic recommendations
print(f"\nStrategic Recommendations:")
if seasonality_supported:
    if len(ts_data) >= 12:
        print(f"1. Seasonality explains {seasonality_percentage:.1f}% of sales variance - plan inventory accordingly")
    print(f"2. Optimize marketing spend for peak months: {', '.join([str(m) for m in event_df.head(3)['Month'].values])}")
    print(f"3. Prepare for demand fluctuations in low months: {', '.join([str(m) for m in event_df.tail(2)['Month'].values])}")
    print(f"4. Use forecasting model for inventory planning and capacity management")
    if q4_supported:
        print(f"5. Maximize Q4 opportunities - increase inventory and marketing for holiday season")
else:
    print("1. Sales patterns appear relatively stable - focus on other growth drivers")
    print("2. Consider creating seasonal campaigns to introduce artificial seasonality")
```

### From Sales:
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, f_oneway
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("RdYlBu_r")

# ========== 1. DISCOUNT CORRELATION ANALYSIS ==========
print("=== DISCOUNT CORRELATION ANALYSIS ===")

# Calculate key correlations
discount_vars = ['discount', 'discount_amount', 'sales', 'profit', 'profit_margin', 'quantity']
correlation_matrix = df[discount_vars].corr()

print("Correlation Matrix:")
print(correlation_matrix.round(3))

# Statistical significance of key correlations
discount_sales_corr, discount_sales_p = pearsonr(df['discount'], df['sales'])
discount_profit_corr, discount_profit_p = pearsonr(df['discount'], df['profit_margin'])
discount_quantity_corr, discount_quantity_p = pearsonr(df['discount'], df['quantity'])

print(f"\nKey Correlations with Statistical Significance:")
print(f"Discount vs Sales: r={discount_sales_corr:.3f}, p={discount_sales_p:.6f}")
print(f"Discount vs Profit Margin: r={discount_profit_corr:.3f}, p={discount_profit_p:.6f}")
print(f"Discount vs Quantity: r={discount_quantity_corr:.3f}, p={discount_quantity_p:.6f}")

# Visualize correlations
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Correlation heatmap
sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0,
            square=True, fmt='.3f', ax=axes[0,0])
axes[0,0].set_title('Discount-Related Correlations')

# Discount vs Sales scatter
axes[0,1].scatter(df['discount'], df['sales'], alpha=0.5, s=20)
axes[0,1].set_xlabel('Discount Rate')
axes[0,1].set_ylabel('Sales ($)')
axes[0,1].set_title(f'Discount vs Sales (r={discount_sales_corr:.3f})')

# Discount vs Profit Margin scatter
axes[1,0].scatter(df['discount'], df['profit_margin'], alpha=0.5, s=20, color='red')
axes[1,0].set_xlabel('Discount Rate')
axes[1,0].set_ylabel('Profit Margin')
axes[1,0].set_title(f'Discount vs Profit Margin (r={discount_profit_corr:.3f})')

# Discount vs Quantity scatter
axes[1,1].scatter(df['discount'], df['quantity'], alpha=0.5, s=20, color='green')
axes[1,1].set_xlabel('Discount Rate')
axes[1,1].set_ylabel('Quantity')
axes[1,1].set_title(f'Discount vs Quantity (r={discount_quantity_corr:.3f})')

plt.tight_layout()
plt.show()

# ========== 2. DISCOUNT EFFECTIVENESS ANALYSIS ==========
print("\n=== DISCOUNT EFFECTIVENESS ANALYSIS ===")

# Analyze by discount category
if 'discount_category' in df.columns:
    discount_effectiveness = df.groupby('discount_category').agg({
        'sales': ['sum', 'mean', 'count'],
        'profit': ['sum', 'mean'],
        'profit_margin': 'mean',
        'quantity': ['sum', 'mean'],
        'discount': 'mean',
        'discount_amount': 'mean'
    }).round(3)

    discount_effectiveness.columns = ['_'.join(col).strip() for col in discount_effectiveness.columns]
    print("Discount Category Effectiveness:")
    print(discount_effectiveness)

    # Calculate ROI metrics
    discount_effectiveness['profit_per_sale'] = discount_effectiveness['profit_sum'] / discount_effectiveness['sales_count']
    discount_effectiveness['sales_per_discount_dollar'] = discount_effectiveness['sales_sum'] / discount_effectiveness['discount_amount_mean']

    print(f"\nROI Metrics by Discount Category:")
    print(discount_effectiveness[['profit_per_sale', 'sales_per_discount_dollar']].round(2))

# Create discount bins for analysis
df['discount_bin'] = pd.cut(df['discount'],
                           bins=[0, 0.05, 0.15, 0.25, 0.50, 1.0],
                           labels=['0-5%', '5-15%', '15-25%', '25-50%', '50%+'],
                           include_lowest=True)

discount_bin_analysis = df.groupby('discount_bin').agg({
    'sales': ['sum', 'mean', 'count'],
    'profit': ['sum', 'mean'],
    'profit_margin': 'mean',
    'quantity': ['sum', 'mean'],
    'discount': 'mean'
}).round(3)

discount_bin_analysis.columns = ['_'.join(col).strip() for col in discount_bin_analysis.columns]
print(f"\nDiscount Bin Analysis:")
print(discount_bin_analysis)

# Visualize discount effectiveness
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Sales by discount bin
total_sales_by_bin = df.groupby('discount_bin')['sales'].sum()
total_sales_by_bin.plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Total Sales by Discount Range')
axes[0,0].set_ylabel('Total Sales ($)')
axes[0,0].tick_params(axis='x', rotation=45)

# Profit margin by discount bin
avg_margin_by_bin = df.groupby('discount_bin')['profit_margin'].mean()
avg_margin_by_bin.plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Average Profit Margin by Discount Range')
axes[0,1].set_ylabel('Profit Margin')
axes[0,1].tick_params(axis='x', rotation=45)

# Order count by discount bin
order_count_by_bin = df.groupby('discount_bin').size()
order_count_by_bin.plot(kind='bar', ax=axes[1,0], color='lightgreen')
axes[1,0].set_title('Order Count by Discount Range')
axes[1,0].set_ylabel('Number of Orders')
axes[1,0].tick_params(axis='x', rotation=45)

# Profit vs Sales efficiency by discount bin
efficiency_data = df.groupby('discount_bin').agg({'sales': 'sum', 'profit': 'sum'})
efficiency_data['profit_ratio'] = efficiency_data['profit'] / efficiency_data['sales']
efficiency_data['profit_ratio'].plot(kind='bar', ax=axes[1,1], color='gold')
axes[1,1].set_title('Profit Efficiency by Discount Range')
axes[1,1].set_ylabel('Profit/Sales Ratio')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# Find optimal discount range
optimal_analysis = df.groupby('discount_bin').agg({
    'profit': 'sum',
    'sales': 'sum',
    'quantity': 'sum'
})
optimal_analysis['total_profit_margin'] = optimal_analysis['profit'] / optimal_analysis['sales']
optimal_bin = optimal_analysis['total_profit_margin'].idxmax()
print(f"\nOptimal discount range for profit margin: {optimal_bin}")
print(f"Profit margin at optimal range: {optimal_analysis.loc[optimal_bin, 'total_profit_margin']:.3f}")

# ========== 3. PRICE ELASTICITY ANALYSIS ==========
print("\n=== PRICE ELASTICITY ANALYSIS ===")

# Calculate price elasticity by category
elasticity_results = []

for category in df['category'].unique()[:5]:  # Limit to top 5 categories for performance
    cat_data = df[df['category'] == category].copy()

    if len(cat_data) > 50:  # Ensure sufficient data
        # Calculate effective price (unit_price * (1 - discount))
        cat_data['effective_price'] = cat_data['unit_price'] * (1 - cat_data['discount'])

        # Remove outliers for cleaner analysis
        price_q1, price_q3 = cat_data['effective_price'].quantile([0.1, 0.9])
        quantity_q1, quantity_q3 = cat_data['quantity'].quantile([0.1, 0.9])

        clean_data = cat_data[
            (cat_data['effective_price'] >= price_q1) &
            (cat_data['effective_price'] <= price_q3) &
            (cat_data['quantity'] >= quantity_q1) &
            (cat_data['quantity'] <= quantity_q3)
        ]

        if len(clean_data) > 30:
            # Log transformation for elasticity calculation
            clean_data['log_price'] = np.log(clean_data['effective_price'])
            clean_data['log_quantity'] = np.log(clean_data['quantity'])

            # Linear regression: log(quantity) = a + b*log(price)
            # Price elasticity = coefficient b
            X = clean_data[['log_price']].values
            y = clean_data['log_quantity'].values

            model = LinearRegression()
            model.fit(X, y)

            elasticity = model.coef_[0]
            r2_score = model.score(X, y)

            elasticity_results.append({
                'Category': category,
                'Price_Elasticity': elasticity,
                'R_Squared': r2_score,
                'Sample_Size': len(clean_data),
                'Avg_Price': clean_data['effective_price'].mean(),
                'Avg_Quantity': clean_data['quantity'].mean()
            })

elasticity_df = pd.DataFrame(elasticity_results).sort_values('Price_Elasticity')
print("Price Elasticity by Category:")
print(elasticity_df.round(3))

# Visualize price elasticity
if not elasticity_df.empty:
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Price elasticity by category
    elasticity_df.set_index('Category')['Price_Elasticity'].plot(kind='barh', ax=axes[0], color='teal')
    axes[0].set_title('Price Elasticity by Category')
    axes[0].set_xlabel('Price Elasticity (% change in quantity / % change in price)')
    axes[0].axvline(x=-1, color='red', linestyle='--', alpha=0.7, label='Unit Elastic')
    axes[0].legend()

    # R-squared values (model fit quality)
    elasticity_df.set_index('Category')['R_Squared'].plot(kind='barh', ax=axes[1], color='orange')
    axes[1].set_title('Model Fit Quality (R²)')
    axes[1].set_xlabel('R² Score')

    plt.tight_layout()
    plt.show()

# ========== 4. OPTIMAL DISCOUNT STRATEGY ==========
print("\n=== OPTIMAL DISCOUNT STRATEGY ===")

# Polynomial regression to find optimal discount level
discount_clean = df[(df['discount'] >= 0) & (df['discount'] <= 0.6)].copy()

if len(discount_clean) > 100:
    # Prepare data for polynomial regression
    X = discount_clean[['discount']].values
    y_profit = discount_clean['profit'].values
    y_sales = discount_clean['sales'].values

    # Fit polynomial models (degree 2)
    poly_features = PolynomialFeatures(degree=2)
    X_poly = poly_features.fit_transform(X)

    # Profit model
    profit_model = LinearRegression()
    profit_model.fit(X_poly, y_profit)

    # Sales model
    sales_model = LinearRegression()
    sales_model.fit(X_poly, y_sales)

    # Generate predictions for visualization
    discount_range = np.linspace(0, 0.6, 100).reshape(-1, 1)
    discount_range_poly = poly_features.transform(discount_range)

    profit_pred = profit_model.predict(discount_range_poly)
    sales_pred = sales_model.predict(discount_range_poly)

    # Find optimal discount for profit
    optimal_discount_idx = np.argmax(profit_pred)
    optimal_discount = discount_range[optimal_discount_idx, 0]
    optimal_profit = profit_pred[optimal_discount_idx]

    print(f"Optimal discount rate for maximum profit: {optimal_discount:.1%}")
    print(f"Expected profit at optimal rate: ${optimal_profit:.2f}")

    # Visualize optimal strategy
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Profit vs discount curve
    axes[0].scatter(discount_clean['discount'], discount_clean['profit'], alpha=0.3, s=10, label='Actual Data')
    axes[0].plot(discount_range, profit_pred, 'r-', linewidth=2, label='Profit Curve')
    axes[0].axvline(x=optimal_discount, color='green', linestyle='--',
                   label=f'Optimal Discount ({optimal_discount:.1%})')
    axes[0].set_xlabel('Discount Rate')
    axes[0].set_ylabel('Profit ($)')
    axes[0].set_title('Profit Optimization Curve')
    axes[0].legend()

    # Sales vs discount curve
    axes[1].scatter(discount_clean['discount'], discount_clean['sales'], alpha=0.3, s=10, label='Actual Data')
    axes[1].plot(discount_range, sales_pred, 'b-', linewidth=2, label='Sales Curve')
    axes[1].axvline(x=optimal_discount, color='green', linestyle='--',
                   label=f'Optimal Discount ({optimal_discount:.1%})')
    axes[1].set_xlabel('Discount Rate')
    axes[1].set_ylabel('Sales ($)')
    axes[1].set_title('Sales Response Curve')
    axes[1].legend()

    plt.tight_layout()
    plt.show()

# ========== 5. DISCOUNT IMPACT BY CATEGORY ==========
print("\n=== DISCOUNT IMPACT BY CATEGORY ===")

category_discount_impact = []

for category in df['category'].unique():
    cat_data = df[df['category'] == category]

    discounted = cat_data[cat_data['is_discounted'] == True]
    non_discounted = cat_data[cat_data['is_discounted'] == False]

    if len(discounted) > 10 and len(non_discounted) > 10:
        # Compare metrics
        discount_impact = {
            'Category': category,
            'Discounted_Avg_Sales': discounted['sales'].mean(),
            'Non_Discounted_Avg_Sales': non_discounted['sales'].mean(),
            'Discounted_Avg_Margin': discounted['profit_margin'].mean(),
            'Non_Discounted_Avg_Margin': non_discounted['profit_margin'].mean(),
            'Discounted_Orders': len(discounted),
            'Non_Discounted_Orders': len(non_discounted)
        }

        # Calculate percentage differences
        discount_impact['Sales_Lift'] = ((discounted['sales'].mean() - non_discounted['sales'].mean()) /
                                       non_discounted['sales'].mean()) * 100
        discount_impact['Margin_Impact'] = ((discounted['profit_margin'].mean() - non_discounted['profit_margin'].mean()) /
                                          non_discounted['profit_margin'].mean()) * 100

        category_discount_impact.append(discount_impact)

impact_df = pd.DataFrame(category_discount_impact)
if not impact_df.empty:
    print("Discount Impact by Category:")
    print(impact_df[['Category', 'Sales_Lift', 'Margin_Impact']].round(2))

    # Visualize category impact
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))

    scatter = ax.scatter(impact_df['Sales_Lift'], impact_df['Margin_Impact'],
                        s=100, alpha=0.7, c=range(len(impact_df)), cmap='viridis')

    # Add category labels
    for i, row in impact_df.iterrows():
        ax.annotate(row['Category'], (row['Sales_Lift'], row['Margin_Impact']),
                   xytext=(5, 5), textcoords='offset points', fontsize=9)

    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)
    ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)
    ax.set_xlabel('Sales Lift from Discounts (%)')
    ax.set_ylabel('Profit Margin Impact (%)')
    ax.set_title('Discount Impact: Sales Lift vs Margin Impact by Category')
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# ========== 6. HYPOTHESIS TESTING SUMMARY ==========
print("\n=== HYPOTHESIS TESTING SUMMARY ===")
print("Testing: 'Discounts boost sales volume but potentially reduce overall profit if not managed strategically'")

# Statistical significance tests
alpha = 0.05
sales_correlation_significant = discount_sales_p < alpha
margin_correlation_significant = discount_profit_p < alpha

print(f"\nStatistical Results:")
print(f"Discount-Sales correlation significant: {'YES' if sales_correlation_significant else 'NO'} (p={discount_sales_p:.6f})")
print(f"Discount-Margin correlation significant: {'YES' if margin_correlation_significant else 'NO'} (p={discount_profit_p:.6f})")

print(f"\nKey Findings:")
print(f"1. Discount vs Sales correlation: {discount_sales_corr:.3f} ({'Positive' if discount_sales_corr > 0 else 'Negative'})")
print(f"2. Discount vs Profit Margin correlation: {discount_profit_corr:.3f} ({'Positive' if discount_profit_corr > 0 else 'Negative'})")

if not elasticity_df.empty:
    avg_elasticity = elasticity_df['Price_Elasticity'].mean()
    print(f"3. Average price elasticity: {avg_elasticity:.3f} ({'Elastic' if avg_elasticity < -1 else 'Inelastic'})")

if 'optimal_discount' in locals():
    print(f"4. Optimal discount rate for profit: {optimal_discount:.1%}")

# Final hypothesis conclusion
sales_boost_confirmed = sales_correlation_significant and discount_sales_corr > 0
margin_reduction_confirmed = margin_correlation_significant and discount_profit_corr < 0
complex_relationship = sales_boost_confirmed and margin_reduction_confirmed

if complex_relationship:
    conclusion = "HYPOTHESIS FULLY SUPPORTED: Discounts boost sales but reduce profit margins - strategic management needed"
elif sales_boost_confirmed:
    conclusion = "HYPOTHESIS PARTIALLY SUPPORTED: Discounts boost sales, margin impact unclear"
elif margin_reduction_confirmed:
    conclusion = "HYPOTHESIS PARTIALLY SUPPORTED: Discounts reduce margins, sales impact unclear"
else:
    conclusion = "HYPOTHESIS NOT SUPPORTED: No clear evidence of expected discount effects"

print(f"\nFinal Conclusion: {conclusion}")

# Strategic recommendations
print(f"\nStrategic Recommendations:")
if complex_relationship:
    print(f"1. Implement targeted discount strategy - avoid blanket discounting")
    if 'optimal_discount' in locals():
        print(f"2. Target discount rate around {optimal_discount:.1%} for optimal profit")
    print(f"3. Focus discounts on price-elastic categories")
    print(f"4. Monitor profit margins closely when running promotions")
    print(f"5. Consider value-based pricing instead of discount-heavy strategies")
else:
    print("1. Review discount strategy - current approach may not be optimal")
    print("2. Test different discount levels to find effective ranges")
    print("3. Analyze customer response to discounts more carefully")
```

### From Sales:
```python
import json
from matplotlib.patches import Wedge
```

### From Sales:
```python
# Visualization Functions
def calculate_feature_importance(model_data, r_squared=0.75):
    """
    Calculate feature importance based on absolute weights
    """
    feature_importance = {}

    for feature in model_data:
        feature_name = feature["processed_input"]

        # Skip intercept for importance calculation
        if feature_name == "__INTERCEPT__":
            continue

        if feature["weight"] is not None:
            # Numerical feature
            importance = abs(float(feature["weight"]))
            feature_importance[feature_name] = importance
        else:
            # Categorical feature - sum absolute weights of all categories
            total_importance = sum(abs(float(cat["weight"])) for cat in feature["category_weights"])
            feature_importance[feature_name] = total_importance

    # Calculate relative importance
    total_importance = sum(feature_importance.values())

    # Scale by R-squared to get explained variance portions
    explained_variance_portions = {}
    for feature, importance in feature_importance.items():
        explained_variance_portions[feature] = (importance / total_importance) * r_squared

    # Add unexplained variance
    explained_variance_portions["Unexplained Variance"] = 1 - r_squared

    return explained_variance_portions

def create_feature_importance_pie_chart(feature_importance, title="Linear Regression Feature Importance"):
    """
    Create a pie chart showing feature importance with percentages
    """
    # Sort features by importance (excluding unexplained variance)
    explained_features = {k: v for k, v in feature_importance.items() if k != "Unexplained Variance"}
    sorted_features = dict(sorted(explained_features.items(), key=lambda x: x[1], reverse=True))

    # Add unexplained variance at the end
    if "Unexplained Variance" in feature_importance:
        sorted_features["Unexplained Variance"] = feature_importance["Unexplained Variance"]

    # Prepare data for plotting
    labels = list(sorted_features.keys())
    sizes = list(sorted_features.values())
    percentages = [size * 100 for size in sizes]

    # Create color palette with maximum contrast between adjacent colors
    def generate_contrasting_colors(n_colors):
        """Generate colors that are maximally different from adjacent colors"""
        if n_colors <= 1:
            return ['#1f77b4']

        # Define 50 base colors with maximum contrast between adjacent colors
        base_colors = [
            '#d62728',  # Red
            '#2ca02c',  # Green
            '#1f77b4',  # Blue
            '#ff7f0e',  # Orange
            '#9467bd',  # Purple
            '#17becf',  # Cyan
            '#bcbd22',  # Olive
            '#e377c2',  # Pink
            '#8c564b',  # Brown
            '#00ff00',  # Bright Green
            '#000080',  # Navy Blue
            '#ffff00',  # Yellow
            '#800080',  # Dark Purple
            '#00ffff',  # Bright Cyan
            '#ff0000',  # Bright Red
            '#008000',  # Dark Green
            '#0000ff',  # Bright Blue
            '#ffa500',  # Dark Orange
            '#4b0082',  # Indigo
            '#40e0d0',  # Turquoise
            '#adff2f',  # Green Yellow
            '#dc143c',  # Crimson
            '#00008b',  # Dark Blue
            '#ffd700',  # Gold
            '#8b008b',  # Dark Magenta
            '#20b2aa',  # Light Sea Green
            '#ff6347',  # Tomato
            '#32cd32',  # Lime Green
            '#4169e1',  # Royal Blue
            '#ff8c00',  # Dark Orange
            '#ba55d3',  # Medium Orchid
            '#48d1cc',  # Medium Turquoise
            '#9acd32',  # Yellow Green
            '#cd5c5c',  # Indian Red
            '#6495ed',  # Cornflower Blue
            '#daa520',  # Goldenrod
            '#9932cc',  # Dark Orchid
            '#5f9ea0',  # Cadet Blue
            '#98fb98',  # Pale Green
            '#f08080',  # Light Coral
            '#87ceeb',  # Sky Blue
            '#f0e68c',  # Khaki
            '#dda0dd',  # Plum
            '#66cdaa',  # Medium Aquamarine
            '#fa8072',  # Salmon
            '#90ee90',  # Light Green
            '#add8e6',  # Light Blue
            '#f5deb3',  # Wheat
            '#d8bfd8',  # Thistle
            '#afeeee',  # Pale Turquoise
        ]

        if n_colors <= len(base_colors):
            # For smaller lists, manually order for maximum contrast
            contrast_order = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
                            20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,
                            38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
            return [base_colors[contrast_order[i]] for i in range(n_colors)]
        else:
            # For larger lists, use HSV with strategic spacing
            colors = []
            hue_step = 1.0 / n_colors
            for i in range(n_colors):
                # Distribute hues evenly, but skip similar regions
                hue = (i * hue_step * 0.9) % 1.0  # 0.9 to avoid wrap-around
                # Convert HSV to RGB
                import colorsys
                rgb = colorsys.hsv_to_rgb(hue, 0.8, 0.9)
                colors.append(rgb)
            return colors

    colors = generate_contrasting_colors(len(labels)-1)
    colors.append('lightgray')  # Gray for unexplained variance

    # Create the plot
    fig, ax = plt.subplots(figsize=(12, 8))

    # Create pie chart
    wedges, texts, autotexts = ax.pie(sizes, labels=None, colors=colors, autopct='%1.1f%%',
                                     startangle=90, textprops={'fontsize': 12})

    # Customize the percentage text
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_weight('normal')
        autotext.set_fontsize(12)

    # Create legend with feature names and percentages
    legend_labels = [f'{label}: {pct:.1f}%' for label, pct in zip(labels, percentages)]
    ax.legend(wedges, legend_labels, title="Features", loc="center left",
              bbox_to_anchor=(1, 0, 0.5, 1), fontsize=10)

    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

    plt.tight_layout()
    return fig, ax

def create_feature_importance_bar_chart(feature_importance, title="Feature Importance (Explained Variance)"):
    """
    Create a horizontal bar chart showing feature importance
    """
    # Exclude unexplained variance for bar chart
    explained_features = {k: v for k, v in feature_importance.items() if k != "Unexplained Variance"}
    sorted_features = dict(sorted(explained_features.items(), key=lambda x: x[1], reverse=True))

    labels = list(sorted_features.keys())
    values = [v * 100 for v in sorted_features.values()]  # Convert to percentages

    # Create the plot
    fig, ax = plt.subplots(figsize=(10, 8))

    # Create horizontal bar chart
    bars = ax.barh(labels, values, color=plt.cm.viridis(np.linspace(0, 1, len(labels))))

    # Add value labels on bars
    for i, (bar, value) in enumerate(zip(bars, values)):
        ax.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,
                f'{value:.1f}%', ha='left', va='center', fontweight='bold')

    ax.set_xlabel('Explained Variance (%)', fontsize=12, fontweight='bold')
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.grid(axis='x', alpha=0.3)

    # Adjust layout to prevent label cutoff
    plt.tight_layout()
    return fig, ax
```

### From Sales:
```python
model_data = [{
  "processed_input": "quantity",
  "weight": "22.417094583810286",
  "category_weights": []
}, {
  "processed_input": "discount",
  "weight": "-25.220323707648994",
  "category_weights": []
}, {
  "processed_input": "unit_price",
  "weight": "1.582082515201507",
  "category_weights": []
}, {
  "processed_input": "order_processing_time",
  "weight": "-0.540936267301673",
  "category_weights": []
}, {
  "processed_input": "is_discounted",
  "weight": "-3.9095532733320724",
  "category_weights": []
}, {
  "processed_input": "discount_category",
  "weight": None,
  "category_weights": [{
    "category": "Medium Discount",
    "weight": "10.301133531570493"
  }, {
    "category": "High Discount",
    "weight": "11.172213045798252"
  }, {
    "category": "No Discount",
    "weight": "15.73282928657332"
  }, {
    "category": "Low Discount",
    "weight": "87.904538042881114"
  }]
}, {
  "processed_input": "order_size_category",
  "weight": None,
  "category_weights": [{
    "category": "Small",
    "weight": "-33.872003756376039"
  }, {
    "category": "Medium",
    "weight": "17.103543102135"
  }, {
    "category": "Large",
    "weight": "84.983123002654025"
  }, {
    "category": "Bulk",
    "weight": "170.77090635205121"
  }]
}, {
  "processed_input": "price_segment",
  "weight": None,
  "category_weights": [{
    "category": "Low Price",
    "weight": "-36.030001329702372"
  }, {
    "category": "Medium-Low Price",
    "weight": "-38.927794970929341"
  }, {
    "category": "Medium-High Price",
    "weight": "-22.011482053777677"
  }, {
    "category": "High Price",
    "weight": "153.50051677592592"
  }]
}, {
  "processed_input": "segment",
  "weight": None,
  "category_weights": [{
    "category": "Consumer",
    "weight": "11.392876756017047"
  }, {
    "category": "Corporate",
    "weight": "15.603052999213055"
  }, {
    "category": "Home Office",
    "weight": "17.207545064837866"
  }]
}, {
  "processed_input": "category",
  "weight": None,
  "category_weights": [{
    "category": "Office Supplies",
    "weight": "-4.5378245034123434"
  }, {
    "category": "Furniture",
    "weight": "28.094455358457644"
  }, {
    "category": "Technology",
    "weight": "58.13732290465574"
  }]
}, {
  "processed_input": "subcategory",
  "weight": None,
  "category_weights": [{
    "category": "Fasteners",
    "weight": "-33.724062581504406"
  }, {
    "category": "Art",
    "weight": "-25.728911644219995"
  }, {
    "category": "Labels",
    "weight": "-20.986004548471886"
  }, {
    "category": "Envelopes",
    "weight": "-21.99409959330081"
  }, {
    "category": "Furnishings",
    "weight": "-25.805416332233797"
  }, {
    "category": "Paper",
    "weight": "-17.7726948077303"
  }, {
    "category": "Binders",
    "weight": "3.4048852412455437"
  }, {
    "category": "Accessories",
    "weight": "-5.9838444207942789"
  }, {
    "category": "Appliances",
    "weight": "15.526004237772145"
  }, {
    "category": "Supplies",
    "weight": "32.013822935607067"
  }, {
    "category": "Storage",
    "weight": "24.170082241413226"
  }, {
    "category": "Phones",
    "weight": "20.210716192000181"
  }, {
    "category": "Bookcases",
    "weight": "59.661864199509111"
  }, {
    "category": "Chairs",
    "weight": "72.8783325880047"
  }, {
    "category": "Tables",
    "weight": "84.278096440254387"
  }, {
    "category": "Machines",
    "weight": "467.00567777380013"
  }, {
    "category": "Copiers",
    "weight": "564.76306251727544"
  }]
}, {
  "processed_input": "region",
  "weight": None,
  "category_weights": [{
    "category": "West",
    "weight": "11.824149693611517"
  }, {
    "category": "Central",
    "weight": "12.860935412250118"
  }, {
    "category": "East",
    "weight": "14.352135778771302"
  }, {
    "category": "South",
    "weight": "17.575302534604653"
  }]
}, {
  "processed_input": "city",
  "weight": None,
  "category_weights": [{
    "category": "Allentown",
    "weight": "-179.39517939945733"
  }, {
    "category": "Coral Gables",
    "weight": "-161.95899706000085"
  }, {
    "category": "Littleton",
    "weight": "-116.12647797516118"
  }, {
    "category": "Saginaw",
    "weight": "-110.64200297385879"
  }, {
    "category": "Margate",
    "weight": "-94.742896532306276"
  }, {
    "category": "Farmington",
    "weight": "-101.24294249119814"
  }, {
    "category": "Tinley Park",
    "weight": "-83.693924133003037"
  }, {
    "category": "Layton",
    "weight": "-78.1663751316458"
  }, {
    "category": "Lubbock",
    "weight": "-95.1363107383112"
  }, {
    "category": "Modesto",
    "weight": "-90.407644223605573"
  }, {
    "category": "Tuscaloosa",
    "weight": "-85.431653191426221"
  }, {
    "category": "Deer Park",
    "weight": "-69.5097867748774"
  }, {
    "category": "West Jordan",
    "weight": "-73.1266708542484"
  }, {
    "category": "Rapid City",
    "weight": "-85.425224830363533"
  }, {
    "category": "Saint Paul",
    "weight": "-78.087332547207581"
  }, {
    "category": "New Castle",
    "weight": "-60.365329213629835"
  }, {
    "category": "Niagara Falls",
    "weight": "-76.2693347357758"
  }, {
    "category": "Coachella",
    "weight": "-66.36414471711916"
  }, {
    "category": "Summerville",
    "weight": "-61.579290324198425"
  }, {
    "category": "Twin Falls",
    "weight": "-57.673940558530163"
  }, {
    "category": "Encinitas",
    "weight": "-78.5346142847213"
  }, {
    "category": "Glenview",
    "weight": "-78.956727248235993"
  }, {
    "category": "Pompano Beach",
    "weight": "-55.893999062373993"
  }, {
    "category": "Hackensack",
    "weight": "-63.106086465407373"
  }, {
    "category": "Lewiston",
    "weight": "-52.750950323519334"
  }, {
    "category": "Pharr",
    "weight": "-54.21297235623959"
  }, {
    "category": "Broomfield",
    "weight": "-53.607059668717454"
  }, {
    "category": "Coon Rapids",
    "weight": "-87.1534621175085"
  }, {
    "category": "New Bedford",
    "weight": "-49.123188329967384"
  }, {
    "category": "Manhattan",
    "weight": "-86.649371561693286"
  }, {
    "category": "The Colony",
    "weight": "-51.2212476847992"
  }, {
    "category": "Costa Mesa",
    "weight": "-61.110562461308319"
  }, {
    "category": "Saint Cloud",
    "weight": "-48.52380499655645"
  }, {
    "category": "San Angelo",
    "weight": "-60.494696127473652"
  }, {
    "category": "Daytona Beach",
    "weight": "-49.4618182253798"
  }, {
    "category": "Cuyahoga Falls",
    "weight": "-41.267612913824678"
  }, {
    "category": "Waterloo",
    "weight": "-42.594253199576578"
  }, {
    "category": "Bedford",
    "weight": "-45.506962818886009"
  }, {
    "category": "Port Arthur",
    "weight": "-61.691742398304392"
  }, {
    "category": "Palatine",
    "weight": "-53.002578414478833"
  }, {
    "category": "East Point",
    "weight": "-51.461424618152037"
  }, {
    "category": "Woonsocket",
    "weight": "-43.1075836172376"
  }, {
    "category": "Greenwood",
    "weight": "-50.749440069092628"
  }, {
    "category": "La Crosse",
    "weight": "-48.977416373409838"
  }, {
    "category": "Clovis",
    "weight": "-41.057847116589222"
  }, {
    "category": "Vineland",
    "weight": "-46.294988406274229"
  }, {
    "category": "Helena",
    "weight": "-42.134569570193776"
  }, {
    "category": "Cincinnati",
    "weight": "-51.246763837963229"
  }, {
    "category": "Laguna Niguel",
    "weight": "-43.080637315314576"
  }, {
    "category": "Marysville",
    "weight": "-53.270163366816988"
  }, {
    "category": "Olathe",
    "weight": "-81.160043364487564"
  }, {
    "category": "Missouri City",
    "weight": "-39.333381378868417"
  }, {
    "category": "Orange",
    "weight": "-37.94356029683761"
  }, {
    "category": "Greenville",
    "weight": "-81.844874601401187"
  }, {
    "category": "Rio Rancho",
    "weight": "-67.64640407547661"
  }, {
    "category": "College Station",
    "weight": "-47.501947679671943"
  }, {
    "category": "Bryan",
    "weight": "-33.764600185692949"
  }, {
    "category": "Holyoke",
    "weight": "-76.029027562942872"
  }, {
    "category": "Hillsboro",
    "weight": "-32.184257174527922"
  }, {
    "category": "Woodland",
    "weight": "-43.35463227396049"
  }, {
    "category": "Grapevine",
    "weight": "-37.240566662170629"
  }, {
    "category": "Shelton",
    "weight": "-35.271493111523966"
  }, {
    "category": "Lodi",
    "weight": "-38.378726531651921"
  }, {
    "category": "Rockville",
    "weight": "-42.720340477641976"
  }, {
    "category": "Abilene",
    "weight": "-24.638922521948643"
  }, {
    "category": "Saint Louis",
    "weight": "-38.544677772929596"
  }, {
    "category": "Sheboygan",
    "weight": "-23.79401262998686"
  }, {
    "category": "Linden",
    "weight": "-44.714314201184173"
  }, {
    "category": "Allen",
    "weight": "-39.787261716045066"
  }, {
    "category": "Plantation",
    "weight": "-42.873412310874386"
  }, {
    "category": "Mentor",
    "weight": "-28.182659479136039"
  }, {
    "category": "Pensacola",
    "weight": "-26.7096324270225"
  }, {
    "category": "Trenton",
    "weight": "-38.852703592691611"
  }, {
    "category": "Morgan Hill",
    "weight": "-50.2858030666157"
  }, {
    "category": "Rogers",
    "weight": "-33.624912464326968"
  }, {
    "category": "North Charleston",
    "weight": "-22.031808411117186"
  }, {
    "category": "Hot Springs",
    "weight": "-30.575062302979795"
  }, {
    "category": "Norwich",
    "weight": "-25.568446901809242"
  }, {
    "category": "Deltona",
    "weight": "-38.8743658810193"
  }, {
    "category": "Charlottesville",
    "weight": "-28.735072528441464"
  }, {
    "category": "North Miami",
    "weight": "-24.144152394313227"
  }, {
    "category": "Johnson City",
    "weight": "-32.797940306771721"
  }, {
    "category": "Bellevue",
    "weight": "-24.852870525439918"
  }, {
    "category": "Elyria",
    "weight": "-17.154503577378307"
  }, {
    "category": "Edinburg",
    "weight": "-27.693565652116632"
  }, {
    "category": "Gulfport",
    "weight": "-31.734257297283634"
  }, {
    "category": "Rome",
    "weight": "-36.280774663340367"
  }, {
    "category": "Davis",
    "weight": "-26.267280444654578"
  }, {
    "category": "Greeley",
    "weight": "-18.777667424473155"
  }, {
    "category": "Beaumont",
    "weight": "-36.927858314300551"
  }, {
    "category": "Apopka",
    "weight": "-21.948462407778806"
  }, {
    "category": "Palm Coast",
    "weight": "-30.3987142972167"
  }, {
    "category": "Freeport",
    "weight": "-25.708321839843748"
  }, {
    "category": "Durham",
    "weight": "-25.22257423303013"
  }, {
    "category": "Frisco",
    "weight": "-20.425916207265093"
  }, {
    "category": "Rochester Hills",
    "weight": "-34.975666329864779"
  }, {
    "category": "Orlando",
    "weight": "-45.572271767665669"
  }, {
    "category": "Urbandale",
    "weight": "-24.416268529166633"
  }, {
    "category": "Belleville",
    "weight": "-30.423518608808351"
  }, {
    "category": "San Clemente",
    "weight": "-24.421705024571477"
  }, {
    "category": "Utica",
    "weight": "-28.858592127590647"
  }, {
    "category": "Gladstone",
    "weight": "-17.0050924242161"
  }, {
    "category": "Kenner",
    "weight": "-17.64458398973521"
  }, {
    "category": "Frankfort",
    "weight": "-24.8834378654294"
  }, {
    "category": "Altoona",
    "weight": "-19.248965841332179"
  }, {
    "category": "Nashua",
    "weight": "-17.169972074483404"
  }, {
    "category": "Grove City",
    "weight": "-21.776208878911866"
  }, {
    "category": "West Allis",
    "weight": "-34.397020446523939"
  }, {
    "category": "Hialeah",
    "weight": "-32.57160588904722"
  }, {
    "category": "Provo",
    "weight": "-28.334518667616194"
  }, {
    "category": "Murray",
    "weight": "-25.625830240156731"
  }, {
    "category": "Cambridge",
    "weight": "-18.878290788166794"
  }, {
    "category": "Revere",
    "weight": "-30.296725535008505"
  }, {
    "category": "Bristol",
    "weight": "-23.123442268532"
  }, {
    "category": "Evanston",
    "weight": "-31.5391081960186"
  }, {
    "category": "Mount Vernon",
    "weight": "-33.778353231081169"
  }, {
    "category": "Thousand Oaks",
    "weight": "-20.873780449484123"
  }, {
    "category": "San Marcos",
    "weight": "-14.156609902202709"
  }, {
    "category": "Westfield",
    "weight": "-24.528073556522237"
  }, {
    "category": "Springdale",
    "weight": "-11.336744954660098"
  }, {
    "category": "Eagan",
    "weight": "-14.131580327697769"
  }, {
    "category": "Arvada",
    "weight": "-10.529375585799677"
  }, {
    "category": "La Quinta",
    "weight": "-16.214104417806364"
  }, {
    "category": "Coppell",
    "weight": "-18.312833869279707"
  }, {
    "category": "Santa Fe",
    "weight": "-21.720185239850164"
  }, {
    "category": "Draper",
    "weight": "-21.327360817018651"
  }, {
    "category": "Aberdeen",
    "weight": "-14.782058954272985"
  }, {
    "category": "Salinas",
    "weight": "-15.522273619401565"
  }, {
    "category": "Bethlehem",
    "weight": "-23.890793783536473"
  }, {
    "category": "Bayonne",
    "weight": "-20.255479463404036"
  }, {
    "category": "Murfreesboro",
    "weight": "-12.286696051784523"
  }, {
    "category": "Norfolk",
    "weight": "-14.27211150887082"
  }, {
    "category": "Wilson",
    "weight": "-18.917783792898334"
  }, {
    "category": "Bloomington",
    "weight": "-29.2116573114284"
  }, {
    "category": "Delray Beach",
    "weight": "-21.562480411434464"
  }, {
    "category": "Sterling Heights",
    "weight": "-15.052363582983679"
  }, {
    "category": "Macon",
    "weight": "-19.6028219815857"
  }, {
    "category": "Grand Prairie",
    "weight": "-19.392543268699939"
  }, {
    "category": "Grand Rapids",
    "weight": "-22.611471837472017"
  }, {
    "category": "Rock Hill",
    "weight": "-7.4612388529255487"
  }, {
    "category": "New Albany",
    "weight": "-15.343878139059353"
  }, {
    "category": "Covington",
    "weight": "-23.30180332905142"
  }, {
    "category": "Bartlett",
    "weight": "-27.807361984880181"
  }, {
    "category": "Logan",
    "weight": "-16.283326123830609"
  }, {
    "category": "Corpus Christi",
    "weight": "-10.189630916235103"
  }, {
    "category": "Monroe",
    "weight": "-27.330148790258498"
  }, {
    "category": "Visalia",
    "weight": "-24.311020037229472"
  }, {
    "category": "Pembroke Pines",
    "weight": "-29.344785503359265"
  }, {
    "category": "Brownsville",
    "weight": "-26.000110364838616"
  }, {
    "category": "Gresham",
    "weight": "-32.385668810384338"
  }, {
    "category": "Salem",
    "weight": "-20.384586526398913"
  }, {
    "category": "Laredo",
    "weight": "-18.936522438015523"
  }, {
    "category": "Wausau",
    "weight": "-26.5386750727507"
  }, {
    "category": "Tyler",
    "weight": "-10.304073562647876"
  }, {
    "category": "Conroe",
    "weight": "-26.870749024899567"
  }, {
    "category": "Oswego",
    "weight": "-6.90883614792525"
  }, {
    "category": "Vancouver",
    "weight": "-29.01675551526673"
  }, {
    "category": "Peoria",
    "weight": "-17.707125098069657"
  }, {
    "category": "Auburn",
    "weight": "-22.666560465485176"
  }, {
    "category": "Garden City",
    "weight": "-14.291622263709172"
  }, {
    "category": "Danbury",
    "weight": "-4.963061420903129"
  }, {
    "category": "Hendersonville",
    "weight": "-17.491263506069227"
  }, {
    "category": "Port Saint Lucie",
    "weight": "-15.206487298451069"
  }, {
    "category": "Normal",
    "weight": "-61.756211406098657"
  }, {
    "category": "Sanford",
    "weight": "-20.555762771109983"
  }, {
    "category": "Amarillo",
    "weight": "-15.846272703349499"
  }, {
    "category": "Thornton",
    "weight": "-13.608189758881473"
  }, {
    "category": "Cottage Grove",
    "weight": "-19.402265018159913"
  }, {
    "category": "Homestead",
    "weight": "-8.0768097730568353"
  }, {
    "category": "Boca Raton",
    "weight": "-12.035101770571782"
  }, {
    "category": "New Brunswick",
    "weight": "-0.62429843398377294"
  }, {
    "category": "Arlington Heights",
    "weight": "-9.03500845072941"
  }, {
    "category": "Bozeman",
    "weight": "-5.0894869740220479"
  }, {
    "category": "Sandy Springs",
    "weight": "-27.863424146291774"
  }, {
    "category": "Redmond",
    "weight": "-18.002580082658021"
  }, {
    "category": "Mesa",
    "weight": "-25.193107682539413"
  }, {
    "category": "Smyrna",
    "weight": "-22.711967258504952"
  }, {
    "category": "Des Plaines",
    "weight": "-45.6397631701706"
  }, {
    "category": "Spokane",
    "weight": "-42.607193542311379"
  }, {
    "category": "Mission Viejo",
    "weight": "-26.114991396447536"
  }, {
    "category": "Royal Oak",
    "weight": "-2.5002658546789824"
  }, {
    "category": "Port Orange",
    "weight": "1.2077209185701534"
  }, {
    "category": "Quincy",
    "weight": "-12.036823013984508"
  }, {
    "category": "Cary",
    "weight": "-16.090758400444926"
  }, {
    "category": "New Rochelle",
    "weight": "-26.936102180032236"
  }, {
    "category": "Waukesha",
    "weight": "-9.49447542666222"
  }, {
    "category": "Longview",
    "weight": "-4.7351927985650137"
  }, {
    "category": "Malden",
    "weight": "-1.9565616901783738"
  }, {
    "category": "Jupiter",
    "weight": "1.7765475062871676"
  }, {
    "category": "Lansing",
    "weight": "-20.620741559233835"
  }, {
    "category": "Glendale",
    "weight": "-11.93344730977311"
  }, {
    "category": "Reno",
    "weight": "-7.8763430742033993"
  }, {
    "category": "Bowling Green",
    "weight": "-26.254628930533048"
  }, {
    "category": "La Mesa",
    "weight": "-27.743447020989898"
  }, {
    "category": "Chattanooga",
    "weight": "-12.221105656529023"
  }, {
    "category": "Bullhead City",
    "weight": "4.4340445464539826"
  }, {
    "category": "La Porte",
    "weight": "-10.688480306613169"
  }, {
    "category": "Bridgeton",
    "weight": "-5.1296226501314708"
  }, {
    "category": "League City",
    "weight": "-23.198478451486814"
  }, {
    "category": "Loveland",
    "weight": "1.4459037937059804"
  }, {
    "category": "Santa Clara",
    "weight": "-4.1627345534592539"
  }, {
    "category": "Mcallen",
    "weight": "-4.0037845541845272"
  }, {
    "category": "East Orange",
    "weight": "-11.530114462475858"
  }, {
    "category": "Georgetown",
    "weight": "-26.570477746911287"
  }, {
    "category": "Suffolk",
    "weight": "-10.370796552002219"
  }, {
    "category": "West Palm Beach",
    "weight": "-6.1777819583846538"
  }, {
    "category": "Holland",
    "weight": "-7.3634564157984324"
  }, {
    "category": "Superior",
    "weight": "-21.64759866899054"
  }, {
    "category": "Manteca",
    "weight": "-24.771998786710128"
  }, {
    "category": "Bossier City",
    "weight": "5.7823258791031193"
  }, {
    "category": "Dover",
    "weight": "-13.396101396934913"
  }, {
    "category": "Tempe",
    "weight": "-9.5916067791737571"
  }, {
    "category": "Pearland",
    "weight": "3.3659839981888346"
  }, {
    "category": "Las Cruces",
    "weight": "-2.2957200957390818"
  }, {
    "category": "Boynton Beach",
    "weight": "-0.58143971380829917"
  }, {
    "category": "Bakersfield",
    "weight": "-9.3637862552314477"
  }, {
    "category": "Ormond Beach",
    "weight": "1.4384463830193503"
  }, {
    "category": "Mason",
    "weight": "3.3083617646454044"
  }, {
    "category": "Melbourne",
    "weight": "-7.915494208215363"
  }, {
    "category": "Edmonds",
    "weight": "-3.2889719414864267"
  }, {
    "category": "Renton",
    "weight": "-10.011748071042245"
  }, {
    "category": "Billings",
    "weight": "5.1914645740648631"
  }, {
    "category": "Waco",
    "weight": "-2.1734987734357611"
  }, {
    "category": "Irving",
    "weight": "-7.8205650541300251"
  }, {
    "category": "Bolingbrook",
    "weight": "3.5410230479788787"
  }, {
    "category": "Decatur",
    "weight": "-15.351277087182371"
  }, {
    "category": "Lincoln Park",
    "weight": "-13.478643773919911"
  }, {
    "category": "Rochester",
    "weight": "-16.448203454399774"
  }, {
    "category": "Overland Park",
    "weight": "-10.141259008482901"
  }, {
    "category": "Lawrence",
    "weight": "-23.588016679724802"
  }, {
    "category": "Lebanon",
    "weight": "-21.131523331115112"
  }, {
    "category": "Owensboro",
    "weight": "3.1098891195802558"
  }, {
    "category": "Texas City",
    "weight": "-35.318101542050343"
  }, {
    "category": "Rancho Cucamonga",
    "weight": "-1.9464382930015907"
  }, {
    "category": "Portland",
    "weight": "-21.759491933329567"
  }, {
    "category": "Skokie",
    "weight": "-1.4189127602375571"
  }, {
    "category": "Coral Springs",
    "weight": "-8.3332362299363041"
  }, {
    "category": "Haltom City",
    "weight": "-1.1999282390999921"
  }, {
    "category": "Hollywood",
    "weight": "-11.7192725481043"
  }, {
    "category": "Sierra Vista",
    "weight": "7.0736347529900581"
  }, {
    "category": "Garland",
    "weight": "7.3498594957770678"
  }, {
    "category": "Troy",
    "weight": "-8.14807262417122"
  }, {
    "category": "Baytown",
    "weight": "9.50123849685601"
  }, {
    "category": "Paterson",
    "weight": "-8.2441648037097846"
  }, {
    "category": "Scottsdale",
    "weight": "-10.556486025635685"
  }, {
    "category": "Lindenhurst",
    "weight": "2.4238756744736296"
  }, {
    "category": "Sunnyvale",
    "weight": "7.2474311704275589"
  }, {
    "category": "Yucaipa",
    "weight": "1.6987515524951213"
  }, {
    "category": "Mesquite",
    "weight": "11.534626656798537"
  }, {
    "category": "Leominster",
    "weight": "7.6967335108845063"
  }, {
    "category": "Saint Petersburg",
    "weight": "-8.2073718445091846"
  }, {
    "category": "Aurora",
    "weight": "-10.382153279617151"
  }, {
    "category": "York",
    "weight": "1.8259796325487834"
  }, {
    "category": "Gaithersburg",
    "weight": "-20.328097597091215"
  }, {
    "category": "Elkhart",
    "weight": "-0.76477844883828094"
  }, {
    "category": "Escondido",
    "weight": "5.2135513283882329"
  }, {
    "category": "Roseville",
    "weight": "-12.869957011720874"
  }, {
    "category": "Gastonia",
    "weight": "-8.0641078226163856"
  }, {
    "category": "Taylor",
    "weight": "-12.61087145226784"
  }, {
    "category": "Cedar Hill",
    "weight": "3.7168245533114961"
  }, {
    "category": "Sioux Falls",
    "weight": "-5.3030971743719491"
  }, {
    "category": "Ann Arbor",
    "weight": "-23.010080775052373"
  }, {
    "category": "Milford",
    "weight": "-15.425544705186242"
  }, {
    "category": "Akron",
    "weight": "-8.595855799906726"
  }, {
    "category": "Hoover",
    "weight": "-8.47190932625029"
  }, {
    "category": "Warner Robins",
    "weight": "-25.160157413700333"
  }, {
    "category": "Elmhurst",
    "weight": "-0.969733770064753"
  }, {
    "category": "Tamarac",
    "weight": "-4.0653896830858613"
  }, {
    "category": "Caldwell",
    "weight": "-6.9305838911523123"
  }, {
    "category": "Goldsboro",
    "weight": "9.2328737718320362"
  }, {
    "category": "Fresno",
    "weight": "-17.179973524210578"
  }, {
    "category": "Harlingen",
    "weight": "-0.6333678856163778"
  }, {
    "category": "Oceanside",
    "weight": "-12.283640987084009"
  }, {
    "category": "Hamilton",
    "weight": "6.2548139149145978"
  }, {
    "category": "Round Rock",
    "weight": "-19.440229518814188"
  }, {
    "category": "Laurel",
    "weight": "3.6726277534870135"
  }, {
    "category": "Conway",
    "weight": "-34.4556079331835"
  }, {
    "category": "Phoenix",
    "weight": "-8.3858944391031169"
  }, {
    "category": "Marlborough",
    "weight": "2.0220150530409606"
  }, {
    "category": "Kent",
    "weight": "-5.6971662673289165"
  }, {
    "category": "Tigard",
    "weight": "-8.4890338109918879"
  }, {
    "category": "Miramar",
    "weight": "-13.167313589813089"
  }, {
    "category": "Tampa",
    "weight": "-9.651978427337367"
  }, {
    "category": "Little Rock",
    "weight": "0.44455883774390281"
  }, {
    "category": "Fremont",
    "weight": "-6.5887604175742407"
  }, {
    "category": "Dublin",
    "weight": "-2.2385798738107576"
  }, {
    "category": "Grand Island",
    "weight": "17.766860594121198"
  }, {
    "category": "Parker",
    "weight": "-5.1964565348614329"
  }, {
    "category": "Meridian",
    "weight": "8.7104692508655166"
  }, {
    "category": "Waterbury",
    "weight": "-2.2445597523824805"
  }, {
    "category": "Hempstead",
    "weight": "-15.552715163058688"
  }, {
    "category": "Carlsbad",
    "weight": "12.034234780295844"
  }, {
    "category": "Andover",
    "weight": "-8.2548664507144238"
  }, {
    "category": "Jonesboro",
    "weight": "-29.197542933333096"
  }, {
    "category": "Mansfield",
    "weight": "-27.05714721667696"
  }, {
    "category": "Miami",
    "weight": "-2.6083880497825209"
  }, {
    "category": "Hampton",
    "weight": "-25.289313176080682"
  }, {
    "category": "Pico Rivera",
    "weight": "1.6644402308389177"
  }, {
    "category": "Fort Collins",
    "weight": "-1.0070256954892396"
  }, {
    "category": "Englewood",
    "weight": "17.507994945510834"
  }, {
    "category": "Cleveland",
    "weight": "-5.3516894547650367"
  }, {
    "category": "Boise",
    "weight": "-20.16777541491717"
  }, {
    "category": "Santa Maria",
    "weight": "3.7782951501565902"
  }, {
    "category": "Oak Park",
    "weight": "-11.079155598062329"
  }, {
    "category": "Champaign",
    "weight": "2.0886858834605646"
  }, {
    "category": "Wilmington",
    "weight": "-11.01770683644069"
  }, {
    "category": "Dallas",
    "weight": "1.1800192810764041"
  }, {
    "category": "Greensboro",
    "weight": "-8.860021698786646"
  }, {
    "category": "Chicago",
    "weight": "-1.7904678291879055"
  }, {
    "category": "San Jose",
    "weight": "-1.7343748835484654"
  }, {
    "category": "Inglewood",
    "weight": "-16.677363303790578"
  }, {
    "category": "Portage",
    "weight": "19.965777551529786"
  }, {
    "category": "Colorado Springs",
    "weight": "-0.9609561430725"
  }, {
    "category": "Baltimore",
    "weight": "-0.16059230478833086"
  }, {
    "category": "Maple Grove",
    "weight": "-12.816718075964809"
  }, {
    "category": "Las Vegas",
    "weight": "-13.904516837081353"
  }, {
    "category": "Oklahoma City",
    "weight": "-13.225456138384567"
  }, {
    "category": "Wichita",
    "weight": "7.0714001766198553"
  }, {
    "category": "San Bernardino",
    "weight": "2.8751334300155613"
  }, {
    "category": "Omaha",
    "weight": "2.2349314165092959"
  }, {
    "category": "Clarksville",
    "weight": "7.7417828495571444"
  }, {
    "category": "Perth Amboy",
    "weight": "-10.970409837996478"
  }, {
    "category": "Columbus",
    "weight": "-0.64757403985896733"
  }, {
    "category": "Richmond",
    "weight": "-3.4523958090149236"
  }, {
    "category": "Jefferson City",
    "weight": "14.541491989533069"
  }, {
    "category": "Memphis",
    "weight": "4.8839906065055878"
  }, {
    "category": "Avondale",
    "weight": "4.0896714476228748"
  }, {
    "category": "Medford",
    "weight": "23.625174268524734"
  }, {
    "category": "Thomasville",
    "weight": "23.181853684431484"
  }, {
    "category": "Riverside",
    "weight": "4.11709156611991"
  }, {
    "category": "Southaven",
    "weight": "-5.9898928721355738"
  }, {
    "category": "Hattiesburg",
    "weight": "-3.4679437606512327"
  }, {
    "category": "Atlantic City",
    "weight": "25.112215950741319"
  }, {
    "category": "Clinton",
    "weight": "-4.4351468841558415"
  }, {
    "category": "Marion",
    "weight": "0.26220031380907916"
  }, {
    "category": "Redlands",
    "weight": "-5.1388790789480634"
  }, {
    "category": "Concord",
    "weight": "-3.43688001525709"
  }, {
    "category": "Houston",
    "weight": "1.2442962708873324"
  }, {
    "category": "Lakeland",
    "weight": "-12.039001170835535"
  }, {
    "category": "Keller",
    "weight": "31.51316658649985"
  }, {
    "category": "Austin",
    "weight": "6.9556372378792464"
  }, {
    "category": "Toledo",
    "weight": "5.9360518301774778"
  }, {
    "category": "Citrus Heights",
    "weight": "16.408115934975349"
  }, {
    "category": "Chester",
    "weight": "10.34174553276214"
  }, {
    "category": "Pine Bluff",
    "weight": "19.521758993769247"
  }, {
    "category": "Newport News",
    "weight": "13.961470187757467"
  }, {
    "category": "Yuma",
    "weight": "-12.728910390536472"
  }, {
    "category": "Reading",
    "weight": "8.413697765627953"
  }, {
    "category": "Westland",
    "weight": "7.0127034803359241"
  }, {
    "category": "Lawton",
    "weight": "-9.9022057242730437"
  }, {
    "category": "Tulsa",
    "weight": "-1.2495257748438675"
  }, {
    "category": "Rockford",
    "weight": "1.5451201566034847"
  }, {
    "category": "Milwaukee",
    "weight": "-0.91096588889305607"
  }, {
    "category": "Pasadena",
    "weight": "9.9587509362561164"
  }, {
    "category": "Des Moines",
    "weight": "-25.155491044313028"
  }, {
    "category": "Moreno Valley",
    "weight": "13.345065762645259"
  }, {
    "category": "Saint Charles",
    "weight": "13.60054279342155"
  }, {
    "category": "Iowa City",
    "weight": "34.438324633853973"
  }, {
    "category": "Salt Lake City",
    "weight": "25.259197007031688"
  }, {
    "category": "Pocatello",
    "weight": "-2.8644637980991448"
  }, {
    "category": "Commerce City",
    "weight": "16.278616451177079"
  }, {
    "category": "Park Ridge",
    "weight": "11.911905927322564"
  }, {
    "category": "Tucson",
    "weight": "6.5317944975437623"
  }, {
    "category": "Pomona",
    "weight": "-2.1803847433237742"
  }, {
    "category": "Philadelphia",
    "weight": "8.9245503764533716"
  }, {
    "category": "San Francisco",
    "weight": "8.9909917415033132"
  }, {
    "category": "Danville",
    "weight": "9.494667104982"
  }, {
    "category": "Olympia",
    "weight": "8.3311043982164126"
  }, {
    "category": "Bangor",
    "weight": "-1.3631188503167717"
  }, {
    "category": "Passaic",
    "weight": "-1.0452686616840232"
  }, {
    "category": "Cedar Rapids",
    "weight": "-4.85903590997567"
  }, {
    "category": "Middletown",
    "weight": "12.949518187308719"
  }, {
    "category": "Gilbert",
    "weight": "5.5495229368513694"
  }, {
    "category": "Albuquerque",
    "weight": "15.377242373416866"
  }, {
    "category": "Fayetteville",
    "weight": "9.9192353779008737"
  }, {
    "category": "Temecula",
    "weight": "5.6505656242174"
  }, {
    "category": "Fairfield",
    "weight": "8.33531166977885"
  }, {
    "category": "Pueblo",
    "weight": "-1.5102105119621712"
  }, {
    "category": "Westminster",
    "weight": "12.790132223564203"
  }, {
    "category": "Waynesboro",
    "weight": "-4.6439672341625489"
  }, {
    "category": "Plano",
    "weight": "9.6053228457118642"
  }, {
    "category": "Santa Ana",
    "weight": "0.57027687819769213"
  }, {
    "category": "Nashville",
    "weight": "11.200500892269673"
  }, {
    "category": "Long Beach",
    "weight": "6.7166684283615723"
  }, {
    "category": "Franklin",
    "weight": "10.512011719492758"
  }, {
    "category": "Huntsville",
    "weight": "5.8605247894586228"
  }, {
    "category": "Denver",
    "weight": "5.6972143365787566"
  }, {
    "category": "Medina",
    "weight": "-0.282559370671958"
  }, {
    "category": "Carrollton",
    "weight": "24.621640423915913"
  }, {
    "category": "Odessa",
    "weight": "15.202233721236757"
  }, {
    "category": "Carol Stream",
    "weight": "4.5970644154792684"
  }, {
    "category": "Canton",
    "weight": "3.1052630872894014"
  }, {
    "category": "Louisville",
    "weight": "13.145570776038333"
  }, {
    "category": "Chico",
    "weight": "20.797004721656677"
  }, {
    "category": "Clifton",
    "weight": "23.792119434724796"
  }, {
    "category": "Green Bay",
    "weight": "13.780455877308196"
  }, {
    "category": "Longmont",
    "weight": "-7.5917662352571078"
  }, {
    "category": "San Diego",
    "weight": "13.846398666453439"
  }, {
    "category": "Fargo",
    "weight": "24.643389292044411"
  }, {
    "category": "Redding",
    "weight": "-1.3199608380285532"
  }, {
    "category": "Apple Valley",
    "weight": "15.529135655630276"
  }, {
    "category": "El Cajon",
    "weight": "-16.509001488176516"
  }, {
    "category": "Oxnard",
    "weight": "16.772132888373974"
  }, {
    "category": "Naperville",
    "weight": "15.440068434055448"
  }, {
    "category": "Wheeling",
    "weight": "4.0543676222375211"
  }, {
    "category": "Indianapolis",
    "weight": "-0.47252456662713627"
  }, {
    "category": "El Paso",
    "weight": "20.079870612385719"
  }, {
    "category": "Athens",
    "weight": "14.955794802005371"
  }, {
    "category": "Chandler",
    "weight": "21.853184042652455"
  }, {
    "category": "Los Angeles",
    "weight": "15.949470806321296"
  }, {
    "category": "Cranston",
    "weight": "10.00812577387593"
  }, {
    "category": "Oakland",
    "weight": "18.380344422116654"
  }, {
    "category": "Eugene",
    "weight": "16.061261499372087"
  }, {
    "category": "Highland Park",
    "weight": "12.245054251363312"
  }, {
    "category": "Knoxville",
    "weight": "26.935688162457744"
  }, {
    "category": "Hesperia",
    "weight": "-1.7970176638317348"
  }, {
    "category": "Mount Pleasant",
    "weight": "16.597142656102641"
  }, {
    "category": "Fort Lauderdale",
    "weight": "20.528120667528434"
  }, {
    "category": "Raleigh",
    "weight": "23.294740790030225"
  }, {
    "category": "Manchester",
    "weight": "28.542344729668478"
  }, {
    "category": "Everett",
    "weight": "23.288242342656392"
  }, {
    "category": "Roswell",
    "weight": "35.093752529123492"
  }, {
    "category": "Charlotte",
    "weight": "16.321297576175361"
  }, {
    "category": "Columbia",
    "weight": "24.570203009758089"
  }, {
    "category": "Lowell",
    "weight": "27.759351640488308"
  }, {
    "category": "Lake Charles",
    "weight": "24.659236100884616"
  }, {
    "category": "South Bend",
    "weight": "29.218114430827697"
  }, {
    "category": "Meriden",
    "weight": "42.556923246649376"
  }, {
    "category": "Texarkana",
    "weight": "18.206468224785027"
  }, {
    "category": "Eau Claire",
    "weight": "32.5486193546433"
  }, {
    "category": "Springfield",
    "weight": "26.465515043429839"
  }, {
    "category": "North Las Vegas",
    "weight": "22.282707676268444"
  }, {
    "category": "Camarillo",
    "weight": "27.35950036134863"
  }, {
    "category": "Redondo Beach",
    "weight": "20.569648199028705"
  }, {
    "category": "New York City",
    "weight": "24.589670579077907"
  }, {
    "category": "Dearborn",
    "weight": "18.953863100066052"
  }, {
    "category": "Pleasant Grove",
    "weight": "25.07355326976684"
  }, {
    "category": "Lancaster",
    "weight": "26.688604187766778"
  }, {
    "category": "Buffalo Grove",
    "weight": "9.1112778281308344"
  }, {
    "category": "Dearborn Heights",
    "weight": "36.038765829070094"
  }, {
    "category": "Lake Elsinore",
    "weight": "33.39060235904725"
  }, {
    "category": "Lakeville",
    "weight": "24.549944173049958"
  }, {
    "category": "Providence",
    "weight": "30.424914558229766"
  }, {
    "category": "Asheville",
    "weight": "34.382245189604156"
  }, {
    "category": "Lorain",
    "weight": "48.373128442648714"
  }, {
    "category": "Vallejo",
    "weight": "43.619681404653775"
  }, {
    "category": "Seattle",
    "weight": "33.226612460232296"
  }, {
    "category": "Woodbury",
    "weight": "36.207162031661809"
  }, {
    "category": "Ontario",
    "weight": "42.589345696205669"
  }, {
    "category": "Orem",
    "weight": "40.6407981182145"
  }, {
    "category": "Newark",
    "weight": "29.70647993141025"
  }, {
    "category": "Woodstock",
    "weight": "39.153747689171517"
  }, {
    "category": "Moorhead",
    "weight": "13.043773353133716"
  }, {
    "category": "Lake Forest",
    "weight": "48.246921786808869"
  }, {
    "category": "Kenosha",
    "weight": "24.509029221025706"
  }, {
    "category": "Fort Worth",
    "weight": "47.584974353778556"
  }, {
    "category": "Anaheim",
    "weight": "43.87204598476292"
  }, {
    "category": "Mishawaka",
    "weight": "34.199783764893809"
  }, {
    "category": "Plainfield",
    "weight": "43.581287883061528"
  }, {
    "category": "Jackson",
    "weight": "46.171549147883361"
  }, {
    "category": "Stockton",
    "weight": "59.813724378922252"
  }, {
    "category": "Watertown",
    "weight": "53.191485357324332"
  }, {
    "category": "Arlington",
    "weight": "47.576667948422546"
  }, {
    "category": "Montgomery",
    "weight": "34.481803530408058"
  }, {
    "category": "Henderson",
    "weight": "51.139111355912625"
  }, {
    "category": "Whittier",
    "weight": "42.118976260498741"
  }, {
    "category": "Washington",
    "weight": "39.114713365157826"
  }, {
    "category": "Brentwood",
    "weight": "52.560012153293037"
  }, {
    "category": "Detroit",
    "weight": "49.818401128455477"
  }, {
    "category": "Florence",
    "weight": "60.992726144165232"
  }, {
    "category": "Marietta",
    "weight": "60.798899762125316"
  }, {
    "category": "Chesapeake",
    "weight": "51.260234593020471"
  }, {
    "category": "Missoula",
    "weight": "44.613953668049064"
  }, {
    "category": "Chula Vista",
    "weight": "76.068445490202052"
  }, {
    "category": "Huntington Beach",
    "weight": "65.5278338877617"
  }, {
    "category": "Vacaville",
    "weight": "62.77978447638835"
  }, {
    "category": "San Antonio",
    "weight": "67.06607761434546"
  }, {
    "category": "Lakewood",
    "weight": "71.868605212176917"
  }, {
    "category": "Mobile",
    "weight": "64.8750747284386"
  }, {
    "category": "Alexandria",
    "weight": "65.370641797015764"
  }, {
    "category": "Murrieta",
    "weight": "60.293199580519286"
  }, {
    "category": "Harrisonburg",
    "weight": "81.828800118814343"
  }, {
    "category": "Jacksonville",
    "weight": "85.065956901054534"
  }, {
    "category": "Kissimmee",
    "weight": "34.238950115883853"
  }, {
    "category": "Edmond",
    "weight": "97.228584661223934"
  }, {
    "category": "Parma",
    "weight": "104.37901529618142"
  }, {
    "category": "Warwick",
    "weight": "84.217093524690426"
  }, {
    "category": "Pasco",
    "weight": "90.249829684181833"
  }, {
    "category": "Virginia Beach",
    "weight": "95.884576585056791"
  }, {
    "category": "Saint Peters",
    "weight": "69.09497348329154"
  }, {
    "category": "Lehi",
    "weight": "60.817430912194254"
  }, {
    "category": "Tallahassee",
    "weight": "105.95324271657763"
  }, {
    "category": "Atlanta",
    "weight": "105.16489211273814"
  }, {
    "category": "Muskogee",
    "weight": "99.286743177565626"
  }, {
    "category": "Broken Arrow",
    "weight": "130.43274810671858"
  }, {
    "category": "Bellingham",
    "weight": "118.03892375182637"
  }, {
    "category": "Midland",
    "weight": "123.05141267812364"
  }, {
    "category": "Buffalo",
    "weight": "131.3461221468269"
  }, {
    "category": "Great Falls",
    "weight": "110.51613698035744"
  }, {
    "category": "Yonkers",
    "weight": "131.79207795602755"
  }, {
    "category": "Richardson",
    "weight": "159.76110150695146"
  }, {
    "category": "Norman",
    "weight": "168.7579351608378"
  }, {
    "category": "Sacramento",
    "weight": "174.15173127963106"
  }, {
    "category": "San Gabriel",
    "weight": "167.51865307556369"
  }, {
    "category": "Madison",
    "weight": "177.31472165995567"
  }, {
    "category": "Dubuque",
    "weight": "179.04431756185255"
  }, {
    "category": "Burlington",
    "weight": "176.55269249552302"
  }, {
    "category": "Morristown",
    "weight": "172.51755299391385"
  }, {
    "category": "Minneapolis",
    "weight": "230.08319688530926"
  }, {
    "category": "Sparks",
    "weight": "233.95020761143445"
  }, {
    "category": "Appleton",
    "weight": "244.23031474005813"
  }, {
    "category": "Santa Barbara",
    "weight": "254.26445177020167"
  }, {
    "category": "Torrance",
    "weight": "218.13413315892353"
  }, {
    "category": "Lafayette",
    "weight": "268.73399817224026"
  }, {
    "category": "Burbank",
    "weight": "269.27983742809408"
  }, {
    "category": "Beverly",
    "weight": "345.97619913313844"
  }, {
    "category": "Cheyenne",
    "weight": "354.04682028158095"
  }, {
    "category": "Noblesville",
    "weight": "418.36655926175683"
  }, {
    "category": "Independence",
    "weight": "435.30170971405664"
  }, {
    "category": "Jamestown",
    "weight": "783.96598906993984"
  }]
}, {
  "processed_input": "state",
  "weight": None,
  "category_weights": [{
    "category": "South Dakota",
    "weight": "-16.503233353858533"
  }, {
    "category": "Kansas",
    "weight": "-20.28575718505855"
  }, {
    "category": "Oregon",
    "weight": "-12.726771726345749"
  }, {
    "category": "New Mexico",
    "weight": "-3.3125398213680795"
  }, {
    "category": "Idaho",
    "weight": "-11.926129512185659"
  }, {
    "category": "Maine",
    "weight": "-14.608705171862109"
  }, {
    "category": "Arizona",
    "weight": "-7.0769162755767843"
  }, {
    "category": "Louisiana",
    "weight": "-18.631698220228383"
  }, {
    "category": "Illinois",
    "weight": "-3.2624484589948359"
  }, {
    "category": "New Hampshire",
    "weight": "-6.5212136251650641"
  }, {
    "category": "Ohio",
    "weight": "-4.8613929227088484"
  }, {
    "category": "Tennessee",
    "weight": "-0.54286554014404764"
  }, {
    "category": "Nebraska",
    "weight": "0.27427652318576889"
  }, {
    "category": "Utah",
    "weight": "-3.8138564043232517"
  }, {
    "category": "Colorado",
    "weight": "2.1719959828827049"
  }, {
    "category": "Iowa",
    "weight": "3.1929169098351364"
  }, {
    "category": "Texas",
    "weight": "2.1916110680403689"
  }, {
    "category": "Arkansas",
    "weight": "0.584454769876082"
  }, {
    "category": "Pennsylvania",
    "weight": "4.8942224371286391"
  }, {
    "category": "North Carolina",
    "weight": "2.081601413722538"
  }, {
    "category": "Connecticut",
    "weight": "10.350031922559086"
  }, {
    "category": "Massachusetts",
    "weight": "6.1417459799957292"
  }, {
    "category": "South Carolina",
    "weight": "4.4862698496184272"
  }, {
    "category": "Mississippi",
    "weight": "10.605533089846134"
  }, {
    "category": "Maryland",
    "weight": "14.655358074800681"
  }, {
    "category": "California",
    "weight": "12.315757872967254"
  }, {
    "category": "North Dakota",
    "weight": "24.643389292044411"
  }, {
    "category": "Kentucky",
    "weight": "11.712841434403023"
  }, {
    "category": "Wisconsin",
    "weight": "19.158459915655328"
  }, {
    "category": "Florida",
    "weight": "27.529326142084386"
  }, {
    "category": "New York",
    "weight": "22.601750764069326"
  }, {
    "category": "Rhode Island",
    "weight": "22.2254019145958"
  }, {
    "category": "Oklahoma",
    "weight": "22.283172621344487"
  }, {
    "category": "Georgia",
    "weight": "27.80594959196868"
  }, {
    "category": "Washington",
    "weight": "26.840000827166911"
  }, {
    "category": "Alabama",
    "weight": "28.154487583798215"
  }, {
    "category": "New Jersey",
    "weight": "36.304335085735651"
  }, {
    "category": "Delaware",
    "weight": "31.370350635287558"
  }, {
    "category": "Michigan",
    "weight": "33.813679116612491"
  }, {
    "category": "Virginia",
    "weight": "40.815973901983376"
  }, {
    "category": "West Virginia",
    "weight": "36.957735294875157"
  }, {
    "category": "Missouri",
    "weight": "47.828092160174585"
  }, {
    "category": "Nevada",
    "weight": "51.035784889311252"
  }, {
    "category": "District of Columbia",
    "weight": "39.114713365157826"
  }, {
    "category": "Minnesota",
    "weight": "51.459627055649293"
  }, {
    "category": "Montana",
    "weight": "51.537843919652232"
  }, {
    "category": "Indiana",
    "weight": "62.166301306949457"
  }, {
    "category": "Vermont",
    "weight": "171.87602373359391"
  }, {
    "category": "Wyoming",
    "weight": "354.04682028158095"
  }]
}, {
  "processed_input": "manufactory",
  "weight": None,
  "category_weights": [{
    "category": "Texas Instruments",
    "weight": "-191.97914649738567"
  }, {
    "category": "Lexmark",
    "weight": "-138.99879561856307"
  }, {
    "category": "Square",
    "weight": "-79.053552997396977"
  }, {
    "category": "Epson",
    "weight": "-141.78000008082162"
  }, {
    "category": "Barricks",
    "weight": "-71.667626687362343"
  }, {
    "category": "Kingston",
    "weight": "-54.636943997073757"
  }, {
    "category": "Staple-based wall hangings",
    "weight": "-48.679050487713596"
  }, {
    "category": "Anker",
    "weight": "-53.500301123604686"
  }, {
    "category": "Master Caster",
    "weight": "-45.618911158443709"
  }, {
    "category": "Wasp",
    "weight": "-108.39328090127204"
  }, {
    "category": "OtterBox",
    "weight": "-54.818188059212289"
  }, {
    "category": "HP",
    "weight": "-52.623801945795833"
  }, {
    "category": "Staple remover",
    "weight": "-46.860096147520807"
  }, {
    "category": "Verbatim",
    "weight": "-44.571640102070027"
  }, {
    "category": "Alliance",
    "weight": "-46.571140400533665"
  }, {
    "category": "Akro",
    "weight": "-42.107386473961846"
  }, {
    "category": "KeyTronic",
    "weight": "-47.485115942706685"
  }, {
    "category": "Griffin",
    "weight": "-43.306989032214084"
  }, {
    "category": "Memorex",
    "weight": "-44.955456179950936"
  }, {
    "category": "BIC",
    "weight": "-38.043551683820887"
  }, {
    "category": "Nu-Dell",
    "weight": "-42.661955181461352"
  }, {
    "category": "Westinghouse",
    "weight": "-37.4508110272983"
  }, {
    "category": "3-ring staple pack",
    "weight": "-36.74104478896669"
  }, {
    "category": "OIC",
    "weight": "-34.400874230504783"
  }, {
    "category": "DXL",
    "weight": "-37.910121765534647"
  }, {
    "category": "Sterilite",
    "weight": "-35.979517458274728"
  }, {
    "category": "Storex",
    "weight": "-35.613160603758772"
  }, {
    "category": "iOttie",
    "weight": "-37.9393957105901"
  }, {
    "category": "DAX",
    "weight": "-34.262376274144145"
  }, {
    "category": "Crayola",
    "weight": "-33.345923721065532"
  }, {
    "category": "Micro Innovations",
    "weight": "-39.406024005118127"
  }, {
    "category": "Pressboard",
    "weight": "-31.921655776632189"
  }, {
    "category": "Stockwell",
    "weight": "-29.323457459132797"
  }, {
    "category": "Staples in misc. colors",
    "weight": "-34.230206346224882"
  }, {
    "category": "Fiskars",
    "weight": "-35.837551018540921"
  }, {
    "category": "Ultra",
    "weight": "-32.038155427140182"
  }, {
    "category": "ACCOHIDE",
    "weight": "-29.709187741860504"
  }, {
    "category": "Adams",
    "weight": "-30.63521857689868"
  }, {
    "category": "Acme",
    "weight": "-31.978951786761051"
  }, {
    "category": "Newell",
    "weight": "-29.875123832396675"
  }, {
    "category": "Executive Impressions",
    "weight": "-31.882581979879522"
  }, {
    "category": "Wilson Jones",
    "weight": "-31.483307480410446"
  }, {
    "category": "C-Line",
    "weight": "-30.964001051490513"
  }, {
    "category": "Rogers",
    "weight": "-31.221011368436425"
  }, {
    "category": "Cardinal",
    "weight": "-27.908486188972358"
  }, {
    "category": "SanDisk",
    "weight": "-35.057643246089143"
  }, {
    "category": "Eldon",
    "weight": "-33.155797253536633"
  }, {
    "category": "Poly",
    "weight": "-28.733245878635707"
  }, {
    "category": "Tensor",
    "weight": "-30.346840128266866"
  }, {
    "category": "Sanford",
    "weight": "-28.643104543547857"
  }, {
    "category": "Staple envelope",
    "weight": "-28.327981190668034"
  }, {
    "category": "Holmes",
    "weight": "-33.591347113945119"
  }, {
    "category": "Staple holder",
    "weight": "-28.9758461957074"
  }, {
    "category": "Avery",
    "weight": "-26.447845612367889"
  }, {
    "category": "Angle-D",
    "weight": "-23.38323612299089"
  }, {
    "category": "Decoflex",
    "weight": "-28.882692922212616"
  }, {
    "category": "Staple-on labels",
    "weight": "-22.610861416199455"
  }, {
    "category": "Ampad",
    "weight": "-21.824016124684128"
  }, {
    "category": "Acco",
    "weight": "-26.844520239107634"
  }, {
    "category": "Universal",
    "weight": "-22.078370348886391"
  }, {
    "category": "Iris",
    "weight": "-27.637855027666095"
  }, {
    "category": "REDIFORM",
    "weight": "-24.864707066358015"
  }, {
    "category": "Wirebound",
    "weight": "-21.494132073690931"
  }, {
    "category": "Peel \u0026 Seel",
    "weight": "-22.843078810863631"
  }, {
    "category": "XtraLife",
    "weight": "-21.663236822994428"
  }, {
    "category": "Berol",
    "weight": "-30.429240430590347"
  }, {
    "category": "Seth Thomas",
    "weight": "-26.892542996919993"
  }, {
    "category": "Binney \u0026 Smith",
    "weight": "-17.935858934241256"
  }, {
    "category": "Grandstream",
    "weight": "-33.882928908096517"
  }, {
    "category": "Easy-staple paper",
    "weight": "-24.29714080682951"
  }, {
    "category": "Clearsounds",
    "weight": "-45.14397020962803"
  }, {
    "category": "Bulldog",
    "weight": "-25.790701639674193"
  }, {
    "category": "Prang",
    "weight": "-15.891809700891248"
  }, {
    "category": "Xerox 1971",
    "weight": "-17.651907307641405"
  }, {
    "category": "Linden",
    "weight": "-20.483253462851962"
  }, {
    "category": "Staple magnet",
    "weight": "-16.555631597913564"
  }, {
    "category": "Southworth",
    "weight": "-21.146543928549161"
  }, {
    "category": "Sony",
    "weight": "-28.678119811523132"
  }, {
    "category": "Things To Do",
    "weight": "-15.512277838121062"
  }, {
    "category": "Dixon",
    "weight": "-16.600426859269483"
  }, {
    "category": "Array",
    "weight": "-14.497326533216249"
  }, {
    "category": "Advantus",
    "weight": "-20.802355688849033"
  }, {
    "category": "Strathmore",
    "weight": "-18.287840360537622"
  }, {
    "category": "Quartet",
    "weight": "-8.711666936961926"
  }, {
    "category": "Hammermil",
    "weight": "-10.331061452072266"
  }, {
    "category": "Euro Pro",
    "weight": "-22.266611193637306"
  }, {
    "category": "TOPS",
    "weight": "-17.225596087368444"
  }, {
    "category": "Dana",
    "weight": "-19.998919386882818"
  }, {
    "category": "3M",
    "weight": "-25.598144776419467"
  }, {
    "category": "Maxell",
    "weight": "-22.639851104014745"
  }, {
    "category": "Bionaire",
    "weight": "-17.094587112607698"
  }, {
    "category": "Enermax",
    "weight": "-41.548975358822133"
  }, {
    "category": "Message Book",
    "weight": "-6.8686620925187372"
  }, {
    "category": "Xerox",
    "weight": "-12.950042334739981"
  }, {
    "category": "RCA",
    "weight": "-44.080376443105678"
  }, {
    "category": "Belkin",
    "weight": "-16.286255174893654"
  }, {
    "category": "Imation",
    "weight": "-21.486209779699486"
  }, {
    "category": "Bestar",
    "weight": "-36.44041164784268"
  }, {
    "category": "Boston",
    "weight": "-2.2951136654294859"
  }, {
    "category": "Novimex",
    "weight": "-24.148413670676121"
  }, {
    "category": "Socket",
    "weight": "-77.7732664883727"
  }, {
    "category": "Stanley",
    "weight": "7.7565157101202438"
  }, {
    "category": "Lesro",
    "weight": "-28.066233225141968"
  }, {
    "category": "Nokia",
    "weight": "-22.460419584346681"
  }, {
    "category": "Microsoft",
    "weight": "-11.558007954357436"
  }, {
    "category": "Gould Plastics",
    "weight": "-13.971893246388602"
  }, {
    "category": "Other",
    "weight": "-6.7815544006751676"
  }, {
    "category": "AT\u0026T",
    "weight": "-24.245515643602861"
  }, {
    "category": "Howard Miller",
    "weight": "-4.3716966980746408"
  }, {
    "category": "KI",
    "weight": "-20.092569424464688"
  }, {
    "category": "Deflect-o",
    "weight": "-3.4805908644696668"
  }, {
    "category": "Tenex",
    "weight": "-1.7441813953683916"
  }, {
    "category": "HTC",
    "weight": "-23.909387416429333"
  }, {
    "category": "Tyvek",
    "weight": "3.8462153453530163"
  }, {
    "category": "Eureka",
    "weight": "-3.4743477616225338"
  }, {
    "category": "GE",
    "weight": "2.5968971661412272"
  }, {
    "category": "Space Solutions",
    "weight": "-13.542640032101749"
  }, {
    "category": "Carina",
    "weight": "-11.125671804179614"
  }, {
    "category": "Pyle",
    "weight": "-11.508299967107451"
  }, {
    "category": "Premier",
    "weight": "5.6751714404957774"
  }, {
    "category": "First Data",
    "weight": "0.55410903429158509"
  }, {
    "category": "Panasonic",
    "weight": "3.12676321225608"
  }, {
    "category": "Tripp Lite",
    "weight": "19.115692417449718"
  }, {
    "category": "Hunt",
    "weight": "23.742031075390919"
  }, {
    "category": "Harmony",
    "weight": "11.782921670893412"
  }, {
    "category": "Kensington",
    "weight": "10.455115969418772"
  }, {
    "category": "Brother",
    "weight": "-52.485765479054734"
  }, {
    "category": "Logitech",
    "weight": "10.924801972681339"
  }, {
    "category": "Sauder",
    "weight": "10.070133021442494"
  }, {
    "category": "WD My Passport",
    "weight": "24.923817357006776"
  }, {
    "category": "Nortel",
    "weight": "12.908572157120105"
  }, {
    "category": "Electrix",
    "weight": "35.757272132473879"
  }, {
    "category": "Luxo",
    "weight": "29.911439918468162"
  }, {
    "category": "NETGEAR",
    "weight": "21.828346853510542"
  }, {
    "category": "SAFCO",
    "weight": "29.776529168155424"
  }, {
    "category": "Avaya",
    "weight": "34.735994413566374"
  }, {
    "category": "O\u0027Sullivan",
    "weight": "30.733632178943125"
  }, {
    "category": "Motorola",
    "weight": "37.756085563897784"
  }, {
    "category": "Jabra",
    "weight": "28.635051112621976"
  }, {
    "category": "GBC",
    "weight": "55.29501848916145"
  }, {
    "category": "Global",
    "weight": "40.176324725187811"
  }, {
    "category": "Fellowes",
    "weight": "59.904087226610152"
  }, {
    "category": "Bush",
    "weight": "48.987225516765456"
  }, {
    "category": "Jawbone",
    "weight": "47.641609377025908"
  }, {
    "category": "Plantronics",
    "weight": "54.297743960950456"
  }, {
    "category": "Hoover",
    "weight": "65.258350302901661"
  }, {
    "category": "Office Star",
    "weight": "49.890996013588122"
  }, {
    "category": "LG",
    "weight": "60.039251848171567"
  }, {
    "category": "Bevis",
    "weight": "51.044121115100481"
  }, {
    "category": "Ibico",
    "weight": "77.515723885734388"
  }, {
    "category": "Razer",
    "weight": "65.637771936051124"
  }, {
    "category": "Smead",
    "weight": "95.5041944239781"
  }, {
    "category": "Balt",
    "weight": "65.430572363337234"
  }, {
    "category": "Iceberg",
    "weight": "74.2868751868129"
  }, {
    "category": "Avanti",
    "weight": "71.313782604793715"
  }, {
    "category": "Rush",
    "weight": "69.863282806582617"
  }, {
    "category": "DMI",
    "weight": "86.029892774576226"
  }, {
    "category": "Mitel",
    "weight": "91.6609536474602"
  }, {
    "category": "Standard",
    "weight": "113.94377337682425"
  }, {
    "category": "Chromcraft",
    "weight": "96.743223071690224"
  }, {
    "category": "Sharp",
    "weight": "71.174693466918754"
  }, {
    "category": "ClearOne",
    "weight": "139.06469394057783"
  }, {
    "category": "Polycom",
    "weight": "140.32950147001131"
  }, {
    "category": "Tennsco",
    "weight": "158.64967539437754"
  }, {
    "category": "Atlantic",
    "weight": "154.22554129858131"
  }, {
    "category": "Hon",
    "weight": "160.23828434260918"
  }, {
    "category": "Okidata",
    "weight": "143.66595162745438"
  }, {
    "category": "Honeywell",
    "weight": "216.32510431180242"
  }, {
    "category": "Bretford",
    "weight": "207.30511534662486"
  }, {
    "category": "Office Impressions",
    "weight": "226.61160078934026"
  }, {
    "category": "Samsung",
    "weight": "257.38164869399418"
  }, {
    "category": "Cisco",
    "weight": "258.11620622862705"
  }, {
    "category": "Apple",
    "weight": "282.44753795265666"
  }, {
    "category": "Zebra",
    "weight": "301.89855371582314"
  }, {
    "category": "Ativa",
    "weight": "300.48157137781203"
  }, {
    "category": "Martin-Yale",
    "weight": "456.56697201483189"
  }, {
    "category": "Hewlett-Packard",
    "weight": "389.099752594089"
  }, {
    "category": "Riverside",
    "weight": "556.48348296694132"
  }, {
    "category": "Sanyo",
    "weight": "600.58547565730476"
  }, {
    "category": "Canon",
    "weight": "929.8590020897791"
  }, {
    "category": "Cubify",
    "weight": "1466.480931388252"
  }, {
    "category": "3D Systems",
    "weight": "1745.8747504593871"
  }]
}, {
  "processed_input": "order_month",
  "weight": "-0.32300440941010572",
  "category_weights": []
}, {
  "processed_input": "order_year",
  "weight": "-0.834641742890926",
  "category_weights": []
}, {
  "processed_input": "order_quarter",
  "weight": "-1.634304328866286",
  "category_weights": []
}, {
  "processed_input": "order_day_of_week",
  "weight": None,
  "category_weights": [{
    "category": "Saturday",
    "weight": "6.7939916008204824"
  }, {
    "category": "Sunday",
    "weight": "10.712322658707599"
  }, {
    "category": "Friday",
    "weight": "10.799682317970744"
  }, {
    "category": "Wednesday",
    "weight": "14.139266978782581"
  }, {
    "category": "Thursday",
    "weight": "17.830419460021311"
  }, {
    "category": "Monday",
    "weight": "19.685933567403563"
  }, {
    "category": "Tuesday",
    "weight": "26.117928207601487"
  }]
}, {
  "processed_input": "customer_frequency",
  "weight": "-1.3166966679359431",
  "category_weights": []
}, {
  "processed_input": "customer_monetary_value",
  "weight": "0.012704039226859526",
  "category_weights": []
}, {
  "processed_input": "customer_unique_orders",
  "weight": "-2.6557697789582511",
  "category_weights": []
}, {
  "processed_input": "customer_recency",
  "weight": "0.013625428989319587",
  "category_weights": []
}, {
  "processed_input": "customer_avg_order_value",
  "weight": "0.10577545213724476",
  "category_weights": []
}, {
  "processed_input": "customer_rfm_segment",
  "weight": None,
  "category_weights": [{
    "category": "Cannot Lose Them",
    "weight": "-1.4183132341785485"
  }, {
    "category": "At Risk",
    "weight": "7.4611915625929335"
  }, {
    "category": "Potential Loyalists",
    "weight": "9.33237396255821"
  }, {
    "category": "Champions",
    "weight": "14.504215031174633"
  }, {
    "category": "Loyal Customers",
    "weight": "19.016954648535176"
  }]
}, {
  "processed_input": "__INTERCEPT__",
  "weight": "1475.3943271498488",
  "category_weights": []
}]
```

### From Sales:
```python
r_squared = 0.6778378623516863

importance = calculate_feature_importance(model_data, r_squared)
fig1, ax1 = create_feature_importance_pie_chart(importance)
plt.show()
```

### From Sales:
```python
model_data = model_data = [{
  "processed_input": "sales",
  "weight": "0.055524624891881542",
  "category_weights": []
}, {
  "processed_input": "quantity",
  "weight": "1.6038510000779913",
  "category_weights": []
}, {
  "processed_input": "discount",
  "weight": "-55.292966587136",
  "category_weights": []
}, {
  "processed_input": "unit_price",
  "weight": "0.2062705715620623",
  "category_weights": []
}, {
  "processed_input": "order_processing_time",
  "weight": "-0.19195247971531876",
  "category_weights": []
}, {
  "processed_input": "is_discounted",
  "weight": "-15.223020457316572",
  "category_weights": []
}, {
  "processed_input": "discount_category",
  "weight": None,
  "category_weights": [{
    "category": "High Discount",
    "weight": "-31.306431660324634"
  }, {
    "category": "Medium Discount",
    "weight": "0.64892443990828985"
  }, {
    "category": "No Discount",
    "weight": "9.1108187755638568"
  }, {
    "category": "Low Discount",
    "weight": "15.372197549818303"
  }]
}, {
  "processed_input": "order_size_category",
  "weight": None,
  "category_weights": [{
    "category": "Small",
    "weight": "-2.059093882182176"
  }, {
    "category": "Medium",
    "weight": "1.4807307608988358"
  }, {
    "category": "Large",
    "weight": "4.852376424575823"
  }, {
    "category": "Bulk",
    "weight": "26.51185176646792"
  }]
}, {
  "processed_input": "price_segment",
  "weight": None,
  "category_weights": [{
    "category": "Medium-Low Price",
    "weight": "-3.4855457748603516"
  }, {
    "category": "Low Price",
    "weight": "-2.3948862763311132"
  }, {
    "category": "Medium-High Price",
    "weight": "-1.2074384811288947"
  }, {
    "category": "High Price",
    "weight": "11.918613632527904"
  }]
}, {
  "processed_input": "segment",
  "weight": None,
  "category_weights": [{
    "category": "Consumer",
    "weight": "0.51835294350112"
  }, {
    "category": "Corporate",
    "weight": "1.8036859727875747"
  }, {
    "category": "Home Office",
    "weight": "2.0102222732274164"
  }]
}, {
  "processed_input": "category",
  "weight": None,
  "category_weights": [{
    "category": "Furniture",
    "weight": "-5.71537267888185"
  }, {
    "category": "Office Supplies",
    "weight": "0.2692424508483775"
  }, {
    "category": "Technology",
    "weight": "11.833735179222678"
  }]
}, {
  "processed_input": "subcategory",
  "weight": None,
  "category_weights": [{
    "category": "Tables",
    "weight": "-27.383739669104955"
  }, {
    "category": "Bookcases",
    "weight": "-11.632728064934474"
  }, {
    "category": "Supplies",
    "weight": "-10.207143546133624"
  }, {
    "category": "Fasteners",
    "weight": "-3.6202355570008207"
  }, {
    "category": "Art",
    "weight": "-3.0454684486186436"
  }, {
    "category": "Furnishings",
    "weight": "-1.6583122981006948"
  }, {
    "category": "Labels",
    "weight": "-1.0009112940192151"
  }, {
    "category": "Storage",
    "weight": "-1.2208293519661284"
  }, {
    "category": "Paper",
    "weight": "1.0331848353826483"
  }, {
    "category": "Binders",
    "weight": "3.0637948852502812"
  }, {
    "category": "Envelopes",
    "weight": "2.195887990992742"
  }, {
    "category": "Chairs",
    "weight": "0.97475856391424109"
  }, {
    "category": "Machines",
    "weight": "-2.9951554079880456"
  }, {
    "category": "Appliances",
    "weight": "3.6120625731430955"
  }, {
    "category": "Phones",
    "weight": "4.8865089684411958"
  }, {
    "category": "Accessories",
    "weight": "5.8086394702253843"
  }, {
    "category": "Copiers",
    "weight": "192.08397238541244"
  }]
}, {
  "processed_input": "region",
  "weight": None,
  "category_weights": [{
    "category": "Central",
    "weight": "-0.46520078473189663"
  }, {
    "category": "South",
    "weight": "0.95606591767944682"
  }, {
    "category": "East",
    "weight": "1.9296227562272472"
  }, {
    "category": "West",
    "weight": "1.7808376108188879"
  }]
}, {
  "processed_input": "city",
  "weight": None,
  "category_weights": [{
    "category": "Burlington",
    "weight": "-74.419393197162833"
  }, {
    "category": "Round Rock",
    "weight": "-65.103260518843584"
  }, {
    "category": "Bethlehem",
    "weight": "-58.978220989719432"
  }, {
    "category": "Lancaster",
    "weight": "-54.394304547358225"
  }, {
    "category": "Clarksville",
    "weight": "-53.424934193087246"
  }, {
    "category": "Champaign",
    "weight": "-49.865349996050263"
  }, {
    "category": "Buffalo Grove",
    "weight": "-48.951883318137959"
  }, {
    "category": "Medina",
    "weight": "-48.69824958797755"
  }, {
    "category": "San Antonio",
    "weight": "-42.304448065397672"
  }, {
    "category": "Richardson",
    "weight": "-39.307037013569328"
  }, {
    "category": "Rockford",
    "weight": "-38.651084720588386"
  }, {
    "category": "Park Ridge",
    "weight": "-37.058614726315206"
  }, {
    "category": "Normal",
    "weight": "-38.379416843926641"
  }, {
    "category": "Yuma",
    "weight": "-34.978374212553277"
  }, {
    "category": "Pueblo",
    "weight": "-33.477644255787645"
  }, {
    "category": "Lorain",
    "weight": "-32.298139143952817"
  }, {
    "category": "Littleton",
    "weight": "-24.149055117876749"
  }, {
    "category": "Pharr",
    "weight": "-28.208007398322252"
  }, {
    "category": "Reading",
    "weight": "-24.676488967009959"
  }, {
    "category": "Greenville",
    "weight": "-25.939547541391267"
  }, {
    "category": "Tigard",
    "weight": "-24.950947907236639"
  }, {
    "category": "Tamarac",
    "weight": "-20.977636886211123"
  }, {
    "category": "Knoxville",
    "weight": "-20.412296692776636"
  }, {
    "category": "Louisville",
    "weight": "-20.920063493798274"
  }, {
    "category": "Phoenix",
    "weight": "-19.180398327038837"
  }, {
    "category": "Colorado Springs",
    "weight": "-18.118376483208912"
  }, {
    "category": "Concord",
    "weight": "-20.440321095539872"
  }, {
    "category": "Amarillo",
    "weight": "-17.880741864526481"
  }, {
    "category": "Ontario",
    "weight": "-16.955516087159847"
  }, {
    "category": "Allentown",
    "weight": "-18.91086329337638"
  }, {
    "category": "Aurora",
    "weight": "-14.280344762229056"
  }, {
    "category": "Bryan",
    "weight": "-13.108147539626108"
  }, {
    "category": "Fort Collins",
    "weight": "-13.64337100664461"
  }, {
    "category": "College Station",
    "weight": "-12.281856063238651"
  }, {
    "category": "Evanston",
    "weight": "-12.930089380513973"
  }, {
    "category": "Plano",
    "weight": "-12.354423227880329"
  }, {
    "category": "Highland Park",
    "weight": "-12.108137227519384"
  }, {
    "category": "Des Plaines",
    "weight": "-11.193230931651044"
  }, {
    "category": "Commerce City",
    "weight": "-11.329656752780473"
  }, {
    "category": "Dublin",
    "weight": "-10.512086109508113"
  }, {
    "category": "Miami",
    "weight": "-9.7990651181261548"
  }, {
    "category": "Mentor",
    "weight": "-9.2574738719053578"
  }, {
    "category": "Chicago",
    "weight": "-9.2431432973493965"
  }, {
    "category": "Skokie",
    "weight": "-7.9252078205985725"
  }, {
    "category": "Scottsdale",
    "weight": "-9.3005602817178037"
  }, {
    "category": "Philadelphia",
    "weight": "-9.1215064200808946"
  }, {
    "category": "Marion",
    "weight": "-9.2178693445346731"
  }, {
    "category": "Hesperia",
    "weight": "-10.587496403233589"
  }, {
    "category": "Odessa",
    "weight": "-8.0536531533788125"
  }, {
    "category": "Houston",
    "weight": "-7.98337040592787"
  }, {
    "category": "Tyler",
    "weight": "-6.0019797704165176"
  }, {
    "category": "Troy",
    "weight": "-8.6324915379543761"
  }, {
    "category": "Parker",
    "weight": "-6.4789901732721136"
  }, {
    "category": "York",
    "weight": "-7.7426566052920451"
  }, {
    "category": "Cleveland",
    "weight": "-7.7020169875804"
  }, {
    "category": "El Paso",
    "weight": "-7.5159928389223847"
  }, {
    "category": "Longmont",
    "weight": "-8.941925935599965"
  }, {
    "category": "Carol Stream",
    "weight": "-8.23220711582036"
  }, {
    "category": "Irving",
    "weight": "-7.0640152972094175"
  }, {
    "category": "Charlotte",
    "weight": "-8.3019341851115112"
  }, {
    "category": "San Angelo",
    "weight": "-7.3069294378355085"
  }, {
    "category": "Hialeah",
    "weight": "-7.1350764658235244"
  }, {
    "category": "Manhattan",
    "weight": "-12.244099165052987"
  }, {
    "category": "Naperville",
    "weight": "-6.3226964358402711"
  }, {
    "category": "Redmond",
    "weight": "-7.4024784196261226"
  }, {
    "category": "Denver",
    "weight": "-8.1103300775716765"
  }, {
    "category": "Mesquite",
    "weight": "-4.9108761485521084"
  }, {
    "category": "Elmhurst",
    "weight": "-5.8199484190968107"
  }, {
    "category": "Fort Lauderdale",
    "weight": "-6.9023853668325268"
  }, {
    "category": "North Charleston",
    "weight": "-9.1920323498537577"
  }, {
    "category": "Layton",
    "weight": "-8.62186524688165"
  }, {
    "category": "Daytona Beach",
    "weight": "-5.4041675489322785"
  }, {
    "category": "Wheeling",
    "weight": "-6.9487526266781749"
  }, {
    "category": "Lakeland",
    "weight": "-6.6416243468311995"
  }, {
    "category": "Tucson",
    "weight": "-6.0350077028316349"
  }, {
    "category": "Dallas",
    "weight": "-4.866881764466493"
  }, {
    "category": "Hoover",
    "weight": "-8.06204786468619"
  }, {
    "category": "Huntsville",
    "weight": "-5.8273623807303654"
  }, {
    "category": "Pasadena",
    "weight": "-5.861096735573831"
  }, {
    "category": "El Cajon",
    "weight": "-7.3624349505843538"
  }, {
    "category": "Mesa",
    "weight": "-4.8574921769748816"
  }, {
    "category": "Pembroke Pines",
    "weight": "-4.9925445510273612"
  }, {
    "category": "Texas City",
    "weight": "-3.5471660477963347"
  }, {
    "category": "Greensboro",
    "weight": "-4.4841922255303555"
  }, {
    "category": "Laredo",
    "weight": "-4.5616136314310456"
  }, {
    "category": "Springdale",
    "weight": "-6.2270160914230921"
  }, {
    "category": "Bridgeton",
    "weight": "-6.2697775946477936"
  }, {
    "category": "Parma",
    "weight": "-5.7506382205728279"
  }, {
    "category": "Pearland",
    "weight": "-1.8168961810377904"
  }, {
    "category": "San Luis Obispo",
    "weight": "-5.747989105310066"
  }, {
    "category": "Reno",
    "weight": "-5.6051451889661914"
  }, {
    "category": "Montebello",
    "weight": "-6.1801008260125858"
  }, {
    "category": "Grand Prairie",
    "weight": "-3.5873641217335006"
  }, {
    "category": "Marysville",
    "weight": "-5.7908029314425651"
  }, {
    "category": "Memphis",
    "weight": "-3.6318999164238388"
  }, {
    "category": "New Brunswick",
    "weight": "-5.8422729479303825"
  }, {
    "category": "Elkhart",
    "weight": "-6.7653220465069479"
  }, {
    "category": "Modesto",
    "weight": "-6.3525201297191209"
  }, {
    "category": "Lewiston",
    "weight": "-5.6591166830172455"
  }, {
    "category": "Garden City",
    "weight": "-5.5260591556580323"
  }, {
    "category": "Vineland",
    "weight": "-5.9068586313764371"
  }, {
    "category": "Hendersonville",
    "weight": "-2.7288714308868194"
  }, {
    "category": "Portland",
    "weight": "-4.1020943212563958"
  }, {
    "category": "San Bernardino",
    "weight": "-4.7416918356511655"
  }, {
    "category": "Royal Oak",
    "weight": "-5.60663807087228"
  }, {
    "category": "New Bedford",
    "weight": "-6.2498549964186125"
  }, {
    "category": "Frisco",
    "weight": "-0.62344470734951862"
  }, {
    "category": "Saginaw",
    "weight": "-6.9737889565358664"
  }, {
    "category": "Margate",
    "weight": "-4.5085911003753116"
  }, {
    "category": "Rock Hill",
    "weight": "-4.7747504990269718"
  }, {
    "category": "Saint Paul",
    "weight": "-6.4528038464116264"
  }, {
    "category": "New Castle",
    "weight": "-6.235857139646769"
  }, {
    "category": "Peoria",
    "weight": "-2.9159753414408756"
  }, {
    "category": "Jacksonville",
    "weight": "-3.7364078736031878"
  }, {
    "category": "Toledo",
    "weight": "-2.3372632472032842"
  }, {
    "category": "League City",
    "weight": "-3.4952188908944009"
  }, {
    "category": "Alexandria",
    "weight": "-7.8352443958176874"
  }, {
    "category": "Plantation",
    "weight": "-3.4932721416458872"
  }, {
    "category": "Austin",
    "weight": "-3.0463165458128425"
  }, {
    "category": "Sheboygan",
    "weight": "-5.2304235286767851"
  }, {
    "category": "Akron",
    "weight": "-2.8058235432991321"
  }, {
    "category": "Kenner",
    "weight": "-5.2924914282112718"
  }, {
    "category": "Gilbert",
    "weight": "-4.5419811654087505"
  }, {
    "category": "Salem",
    "weight": "-3.6582379418025237"
  }, {
    "category": "Clovis",
    "weight": "-4.2896411758665867"
  }, {
    "category": "Vancouver",
    "weight": "-5.5351511874047263"
  }, {
    "category": "Bellevue",
    "weight": "-4.0959508410050471"
  }, {
    "category": "San Marcos",
    "weight": "-1.915305750410264"
  }, {
    "category": "Tinley Park",
    "weight": "-1.0979106148301514"
  }, {
    "category": "Holland",
    "weight": "-4.640793103402773"
  }, {
    "category": "Nashua",
    "weight": "-3.9606720092265997"
  }, {
    "category": "Santa Fe",
    "weight": "-4.6590926494275164"
  }, {
    "category": "Shelton",
    "weight": "-4.6836175690821111"
  }, {
    "category": "Cottage Grove",
    "weight": "-3.9013919034766942"
  }, {
    "category": "Morgan Hill",
    "weight": "-3.8214864714832526"
  }, {
    "category": "Deer Park",
    "weight": "-0.35009043383376381"
  }, {
    "category": "Coral Springs",
    "weight": "-2.7664033903349772"
  }, {
    "category": "Taylor",
    "weight": "-5.2549349186826726"
  }, {
    "category": "East Point",
    "weight": "-4.8994216360680456"
  }, {
    "category": "Charlottesville",
    "weight": "-4.2343144446024468"
  }, {
    "category": "Tampa",
    "weight": "-2.2878052725762839"
  }, {
    "category": "Antioch",
    "weight": "-3.9973845147885667"
  }, {
    "category": "Jefferson City",
    "weight": "-3.7287232840735802"
  }, {
    "category": "Iowa City",
    "weight": "-2.8390384267860584"
  }, {
    "category": "Waterloo",
    "weight": "-4.2836121273795067"
  }, {
    "category": "Garland",
    "weight": "-0.29106103842925513"
  }, {
    "category": "Miramar",
    "weight": "-2.7160158617073571"
  }, {
    "category": "Grand Island",
    "weight": "-3.502999556714502"
  }, {
    "category": "Green Bay",
    "weight": "-3.6670918246856754"
  }, {
    "category": "Warner Robins",
    "weight": "-3.9391138360505575"
  }, {
    "category": "Moreno Valley",
    "weight": "-3.5990396058470941"
  }, {
    "category": "Wilson",
    "weight": "-1.2700333926545644"
  }, {
    "category": "Spokane",
    "weight": "-5.1665534590293145"
  }, {
    "category": "West Jordan",
    "weight": "-4.64952607292339"
  }, {
    "category": "Bedford",
    "weight": "-1.1730067727757598"
  }, {
    "category": "Corpus Christi",
    "weight": "-0.74840674908668825"
  }, {
    "category": "Eagan",
    "weight": "-3.6211888085965933"
  }, {
    "category": "Logan",
    "weight": "-3.3066537556135893"
  }, {
    "category": "Woodland",
    "weight": "-3.6480466244825611"
  }, {
    "category": "Decatur",
    "weight": "-3.6337735757884628"
  }, {
    "category": "Boca Raton",
    "weight": "-1.7767345044171754"
  }, {
    "category": "Romeoville",
    "weight": "1.6004098815616032"
  }, {
    "category": "Sterling Heights",
    "weight": "-4.2447913132338906"
  }, {
    "category": "Orange",
    "weight": "-4.0780993912275143"
  }, {
    "category": "Bristol",
    "weight": "-3.1130310285546119"
  }, {
    "category": "Chico",
    "weight": "-3.3980372380249251"
  }, {
    "category": "Allen",
    "weight": "-0.44469400778640855"
  }, {
    "category": "Jupiter",
    "weight": "-1.0241547172633467"
  }, {
    "category": "Laurel",
    "weight": "-2.93143974650146"
  }, {
    "category": "Chester",
    "weight": "-1.2279780381909331"
  }, {
    "category": "West Palm Beach",
    "weight": "-1.5746300816211658"
  }, {
    "category": "Danbury",
    "weight": "-2.8983397332392506"
  }, {
    "category": "Dearborn Heights",
    "weight": "-4.5932573739092728"
  }, {
    "category": "North Miami",
    "weight": "-1.128138693607188"
  }, {
    "category": "Port Saint Lucie",
    "weight": "-1.441255137120566"
  }, {
    "category": "Longview",
    "weight": "-3.3393869692759135"
  }, {
    "category": "Chattanooga",
    "weight": "-1.0271463743050626"
  }, {
    "category": "Lake Charles",
    "weight": "-2.8451793474945211"
  }, {
    "category": "Bolingbrook",
    "weight": "0.54668105993002736"
  }, {
    "category": "Laguna Niguel",
    "weight": "-3.0335694653378482"
  }, {
    "category": "West Allis",
    "weight": "-3.4301103539382041"
  }, {
    "category": "Malden",
    "weight": "-2.901458751886127"
  }, {
    "category": "Bozeman",
    "weight": "-2.5219893699966636"
  }, {
    "category": "Port Orange",
    "weight": "-0.99117241273542611"
  }, {
    "category": "Bakersfield",
    "weight": "-2.3621192960564521"
  }, {
    "category": "Pompano Beach",
    "weight": "-1.7333654421521816"
  }, {
    "category": "Owensboro",
    "weight": "-2.9471255548135917"
  }, {
    "category": "Atlantic City",
    "weight": "-2.5065871699407327"
  }, {
    "category": "Lebanon",
    "weight": "-2.5782028316543828"
  }, {
    "category": "Grapevine",
    "weight": "-0.6980200312026299"
  }, {
    "category": "Woonsocket",
    "weight": "-4.0340234193779843"
  }, {
    "category": "Davis",
    "weight": "-3.1459906645916158"
  }, {
    "category": "Coral Gables",
    "weight": "-2.1641794042613571"
  }, {
    "category": "Bloomington",
    "weight": "-2.6132630181485736"
  }, {
    "category": "Murfreesboro",
    "weight": "-0.060407554385429191"
  }, {
    "category": "Englewood",
    "weight": "-1.5039817322048494"
  }, {
    "category": "Pomona",
    "weight": "-4.1628541770535179"
  }, {
    "category": "Bullhead City",
    "weight": "-0.522514554615807"
  }, {
    "category": "Lubbock",
    "weight": "0.74731497556794979"
  }, {
    "category": "Yucaipa",
    "weight": "-2.47737351274548"
  }, {
    "category": "Billings",
    "weight": "-0.30272545931577433"
  }, {
    "category": "Mcallen",
    "weight": "-0.050356968713387684"
  }, {
    "category": "Carrollton",
    "weight": "-0.56611367561945791"
  }, {
    "category": "Hamilton",
    "weight": "-0.40479984738916708"
  }, {
    "category": "Johnson City",
    "weight": "-1.4647093239799502"
  }, {
    "category": "Mason",
    "weight": "0.5974315520869794"
  }, {
    "category": "Harlingen",
    "weight": "-0.28989552388305917"
  }, {
    "category": "Baytown",
    "weight": "-0.26818136386587821"
  }, {
    "category": "Hot Springs",
    "weight": "-2.7992318660264726"
  }, {
    "category": "Glendale",
    "weight": "-0.78917327146501592"
  }, {
    "category": "Glenview",
    "weight": "-2.2155289080300058"
  }, {
    "category": "Encinitas",
    "weight": "-2.2038341980854339"
  }, {
    "category": "Hickory",
    "weight": "1.4155917142149166"
  }, {
    "category": "Sierra Vista",
    "weight": "-0.019935826768477605"
  }, {
    "category": "Apopka",
    "weight": "-0.6805094046695821"
  }, {
    "category": "Las Cruces",
    "weight": "-2.2263122987882906"
  }, {
    "category": "La Quinta",
    "weight": "-2.8772239563666751"
  }, {
    "category": "Hillsboro",
    "weight": "0.3403184255524675"
  }, {
    "category": "Waukesha",
    "weight": "-2.0318404580314415"
  }, {
    "category": "Moorhead",
    "weight": "-3.1061529188547889"
  }, {
    "category": "Leominster",
    "weight": "-1.7835641525151082"
  }, {
    "category": "Loveland",
    "weight": "0.52888693839471312"
  }, {
    "category": "Melbourne",
    "weight": "-1.0285818306329286"
  }, {
    "category": "Coachella",
    "weight": "-3.8287585761392835"
  }, {
    "category": "Rockville",
    "weight": "-2.9642299792158813"
  }, {
    "category": "Saint Louis",
    "weight": "-2.9649698840136463"
  }, {
    "category": "Arlington Heights",
    "weight": "0.77806546214354033"
  }, {
    "category": "Oswego",
    "weight": "0.25673623705727555"
  }, {
    "category": "Chapel Hill",
    "weight": "0.14321514982312866"
  }, {
    "category": "Salinas",
    "weight": "-1.046119953374165"
  }, {
    "category": "Saint Petersburg",
    "weight": "-0.6514723496485495"
  }, {
    "category": "Delray Beach",
    "weight": "-0.57060239145304936"
  }, {
    "category": "Altoona",
    "weight": "1.3311395270444"
  }, {
    "category": "Waco",
    "weight": "1.2977852891510764"
  }, {
    "category": "Conroe",
    "weight": "-0.031286755236517028"
  }, {
    "category": "Cuyahoga Falls",
    "weight": "1.4664508639001279"
  }, {
    "category": "Boynton Beach",
    "weight": "0.37183356770229881"
  }, {
    "category": "Caldwell",
    "weight": "-2.4661726154044072"
  }, {
    "category": "Sunnyvale",
    "weight": "-2.0849404785373782"
  }, {
    "category": "Palm Coast",
    "weight": "0.3338873036005513"
  }, {
    "category": "Escondido",
    "weight": "-0.63813374109158083"
  }, {
    "category": "The Colony",
    "weight": "-0.49782514197568295"
  }, {
    "category": "Santa Clara",
    "weight": "-1.4610264047919954"
  }, {
    "category": "Haltom City",
    "weight": "0.59430426923570967"
  }, {
    "category": "Rogers",
    "weight": "-2.0840030662190649"
  }, {
    "category": "Greeley",
    "weight": "0.60025620996632578"
  }, {
    "category": "Cary",
    "weight": "-0.35322690539686974"
  }, {
    "category": "Medford",
    "weight": "1.5781860969526578"
  }, {
    "category": "Tempe",
    "weight": "0.014012288983398236"
  }, {
    "category": "Visalia",
    "weight": "-2.5521771115545171"
  }, {
    "category": "Nashville",
    "weight": "-0.36536945925672804"
  }, {
    "category": "New Albany",
    "weight": "-1.8399743056486706"
  }, {
    "category": "Port Arthur",
    "weight": "-2.8906059101401063"
  }, {
    "category": "Freeport",
    "weight": "-1.011444078633589"
  }, {
    "category": "Homestead",
    "weight": "-0.15723422117219865"
  }, {
    "category": "Abilene",
    "weight": "2.9381426700036326"
  }, {
    "category": "Carlsbad",
    "weight": "-0.72956939990732916"
  }, {
    "category": "Avondale",
    "weight": "-0.688474717469608"
  }, {
    "category": "Redding",
    "weight": "-2.6219767868326711"
  }, {
    "category": "Woodstock",
    "weight": "-0.76968174957522528"
  }, {
    "category": "Niagara Falls",
    "weight": "-1.5185499129470621"
  }, {
    "category": "Elyria",
    "weight": "2.7352816614031825"
  }, {
    "category": "Urbandale",
    "weight": "-1.9745922854714948"
  }, {
    "category": "Hollywood",
    "weight": "0.23198997566433821"
  }, {
    "category": "Quincy",
    "weight": "0.35035874223565755"
  }, {
    "category": "Hagerstown",
    "weight": "-1.5458271964001762"
  }, {
    "category": "Lodi",
    "weight": "-1.7943584733730518"
  }, {
    "category": "Belleville",
    "weight": "-2.7324535047752025"
  }, {
    "category": "Fremont",
    "weight": "-2.2466870728850852"
  }, {
    "category": "Bartlett",
    "weight": "0.78607270150216979"
  }, {
    "category": "Middletown",
    "weight": "-0.97092532950776889"
  }, {
    "category": "Gulfport",
    "weight": "-1.8702846399725033"
  }, {
    "category": "Cincinnati",
    "weight": "1.503562401038486"
  }, {
    "category": "Rancho Cucamonga",
    "weight": "-0.72879281374859151"
  }, {
    "category": "Thousand Oaks",
    "weight": "-1.0328367812409449"
  }, {
    "category": "Bowling Green",
    "weight": "0.27736399539749579"
  }, {
    "category": "La Porte",
    "weight": "-0.83556567330378151"
  }, {
    "category": "Fort Worth",
    "weight": "0.19531158752782485"
  }, {
    "category": "Grand Rapids",
    "weight": "-1.6284932447325975"
  }, {
    "category": "Temecula",
    "weight": "-2.779381925756681"
  }, {
    "category": "Las Vegas",
    "weight": "-1.5685345927751255"
  }, {
    "category": "Beaumont",
    "weight": "1.15426439434634"
  }, {
    "category": "Costa Mesa",
    "weight": "-1.6321944349215336"
  }, {
    "category": "Chandler",
    "weight": "0.93749018003475237"
  }, {
    "category": "Rapid City",
    "weight": "-0.82927553361268647"
  }, {
    "category": "Durham",
    "weight": "1.1929012838585511"
  }, {
    "category": "Riverside",
    "weight": "-0.63244828115646534"
  }, {
    "category": "Ormond Beach",
    "weight": "4.3053124903589168"
  }, {
    "category": "Kirkwood",
    "weight": "-0.79410127736036706"
  }, {
    "category": "Lincoln Park",
    "weight": "-0.47015475734324053"
  }, {
    "category": "Thomasville",
    "weight": "4.607804252086825"
  }, {
    "category": "Renton",
    "weight": "-8.77015418170059"
  }, {
    "category": "Brownsville",
    "weight": "1.4065350845307221"
  }, {
    "category": "Macon",
    "weight": "-0.870335360185158"
  }, {
    "category": "Broomfield",
    "weight": "0.85664259670170528"
  }, {
    "category": "Arvada",
    "weight": "1.311582518150249"
  }, {
    "category": "Helena",
    "weight": "-0.552089466354226"
  }, {
    "category": "Asheville",
    "weight": "0.69698194801761559"
  }, {
    "category": "Westfield",
    "weight": "-1.3593008296136118"
  }, {
    "category": "Franklin",
    "weight": "-0.32564991792082676"
  }, {
    "category": "Redlands",
    "weight": "-1.0007741360111879"
  }, {
    "category": "Pocatello",
    "weight": "-1.2970511186550624"
  }, {
    "category": "Murray",
    "weight": "-0.65668409379870241"
  }, {
    "category": "Grove City",
    "weight": "3.4399615655039621"
  }, {
    "category": "San Clemente",
    "weight": "0.51729028773057761"
  }, {
    "category": "Palatine",
    "weight": "0.14007031428075667"
  }, {
    "category": "Covington",
    "weight": "-0.93914561302431476"
  }, {
    "category": "Wausau",
    "weight": "-0.81907641931780439"
  }, {
    "category": "Utica",
    "weight": "-0.37295006012802556"
  }, {
    "category": "Rochester",
    "weight": "-0.44848462682647217"
  }, {
    "category": "Thornton",
    "weight": "1.7898266319500273"
  }, {
    "category": "Meridian",
    "weight": "0.48654637214375729"
  }, {
    "category": "Lindenhurst",
    "weight": "0.027355536941469083"
  }, {
    "category": "Cambridge",
    "weight": "-0.41146080146420605"
  }, {
    "category": "Rome",
    "weight": "-0.78679766407092"
  }, {
    "category": "Olympia",
    "weight": "-0.31986887468890224"
  }, {
    "category": "Edinburg",
    "weight": "2.6270236971315"
  }, {
    "category": "Westland",
    "weight": "-0.56861106605181266"
  }, {
    "category": "Eugene",
    "weight": "1.4055404364463762"
  }, {
    "category": "Great Falls",
    "weight": "-0.69566055334785215"
  }, {
    "category": "Oceanside",
    "weight": "0.24299477644732015"
  }, {
    "category": "Columbus",
    "weight": "1.179931199219598"
  }, {
    "category": "Fairfield",
    "weight": "1.0910928560058952"
  }, {
    "category": "Coppell",
    "weight": "2.5679466791320404"
  }, {
    "category": "Auburn",
    "weight": "-0.2996479546821682"
  }, {
    "category": "Tuscaloosa",
    "weight": "-0.682282284778732"
  }, {
    "category": "Redondo Beach",
    "weight": "0.068005659786034123"
  }, {
    "category": "Camarillo",
    "weight": "0.75259849535070078"
  }, {
    "category": "Saint Charles",
    "weight": "2.3812048334909024"
  }, {
    "category": "Springfield",
    "weight": "0.647003916346887"
  }, {
    "category": "Tallahassee",
    "weight": "1.4317061553581745"
  }, {
    "category": "Santa Maria",
    "weight": "0.70015688372244789"
  }, {
    "category": "Andover",
    "weight": "0.58669573685233"
  }, {
    "category": "Raleigh",
    "weight": "2.346114807172881"
  }, {
    "category": "East Orange",
    "weight": "0.33112906006715281"
  }, {
    "category": "Long Beach",
    "weight": "0.072377654385945789"
  }, {
    "category": "Draper",
    "weight": "1.2754572571019134"
  }, {
    "category": "San Jose",
    "weight": "1.3936217103159416"
  }, {
    "category": "Cedar Hill",
    "weight": "3.7015621068173288"
  }, {
    "category": "Smyrna",
    "weight": "1.5060473822472611"
  }, {
    "category": "Overland Park",
    "weight": "1.3743525887660573"
  }, {
    "category": "Monroe",
    "weight": "1.8190328433232432"
  }, {
    "category": "Fargo",
    "weight": "1.8556332769198569"
  }, {
    "category": "Pine Bluff",
    "weight": "1.4964871735100305"
  }, {
    "category": "Waterbury",
    "weight": "1.3825466402843718"
  }, {
    "category": "Oakland",
    "weight": "1.7665631667084405"
  }, {
    "category": "Provo",
    "weight": "1.3567280909704147"
  }, {
    "category": "Baltimore",
    "weight": "1.6119591826007422"
  }, {
    "category": "Revere",
    "weight": "1.3835072963918131"
  }, {
    "category": "Little Rock",
    "weight": "1.4117325750296041"
  }, {
    "category": "Deltona",
    "weight": "3.4899124848125167"
  }, {
    "category": "San Francisco",
    "weight": "1.7756706321167881"
  }, {
    "category": "Fresno",
    "weight": "1.5806192547823521"
  }, {
    "category": "Marlborough",
    "weight": "2.4702640626162093"
  }, {
    "category": "San Diego",
    "weight": "2.0533364374719216"
  }, {
    "category": "Danville",
    "weight": "3.7258715805323122"
  }, {
    "category": "Whittier",
    "weight": "1.514868608799393"
  }, {
    "category": "San Mateo",
    "weight": "3.5882215044665706"
  }, {
    "category": "Sioux Falls",
    "weight": "2.431431506707507"
  }, {
    "category": "Apple Valley",
    "weight": "2.9542593960341783"
  }, {
    "category": "Los Angeles",
    "weight": "2.9102717097794244"
  }, {
    "category": "Tulsa",
    "weight": "2.6333549683627346"
  }, {
    "category": "Orlando",
    "weight": "3.1183371666433919"
  }, {
    "category": "Mishawaka",
    "weight": "1.6512031837131484"
  }, {
    "category": "Santa Barbara",
    "weight": "1.7959769424862886"
  }, {
    "category": "Wilmington",
    "weight": "2.9872677647342814"
  }, {
    "category": "Cranston",
    "weight": "2.4993797103048268"
  }, {
    "category": "Gresham",
    "weight": "3.5352615909615688"
  }, {
    "category": "Gladstone",
    "weight": "3.6124726524405091"
  }, {
    "category": "Paterson",
    "weight": "3.2253245058507378"
  }, {
    "category": "Meriden",
    "weight": "4.0080740858157942"
  }, {
    "category": "South Bend",
    "weight": "2.9998946414827952"
  }, {
    "category": "Mission Viejo",
    "weight": "2.7893267448976262"
  }, {
    "category": "Roseville",
    "weight": "3.1850407522792796"
  }, {
    "category": "Anaheim",
    "weight": "3.8464770795115513"
  }, {
    "category": "Dover",
    "weight": "3.3500361540654957"
  }, {
    "category": "Conway",
    "weight": "3.8836057662309731"
  }, {
    "category": "Linden",
    "weight": "3.0476754700420186"
  }, {
    "category": "Lake Forest",
    "weight": "4.0652946976614182"
  }, {
    "category": "Olathe",
    "weight": "1.4937829282410195"
  }, {
    "category": "Gastonia",
    "weight": "5.4910974817694127"
  }, {
    "category": "Sandy Springs",
    "weight": "3.7477008265976615"
  }, {
    "category": "Suffolk",
    "weight": "4.1665580407921405"
  }, {
    "category": "Trenton",
    "weight": "2.5315163216330028"
  }, {
    "category": "Canton",
    "weight": "3.6654346758266838"
  }, {
    "category": "Clinton",
    "weight": "3.8771528526590258"
  }, {
    "category": "New Rochelle",
    "weight": "5.0223390839622741"
  }, {
    "category": "Ann Arbor",
    "weight": "3.3423450661157048"
  }, {
    "category": "Rochester Hills",
    "weight": "3.7273311591381617"
  }, {
    "category": "Indianapolis",
    "weight": "3.2489981618254404"
  }, {
    "category": "Albuquerque",
    "weight": "5.4180524184091876"
  }, {
    "category": "Jonesboro",
    "weight": "3.5158458838414868"
  }, {
    "category": "Lansing",
    "weight": "3.4424892924067532"
  }, {
    "category": "Norwich",
    "weight": "5.0408380176012288"
  }, {
    "category": "Westminster",
    "weight": "5.3899508955010278"
  }, {
    "category": "Bayonne",
    "weight": "4.9307706501754947"
  }, {
    "category": "Salt Lake City",
    "weight": "6.4392549912459653"
  }, {
    "category": "Fayetteville",
    "weight": "6.9026396355926627"
  }, {
    "category": "Lawrence",
    "weight": "4.8829716965916257"
  }, {
    "category": "Gaithersburg",
    "weight": "5.3681467526340851"
  }, {
    "category": "Oak Park",
    "weight": "5.8747397708277811"
  }, {
    "category": "Plainfield",
    "weight": "5.1922676049022449"
  }, {
    "category": "Wichita",
    "weight": "6.0037993023165033"
  }, {
    "category": "Milford",
    "weight": "5.6722258973649513"
  }, {
    "category": "Milwaukee",
    "weight": "5.6559092791728984"
  }, {
    "category": "La Crosse",
    "weight": "5.808865181150046"
  }, {
    "category": "Waynesboro",
    "weight": "4.6408949714115879"
  }, {
    "category": "Kent",
    "weight": "7.323015153493901"
  }, {
    "category": "Holyoke",
    "weight": "5.533561014712336"
  }, {
    "category": "Lawton",
    "weight": "6.1348690627300595"
  }, {
    "category": "La Mesa",
    "weight": "6.5414998700142606"
  }, {
    "category": "Georgetown",
    "weight": "5.6791376092925354"
  }, {
    "category": "Farmington",
    "weight": "6.9714445947051491"
  }, {
    "category": "Everett",
    "weight": "6.9335880198633477"
  }, {
    "category": "Citrus Heights",
    "weight": "7.9461131923279167"
  }, {
    "category": "Pasco",
    "weight": "6.9602562957031004"
  }, {
    "category": "Hempstead",
    "weight": "6.8070148341454715"
  }, {
    "category": "Manteca",
    "weight": "7.6161524668602034"
  }, {
    "category": "Madison",
    "weight": "7.5792538033965258"
  }, {
    "category": "Orem",
    "weight": "7.4441917543255407"
  }, {
    "category": "Santa Ana",
    "weight": "8.1099696198375266"
  }, {
    "category": "Omaha",
    "weight": "7.85410707809557"
  }, {
    "category": "Coon Rapids",
    "weight": "6.6022717342625148"
  }, {
    "category": "Oxnard",
    "weight": "7.4232410031048346"
  }, {
    "category": "Hattiesburg",
    "weight": "8.04073572237322"
  }, {
    "category": "Stockton",
    "weight": "9.31639830165192"
  }, {
    "category": "Boise",
    "weight": "8.4566428087691854"
  }, {
    "category": "Bossier City",
    "weight": "7.7699471465224876"
  }, {
    "category": "Richmond",
    "weight": "7.8377896065327617"
  }, {
    "category": "Pleasant Grove",
    "weight": "8.2708480648718954"
  }, {
    "category": "Woodbury",
    "weight": "8.7635368141644072"
  }, {
    "category": "Edmonds",
    "weight": "9.2854143794034272"
  }, {
    "category": "Athens",
    "weight": "8.6372002120574365"
  }, {
    "category": "Pico Rivera",
    "weight": "9.9862861459086858"
  }, {
    "category": "New York City",
    "weight": "9.17564182390449"
  }, {
    "category": "Inglewood",
    "weight": "8.9853738935609364"
  }, {
    "category": "Newark",
    "weight": "9.6627297035840414"
  }, {
    "category": "Hackensack",
    "weight": "8.84476085388686"
  }, {
    "category": "Manchester",
    "weight": "10.062413678508976"
  }, {
    "category": "Vallejo",
    "weight": "10.94401598264542"
  }, {
    "category": "Lowell",
    "weight": "10.38419594504882"
  }, {
    "category": "Orland Park",
    "weight": "11.378501314178715"
  }, {
    "category": "Watertown",
    "weight": "10.807086319541291"
  }, {
    "category": "Southaven",
    "weight": "10.698759468755455"
  }, {
    "category": "Eau Claire",
    "weight": "11.062492579738848"
  }, {
    "category": "Chesapeake",
    "weight": "10.514528270517882"
  }, {
    "category": "Columbia",
    "weight": "11.617440414165188"
  }, {
    "category": "Seattle",
    "weight": "11.547122393119851"
  }, {
    "category": "Brentwood",
    "weight": "11.436192351292206"
  }, {
    "category": "Noblesville",
    "weight": "9.66126118785932"
  }, {
    "category": "Cedar Rapids",
    "weight": "11.208375967342459"
  }, {
    "category": "Oklahoma City",
    "weight": "11.257750643603769"
  }, {
    "category": "Texarkana",
    "weight": "11.633702866033364"
  }, {
    "category": "Cheyenne",
    "weight": "8.1628636231065812"
  }, {
    "category": "Clifton",
    "weight": "12.928635250442719"
  }, {
    "category": "Mount Pleasant",
    "weight": "10.993058035780081"
  }, {
    "category": "Chula Vista",
    "weight": "12.462269717078376"
  }, {
    "category": "Superior",
    "weight": "12.340737883325875"
  }, {
    "category": "Marietta",
    "weight": "11.362426889220608"
  }, {
    "category": "Arlington",
    "weight": "13.858249904744788"
  }, {
    "category": "Passaic",
    "weight": "12.271633457343"
  }, {
    "category": "Montgomery",
    "weight": "12.814837802114628"
  }, {
    "category": "Lakewood",
    "weight": "14.777431412970094"
  }, {
    "category": "Mount Vernon",
    "weight": "14.629656729047197"
  }, {
    "category": "Sparks",
    "weight": "12.285102810627077"
  }, {
    "category": "Hampton",
    "weight": "14.070465294488926"
  }, {
    "category": "Henderson",
    "weight": "14.597445286476304"
  }, {
    "category": "Des Moines",
    "weight": "13.128029722150046"
  }, {
    "category": "Bangor",
    "weight": "14.698736855729624"
  }, {
    "category": "Perth Amboy",
    "weight": "15.801764353722378"
  }, {
    "category": "Rio Rancho",
    "weight": "15.359170090100539"
  }, {
    "category": "Buffalo",
    "weight": "14.623279461877507"
  }, {
    "category": "Lakeville",
    "weight": "16.817707165090916"
  }, {
    "category": "Kenosha",
    "weight": "16.08819074636256"
  }, {
    "category": "Summerville",
    "weight": "17.862079911872929"
  }, {
    "category": "Newport News",
    "weight": "16.146898957847707"
  }, {
    "category": "Dearborn",
    "weight": "17.762913228020508"
  }, {
    "category": "Jackson",
    "weight": "18.949053736328885"
  }, {
    "category": "Vacaville",
    "weight": "18.693420413264374"
  }, {
    "category": "Minneapolis",
    "weight": "18.997694037732437"
  }, {
    "category": "Muskogee",
    "weight": "19.86398333796712"
  }, {
    "category": "Greenwood",
    "weight": "19.707262297967219"
  }, {
    "category": "Broken Arrow",
    "weight": "21.761239053510565"
  }, {
    "category": "Atlanta",
    "weight": "22.464464223286232"
  }, {
    "category": "Detroit",
    "weight": "22.950285934190674"
  }, {
    "category": "Harrisonburg",
    "weight": "23.383898832980055"
  }, {
    "category": "Norman",
    "weight": "22.114717707637318"
  }, {
    "category": "Washington",
    "weight": "23.531167700875169"
  }, {
    "category": "Torrance",
    "weight": "24.768683888321785"
  }, {
    "category": "Twin Falls",
    "weight": "25.820351824182183"
  }, {
    "category": "Virginia Beach",
    "weight": "26.789097342215776"
  }, {
    "category": "San Gabriel",
    "weight": "25.276501055206037"
  }, {
    "category": "Florence",
    "weight": "27.891888763419761"
  }, {
    "category": "North Las Vegas",
    "weight": "28.289328899783765"
  }, {
    "category": "Missoula",
    "weight": "32.598961887568109"
  }, {
    "category": "Roswell",
    "weight": "32.206359330210589"
  }, {
    "category": "Dubuque",
    "weight": "32.397959229005266"
  }, {
    "category": "Huntington Beach",
    "weight": "31.834000097263377"
  }, {
    "category": "Maple Grove",
    "weight": "33.9896890465456"
  }, {
    "category": "Providence",
    "weight": "34.758758915105254"
  }, {
    "category": "Independence",
    "weight": "34.348965330808447"
  }, {
    "category": "Yonkers",
    "weight": "42.675850948244488"
  }, {
    "category": "Edmond",
    "weight": "46.73840724767561"
  }, {
    "category": "Warwick",
    "weight": "46.827647020896123"
  }, {
    "category": "Mobile",
    "weight": "50.291250529332217"
  }, {
    "category": "Sacramento",
    "weight": "52.339070467926305"
  }, {
    "category": "Midland",
    "weight": "55.66547772438085"
  }, {
    "category": "Burbank",
    "weight": "55.071251337181486"
  }, {
    "category": "Appleton",
    "weight": "61.946179825209889"
  }, {
    "category": "Beverly",
    "weight": "62.820904934698866"
  }, {
    "category": "Bellingham",
    "weight": "80.300040025808528"
  }, {
    "category": "Morristown",
    "weight": "82.011850954177561"
  }, {
    "category": "Lehi",
    "weight": "74.929331900557955"
  }, {
    "category": "Lafayette",
    "weight": "88.685867896840918"
  }, {
    "category": "Jamestown",
    "weight": "149.65187773932354"
  }]
}, {
  "processed_input": "state",
  "weight": None,
  "category_weights": [{
    "category": "Colorado",
    "weight": "-15.667257510555924"
  }, {
    "category": "Ohio",
    "weight": "-14.187316725278592"
  }, {
    "category": "North Carolina",
    "weight": "-14.314886987380229"
  }, {
    "category": "Illinois",
    "weight": "-10.148281642391137"
  }, {
    "category": "Pennsylvania",
    "weight": "-9.5172784888223276"
  }, {
    "category": "Tennessee",
    "weight": "-9.0878528917481223"
  }, {
    "category": "Texas",
    "weight": "-8.768263133205636"
  }, {
    "category": "Arizona",
    "weight": "-8.5923279125922214"
  }, {
    "category": "Oregon",
    "weight": "-6.5200867834738983"
  }, {
    "category": "Florida",
    "weight": "-4.4695080786369363"
  }, {
    "category": "Kansas",
    "weight": "0.442006581116674"
  }, {
    "category": "North Dakota",
    "weight": "1.8556332769198569"
  }, {
    "category": "Montana",
    "weight": "1.6478481514699403"
  }, {
    "category": "New Mexico",
    "weight": "2.2010613755149722"
  }, {
    "category": "South Dakota",
    "weight": "1.779290098643469"
  }, {
    "category": "California",
    "weight": "2.5844107092282611"
  }, {
    "category": "Idaho",
    "weight": "3.1189366769061317"
  }, {
    "category": "South Carolina",
    "weight": "2.3530685061757923"
  }, {
    "category": "Iowa",
    "weight": "3.748023952408472"
  }, {
    "category": "Louisiana",
    "weight": "1.7295108456635955"
  }, {
    "category": "Massachusetts",
    "weight": "3.8031196173457955"
  }, {
    "category": "Utah",
    "weight": "3.900437756545494"
  }, {
    "category": "Connecticut",
    "weight": "4.5776940171088176"
  }, {
    "category": "New Hampshire",
    "weight": "4.3777660979575153"
  }, {
    "category": "Nebraska",
    "weight": "5.11868488837308"
  }, {
    "category": "Arkansas",
    "weight": "6.6569863235566462"
  }, {
    "category": "Wisconsin",
    "weight": "8.4366105248036742"
  }, {
    "category": "New York",
    "weight": "8.779963810273081"
  }, {
    "category": "Mississippi",
    "weight": "9.3610705690665981"
  }, {
    "category": "Maryland",
    "weight": "10.3347471525569"
  }, {
    "category": "Minnesota",
    "weight": "10.093214792772121"
  }, {
    "category": "Oklahoma",
    "weight": "10.03383828027652"
  }, {
    "category": "Washington",
    "weight": "10.813672623231586"
  }, {
    "category": "Maine",
    "weight": "10.398582040154178"
  }, {
    "category": "Wyoming",
    "weight": "8.1628636231065812"
  }, {
    "category": "Georgia",
    "weight": "12.284363327968117"
  }, {
    "category": "Nevada",
    "weight": "12.299296698823099"
  }, {
    "category": "Kentucky",
    "weight": "12.772798007758297"
  }, {
    "category": "New Jersey",
    "weight": "12.797992863347329"
  }, {
    "category": "Virginia",
    "weight": "13.437445018731559"
  }, {
    "category": "Alabama",
    "weight": "13.551409772560891"
  }, {
    "category": "West Virginia",
    "weight": "16.82995018523803"
  }, {
    "category": "Missouri",
    "weight": "17.783649485573129"
  }, {
    "category": "Michigan",
    "weight": "18.241242250579134"
  }, {
    "category": "Delaware",
    "weight": "20.965916073936185"
  }, {
    "category": "District of Columbia",
    "weight": "23.531167700875169"
  }, {
    "category": "Rhode Island",
    "weight": "23.794852528080767"
  }, {
    "category": "Indiana",
    "weight": "24.914844886649352"
  }, {
    "category": "Vermont",
    "weight": "87.487352963165932"
  }]
}, {
  "processed_input": "manufactory",
  "weight": None,
  "category_weights": [{
    "category": "Cubify",
    "weight": "-940.11640239914686"
  }, {
    "category": "Epson",
    "weight": "-91.35427525736219"
  }, {
    "category": "Riverside",
    "weight": "-71.146058370851975"
  }, {
    "category": "Chromcraft",
    "weight": "-45.419367358545209"
  }, {
    "category": "Balt",
    "weight": "-42.432239018076586"
  }, {
    "category": "Martin-Yale",
    "weight": "-45.175848864512318"
  }, {
    "category": "Bretford",
    "weight": "-30.829379046624304"
  }, {
    "category": "Bestar",
    "weight": "-23.868098246297656"
  }, {
    "category": "Bevis",
    "weight": "-18.250901219105717"
  }, {
    "category": "Office Impressions",
    "weight": "-20.445680472111416"
  }, {
    "category": "O\u0027Sullivan",
    "weight": "-16.68022433469292"
  }, {
    "category": "Novimex",
    "weight": "-14.117172688371127"
  }, {
    "category": "Euro Pro",
    "weight": "-11.862660603363768"
  }, {
    "category": "Bush",
    "weight": "-12.801712374366442"
  }, {
    "category": "Space Solutions",
    "weight": "-14.358949186074195"
  }, {
    "category": "Sauder",
    "weight": "-11.555138432763487"
  }, {
    "category": "Lesro",
    "weight": "-10.105145720572132"
  }, {
    "category": "Carina",
    "weight": "-11.908759354617555"
  }, {
    "category": "Gould Plastics",
    "weight": "-10.677841324139326"
  }, {
    "category": "KI",
    "weight": "-8.679085127092069"
  }, {
    "category": "Lexmark",
    "weight": "-9.9740334726757851"
  }, {
    "category": "Tenex",
    "weight": "-8.7831209912134209"
  }, {
    "category": "Barricks",
    "weight": "-6.9703108942127727"
  }, {
    "category": "iOttie",
    "weight": "-8.4788138887118514"
  }, {
    "category": "Premier",
    "weight": "-6.5597822982428111"
  }, {
    "category": "Okidata",
    "weight": "-12.823016084492894"
  }, {
    "category": "Alliance",
    "weight": "-7.0068033889220223"
  }, {
    "category": "Rogers",
    "weight": "-6.5101728124847744"
  }, {
    "category": "Kingston",
    "weight": "-6.6110191813710113"
  }, {
    "category": "DMI",
    "weight": "-9.2947958549004035"
  }, {
    "category": "SAFCO",
    "weight": "-6.4273978788620516"
  }, {
    "category": "Iris",
    "weight": "-4.8201882184073961"
  }, {
    "category": "Deflect-o",
    "weight": "-5.0649586563816857"
  }, {
    "category": "Akro",
    "weight": "-4.3735878238056651"
  }, {
    "category": "Office Star",
    "weight": "-6.5270145552337819"
  }, {
    "category": "Anker",
    "weight": "-5.0310930068604618"
  }, {
    "category": "Eldon",
    "weight": "-4.2588985212893355"
  }, {
    "category": "3-ring staple pack",
    "weight": "-4.2228820352297305"
  }, {
    "category": "Square",
    "weight": "-4.7023795923598666"
  }, {
    "category": "OIC",
    "weight": "-3.7066510261188239"
  }, {
    "category": "Prang",
    "weight": "-3.8938739787771461"
  }, {
    "category": "Staple remover",
    "weight": "-3.5145239823750356"
  }, {
    "category": "Hammermil",
    "weight": "-4.2135890453459126"
  }, {
    "category": "Ampad",
    "weight": "-4.3764533908935253"
  }, {
    "category": "Binney \u0026 Smith",
    "weight": "-3.5565597152892874"
  }, {
    "category": "Newell",
    "weight": "-3.7752515201118624"
  }, {
    "category": "Staple magnet",
    "weight": "-3.5994095176539664"
  }, {
    "category": "Westinghouse",
    "weight": "-4.0130959971212086"
  }, {
    "category": "BIC",
    "weight": "-3.5608094687287"
  }, {
    "category": "Quartet",
    "weight": "-3.4796514588215461"
  }, {
    "category": "Stockwell",
    "weight": "-2.9169129483914693"
  }, {
    "category": "Crayola",
    "weight": "-3.0274424423719308"
  }, {
    "category": "Staple-on labels",
    "weight": "-3.1132204766189839"
  }, {
    "category": "Sterilite",
    "weight": "-3.0860909734826021"
  }, {
    "category": "Micro Innovations",
    "weight": "-4.44301999686863"
  }, {
    "category": "OtterBox",
    "weight": "-4.0009453818281511"
  }, {
    "category": "Acme",
    "weight": "-3.0187988742768277"
  }, {
    "category": "Adams",
    "weight": "-3.5633396119746683"
  }, {
    "category": "C-Line",
    "weight": "-2.4137781128706526"
  }, {
    "category": "Bulldog",
    "weight": "-3.1690518238345637"
  }, {
    "category": "Staples in misc. colors",
    "weight": "-3.05706329399269"
  }, {
    "category": "ACCOHIDE",
    "weight": "-1.98831954643539"
  }, {
    "category": "Fiskars",
    "weight": "-3.2127409851357527"
  }, {
    "category": "SanDisk",
    "weight": "-4.1058018080983523"
  }, {
    "category": "Universal",
    "weight": "-2.7495812400420041"
  }, {
    "category": "Tensor",
    "weight": "-3.4486239570192971"
  }, {
    "category": "Sanford",
    "weight": "-3.5692789850047855"
  }, {
    "category": "Tennsco",
    "weight": "-5.5469023509071249"
  }, {
    "category": "Master Caster",
    "weight": "-2.1319794758634227"
  }, {
    "category": "Griffin",
    "weight": "-2.3477975076766073"
  }, {
    "category": "Staple holder",
    "weight": "-2.9145179348809385"
  }, {
    "category": "Cardinal",
    "weight": "-1.4560582316421042"
  }, {
    "category": "Clearsounds",
    "weight": "-3.1058414234392626"
  }, {
    "category": "Wirebound",
    "weight": "-2.7393700101710836"
  }, {
    "category": "Texas Instruments",
    "weight": "-2.341780383808445"
  }, {
    "category": "Angle-D",
    "weight": "-0.74802302315664693"
  }, {
    "category": "Verbatim",
    "weight": "-2.407785426819864"
  }, {
    "category": "Xerox 1971",
    "weight": "-2.3249439436757529"
  }, {
    "category": "HP",
    "weight": "-3.0351496926270114"
  }, {
    "category": "Belkin",
    "weight": "-2.6385675184673292"
  }, {
    "category": "Decoflex",
    "weight": "-3.2142346182553276"
  }, {
    "category": "Wilson Jones",
    "weight": "-1.0370194897912037"
  }, {
    "category": "Sony",
    "weight": "-3.75449074580215"
  }, {
    "category": "Storex",
    "weight": "-1.1551784017812794"
  }, {
    "category": "Peel \u0026 Seel",
    "weight": "-2.9316831109180463"
  }, {
    "category": "Ultra",
    "weight": "-2.008862246193134"
  }, {
    "category": "Pressboard",
    "weight": "-0.41264721451756586"
  }, {
    "category": "Avery",
    "weight": "-1.6104426741690683"
  }, {
    "category": "Dixon",
    "weight": "-1.7743557464650503"
  }, {
    "category": "Array",
    "weight": "-2.0742301220606421"
  }, {
    "category": "Acco",
    "weight": "-1.1486473462981281"
  }, {
    "category": "DAX",
    "weight": "-1.4878973653245182"
  }, {
    "category": "Stanley",
    "weight": "-1.2530621228206267"
  }, {
    "category": "Poly",
    "weight": "-1.4125424955592456"
  }, {
    "category": "DXL",
    "weight": "-1.0082652936748344"
  }, {
    "category": "XtraLife",
    "weight": "-0.030243930084906556"
  }, {
    "category": "Message Book",
    "weight": "-1.4584046244769011"
  }, {
    "category": "Staple-based wall hangings",
    "weight": "-1.2235104721069923"
  }, {
    "category": "REDIFORM",
    "weight": "-1.9205415526652638"
  }, {
    "category": "Berol",
    "weight": "-2.15302533411946"
  }, {
    "category": "Advantus",
    "weight": "-1.4365893704347461"
  }, {
    "category": "Linden",
    "weight": "-0.16141661662447415"
  }, {
    "category": "Memorex",
    "weight": "-2.0673779128087473"
  }, {
    "category": "Staple envelope",
    "weight": "-1.6397756082034181"
  }, {
    "category": "Things To Do",
    "weight": "-0.24904200958076705"
  }, {
    "category": "KeyTronic",
    "weight": "-2.6935432747441226"
  }, {
    "category": "Grandstream",
    "weight": "-1.6478807150942827"
  }, {
    "category": "Atlantic",
    "weight": "-2.3223465504067367"
  }, {
    "category": "First Data",
    "weight": "-3.7861041067233172"
  }, {
    "category": "Nu-Dell",
    "weight": "0.266806038903447"
  }, {
    "category": "RCA",
    "weight": "-2.2763532070425647"
  }, {
    "category": "Boston",
    "weight": "-0.75014772784951633"
  }, {
    "category": "Tripp Lite",
    "weight": "-0.52602841765339781"
  }, {
    "category": "Holmes",
    "weight": "0.037910476849241093"
  }, {
    "category": "Executive Impressions",
    "weight": "0.23002438937922687"
  }, {
    "category": "Southworth",
    "weight": "0.18861422657625271"
  }, {
    "category": "Other",
    "weight": "0.026633936169941919"
  }, {
    "category": "Motorola",
    "weight": "-0.91567757076892775"
  }, {
    "category": "Imation",
    "weight": "-0.72338689565714454"
  }, {
    "category": "Seth Thomas",
    "weight": "0.3705250014730419"
  }, {
    "category": "Eureka",
    "weight": "0.39366562860403231"
  }, {
    "category": "Global",
    "weight": "-0.59464037993390217"
  }, {
    "category": "WD My Passport",
    "weight": "-1.3213193449835288"
  }, {
    "category": "Easy-staple paper",
    "weight": "0.5392108007882559"
  }, {
    "category": "Strathmore",
    "weight": "0.30091025392165882"
  }, {
    "category": "TOPS",
    "weight": "1.01917833305064"
  }, {
    "category": "Hon",
    "weight": "-0.874012607281931"
  }, {
    "category": "Xerox",
    "weight": "1.631346840868507"
  }, {
    "category": "Dana",
    "weight": "3.462964652162932"
  }, {
    "category": "Jabra",
    "weight": "0.72700834317937346"
  }, {
    "category": "Kensington",
    "weight": "1.9077166610569263"
  }, {
    "category": "Maxell",
    "weight": "2.4460478591266135"
  }, {
    "category": "3M",
    "weight": "3.5645774230122327"
  }, {
    "category": "Bionaire",
    "weight": "3.6318825151854126"
  }, {
    "category": "AT\u0026T",
    "weight": "2.0454329353920269"
  }, {
    "category": "Electrix",
    "weight": "4.1545193808253211"
  }, {
    "category": "GBC",
    "weight": "4.9587405727684928"
  }, {
    "category": "Hoover",
    "weight": "3.5644132937690358"
  }, {
    "category": "Hunt",
    "weight": "4.3018370388878013"
  }, {
    "category": "Nokia",
    "weight": "3.8668531880115982"
  }, {
    "category": "Ibico",
    "weight": "4.9797345147177863"
  }, {
    "category": "Microsoft",
    "weight": "3.8219364476942674"
  }, {
    "category": "Panasonic",
    "weight": "4.4484403761609981"
  }, {
    "category": "Luxo",
    "weight": "4.5609967615708049"
  }, {
    "category": "Howard Miller",
    "weight": "6.7941700374079179"
  }, {
    "category": "GE",
    "weight": "6.5363039704588495"
  }, {
    "category": "Harmony",
    "weight": "6.4828431324050531"
  }, {
    "category": "Iceberg",
    "weight": "6.4430321970786455"
  }, {
    "category": "Jawbone",
    "weight": "5.9203709316785371"
  }, {
    "category": "HTC",
    "weight": "7.4676369395276918"
  }, {
    "category": "Mitel",
    "weight": "5.8965585045688869"
  }, {
    "category": "Avanti",
    "weight": "7.9756653731432614"
  }, {
    "category": "Pyle",
    "weight": "8.12491929664943"
  }, {
    "category": "Nortel",
    "weight": "8.1490252619516834"
  }, {
    "category": "Brother",
    "weight": "2.5031615850563895"
  }, {
    "category": "Cisco",
    "weight": "9.2148374635810253"
  }, {
    "category": "LG",
    "weight": "9.4782732163156425"
  }, {
    "category": "Enermax",
    "weight": "9.0197073647846544"
  }, {
    "category": "Logitech",
    "weight": "9.9994372130498448"
  }, {
    "category": "Fellowes",
    "weight": "11.918076746617349"
  }, {
    "category": "Avaya",
    "weight": "11.688885823343218"
  }, {
    "category": "Tyvek",
    "weight": "12.927394630026884"
  }, {
    "category": "Samsung",
    "weight": "10.670465088825003"
  }, {
    "category": "Polycom",
    "weight": "11.671052774782682"
  }, {
    "category": "Rush",
    "weight": "14.1398716044931"
  }, {
    "category": "NETGEAR",
    "weight": "15.854658920655254"
  }, {
    "category": "Smead",
    "weight": "19.829250515296536"
  }, {
    "category": "Standard",
    "weight": "20.28577965794458"
  }, {
    "category": "Plantronics",
    "weight": "29.265398512779022"
  }, {
    "category": "Apple",
    "weight": "29.409337458553068"
  }, {
    "category": "Razer",
    "weight": "31.512754668239207"
  }, {
    "category": "Socket",
    "weight": "37.165011003980034"
  }, {
    "category": "ClearOne",
    "weight": "38.97951435794716"
  }, {
    "category": "Honeywell",
    "weight": "53.737620702288353"
  }, {
    "category": "Zebra",
    "weight": "65.800773171985711"
  }, {
    "category": "Sharp",
    "weight": "60.291080326126284"
  }, {
    "category": "Sanyo",
    "weight": "96.154872295196171"
  }, {
    "category": "Hewlett-Packard",
    "weight": "139.83244933118803"
  }, {
    "category": "Ativa",
    "weight": "157.15401685038256"
  }, {
    "category": "3D Systems",
    "weight": "181.06659044433192"
  }, {
    "category": "Canon",
    "weight": "329.11904038433067"
  }]
}, {
  "processed_input": "order_month",
  "weight": "-0.081694902945572523",
  "category_weights": []
}, {
  "processed_input": "order_year",
  "weight": "0.27843171948469247",
  "category_weights": []
}, {
  "processed_input": "order_quarter",
  "weight": "-0.33565491363124622",
  "category_weights": []
}, {
  "processed_input": "order_day_of_week",
  "weight": None,
  "category_weights": [{
    "category": "Thursday",
    "weight": "-0.62108680971722485"
  }, {
    "category": "Sunday",
    "weight": "0.48694076154794175"
  }, {
    "category": "Wednesday",
    "weight": "0.768090094862643"
  }, {
    "category": "Friday",
    "weight": "1.4340107812272107"
  }, {
    "category": "Monday",
    "weight": "1.7463328286634576"
  }, {
    "category": "Saturday",
    "weight": "2.5281532953725625"
  }, {
    "category": "Tuesday",
    "weight": "4.10915551601934"
  }]
}, {
  "processed_input": "customer_frequency",
  "weight": "-0.042256931998512111",
  "category_weights": []
}, {
  "processed_input": "customer_monetary_value",
  "weight": "0.0019472358191663828",
  "category_weights": []
}, {
  "processed_input": "customer_unique_orders",
  "weight": "0.042445397668489357",
  "category_weights": []
}, {
  "processed_input": "customer_recency",
  "weight": "0.0030031100554244097",
  "category_weights": []
}, {
  "processed_input": "customer_avg_order_value",
  "weight": "0.012082732687132112",
  "category_weights": []
}, {
  "processed_input": "customer_rfm_segment",
  "weight": None,
  "category_weights": [{
    "category": "Cannot Lose Them",
    "weight": "-3.7919993995741916"
  }, {
    "category": "At Risk",
    "weight": "-0.2748378633246733"
  }, {
    "category": "Potential Loyalists",
    "weight": "1.5119285681386687"
  }, {
    "category": "Loyal Customers",
    "weight": "1.2350924902977871"
  }, {
    "category": "Champions",
    "weight": "2.1359920649926751"
  }]
}, {
  "processed_input": "__INTERCEPT__",
  "weight": "-586.9013324376125",
  "category_weights": []
}]
```

### From Sales:
```python
r_squared = 0.20173200821653814

importance = calculate_feature_importance(model_data, r_squared)
fig1, ax1 = create_feature_importance_pie_chart(importance)
plt.show()
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plot
sns.set_style('whitegrid')

# Create the bar chart
plt.figure(figsize=(14, 7))
sns.barplot(x='subcategory', y='profit_margin', hue='category', data=profit_margin_by_category_subcategory_sorted, palette='viridis')

# Add titles and labels
plt.title('Average Profit Margin by Category and Sub-Category', fontsize=16)
plt.xlabel('Sub-Category', fontsize=12)
plt.ylabel('Average Profit Margin', fontsize=12)
plt.xticks(rotation=90)
plt.legend(title='Category')
plt.tight_layout()

# Display the plot
plt.show()
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Group by Category and calculate the sum of sales
sales_by_category = df.groupby('category')['sales'].sum().reset_index()

# Sort the categories by sales
sales_by_category_sorted = sales_by_category.sort_values(by='sales', ascending=False)

# Set the style for the plot
sns.set_style('whitegrid')

# Create the bar chart
plt.figure(figsize=(10, 6))
sns.barplot(x='category', y='sales', data=sales_by_category_sorted, palette='viridis')

# Add titles and labels
plt.title('Total Sales by Category', fontsize=16)
plt.xlabel('Category', fontsize=12)
plt.ylabel('Total Sales', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()

# Display the plot
plt.show()
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plot
sns.set_style('whitegrid')

# Create the line chart
plt.figure(figsize=(12, 6))
sns.lineplot(x=monthly_profit.index, y=monthly_profit.values)

# Add titles and labels
plt.title('Monthly Profit Trends Over Time', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Total Profit', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()

# Display the plot
plt.show()
```

### From Regional:
```python
# Create a figure and a set of subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Create the bar chart for sales by region
sns.barplot(x='region', y='sales', data=regional_performance, ax=axes[0], palette='viridis')
axes[0].set_title('Total Sales by Region', fontsize=14)
axes[0].set_xlabel('Region', fontsize=12)
axes[0].set_ylabel('Total Sales', fontsize=12)

# Create the bar chart for profit by region
sns.barplot(x='region', y='profit', data=regional_performance, ax=axes[1], palette='viridis')
axes[1].set_title('Total Profit by Region', fontsize=14)
axes[1].set_xlabel('Region', fontsize=12)
axes[1].set_ylabel('Total Profit', fontsize=12)

# Set the overall title for the figure
fig.suptitle('Regional Performance Analysis', fontsize=16)

# Adjust layout
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Display the plot
plt.show()
```

### From Regional:
```python
# Analyze the impact of discount on profit margin
plt.figure(figsize=(10, 6))
sns.boxplot(x='discount', y='profit_margin', data=df)
plt.title('Profit Margin vs. Discount Level', fontsize=16)
plt.xlabel('Discount Level', fontsize=12)
plt.ylabel('Profit Margin', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
# Analyze profit margin by category
plt.figure(figsize=(10, 6))
sns.boxplot(x='category', y='profit_margin', data=df)
plt.title('Profit Margin by Category', fontsize=16)
plt.xlabel('Category', fontsize=12)
plt.ylabel('Profit Margin', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
# Refined Analysis Interpretations incorporating data evidence

print("## Refined Analysis Interpretations")

print("\n### Sales Distribution by Category")
print("Based on the total sales visualization, Technology is the highest performing category, followed by Furniture and then Office Supplies.")
print("This pattern likely exists due to:")
print("- **Product type characteristics:** Technology products generally have higher price points compared to office supplies, driving up total sales revenue for the category. Furniture also tends to have higher individual item prices than most office supplies.")
print("- **Demand:** There is likely strong consumer and business demand for technology products. While office supplies are essential, individual purchase values are typically lower.")
print("This pattern varies across dimensions as seen in the regional analysis, where the West and East regions, potentially with stronger economies or higher populations, contribute more significantly to the sales of these categories.")

print("\n### Profit Trends over Time")
print("The monthly profit trend shows an overall upward movement but with significant seasonality, particularly spikes towards the end of the year (Q4) and dips at the beginning (Q1), along with volatility and periods of negative profit.")
print("This pattern is likely influenced by:")
print("- **Seasonality and holidays:** The strong spike in Q4 aligns with holiday shopping seasons, significantly increasing sales and profits. The subsequent dip in Q1 could be due to reduced consumer spending post-holidays and potentially business budget cycles.")
print("- **Discounting and promotional activities:** The box plot of profit margin vs. discount shows that higher discounts are associated with lower and more variable profit margins, and can even lead to negative margins. It is possible that aggressive discounting occurs during certain periods, contributing to volatility or negative profit months.")
print("- **Product mix:** The varying profitability of different categories and sub-categories (as seen in the profit margin by category/sub-category analysis) can impact overall monthly profit depending on which products are sold more in a given period.")
print("The volatility could also be influenced by large individual orders or the timing of significant expenses.")

print("\n### Regional Performance Comparison")
print("The regional analysis shows the West and East regions leading significantly in both total sales and total profit, while the South and Central regions have lower sales and profit, with Central having the lowest profit.")
print("This consistent pattern across regions is likely due to a combination of factors:")
print("- **Regional economic conditions and consumer spending habits:** Regions with stronger economies and higher disposable income (potentially West and East) are likely to have higher sales and thus higher total profit, assuming similar cost structures and pricing.")
print("- **Customer demographics:** Differences in population density, customer needs, and purchasing power across regions can lead to variations in sales volume.")
print("- **Marketing and sales efforts:** More effective or targeted marketing and sales strategies in the West and East could contribute to their higher performance.")
print("- **Supply chain and operational efficiency:** While not directly visualized, potential differences in shipping costs or distribution efficiency could impact profitability across regions, potentially contributing to the Central region's lower profit despite not having the absolute lowest sales.")
print("The consistent sales and profit ranking across regions suggests that the underlying drivers of sales and profitability are similar across these areas, with regional variations in their intensity.")
```

### From Regional:
```python
# Analyze how the relationship between profit margin and discount levels varies across different categories
plt.figure(figsize=(14, 7))
sns.boxplot(x='discount', y='profit_margin', hue='category', data=df, palette='viridis')
plt.title('Profit Margin vs. Discount Level by Category', fontsize=16)
plt.xlabel('Discount Level', fontsize=12)
plt.ylabel('Profit Margin', fontsize=12)
plt.tight_layout()
plt.show()

# Analyze seasonal profit trends across different regions
# Resample the data by quarter and calculate the sum of profit for each region
quarterly_profit_by_region = df.groupby('region')['profit'].resample('Q').sum().reset_index()

plt.figure(figsize=(14, 7))
sns.lineplot(x='order_date', y='profit', hue='region', data=quarterly_profit_by_region, marker='o')
plt.title('Quarterly Profit Trends by Region', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Total Profit', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Analyze sales and profit performance of different categories across different regions
regional_category_performance = df.groupby(['region', 'category'])[['sales', 'profit']].sum().reset_index()

fig, axes = plt.subplots(1, 2, figsize=(16, 7))

sns.barplot(x='region', y='sales', hue='category', data=regional_category_performance, ax=axes[0], palette='viridis')
axes[0].set_title('Total Sales by Region and Category', fontsize=14)
axes[0].set_xlabel('Region', fontsize=12)
axes[0].set_ylabel('Total Sales', fontsize=12)
axes[0].legend(title='Category')

sns.barplot(x='region', y='profit', hue='category', data=regional_category_performance, ax=axes[1], palette='viridis')
axes[1].set_title('Total Profit by Region and Category', fontsize=14)
axes[1].set_xlabel('Region', fontsize=12)
axes[1].set_ylabel('Total Profit', fontsize=12)
axes[1].legend(title='Category')

fig.suptitle('Regional and Category Performance Analysis', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()
```

### From Regional:
```python
print("## Variation Across Dimensions Analysis Summary:")

print("\n### Profit Margin vs. Discount Level by Category:")
print("- The box plot shows that for all categories, increasing discount levels generally lead to lower and more variable profit margins, with higher discounts often resulting in negative profit margins.")
print("- The impact of discounts on profit margin appears to vary by category. Furniture and Office Supplies seem to be more negatively affected by high discounts compared to Technology, which shows some resilience at certain discount levels, though still experiences significant drops.")

print("\n### Quarterly Profit Trends by Region:")
print("- The line plot reveals that seasonal profit trends vary across regions. All regions show some degree of seasonality with peaks towards the end of the year, but the magnitude and consistency of these peaks differ.")
print("- The West and East regions generally exhibit higher quarterly profits and more pronounced seasonal spikes compared to the South and Central regions.")
print("- The Central region shows more volatility and periods of lower or negative quarterly profit compared to the other regions.")

print("\n### Total Sales and Profit by Region and Category:")
print("- The bar plots illustrate how sales and profit performance of categories vary across regions. Technology and Office Supplies contribute significantly to sales and profit in all regions, but their relative contribution can differ.")
print("- Furniture sales and profit are notably lower in the Central and South regions compared to the West and East.")
print("- The overall regional performance ranking (West > East > South/Central) holds true when looking at the combined performance across categories within each region.")
print("- Within each region, the category ranking in terms of sales and profit generally follows the overall pattern (Technology > Furniture > Office Supplies for sales, and Technology > Office Supplies > Furniture for profit), but there are variations. For example, Office Supplies profit is relatively strong in the East and West compared to Furniture.")

print("\n### Overall Synthesis:")
print("- The analysis confirms that while overarching patterns exist (e.g., Q4 profit spikes, West/East leading regions), the specifics of these patterns vary significantly when examined across dimensions like category and region.")
print("- The impact of discounts is a universal challenge for profitability across categories, but some categories may be more sensitive than others.")
print("- Regional economic conditions and market characteristics likely play a significant role in shaping both overall regional performance and the success of specific product categories within those regions.")
print("- The seasonality observed in overall profit trends is present across regions but with varying intensity, suggesting regional differences in consumer behavior or promotional activities during peak seasons.")
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.scatterplot(x='shipping_time', y='profit_margin', data=df, alpha=0.5)
plt.title('Profit Margin vs. Shipping Time', fontsize=16)
plt.xlabel('Shipping Time (Days)', fontsize=12)
plt.ylabel('Profit Margin', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
plt.figure(figsize=(10, 6))
sns.scatterplot(x='shipping_time', y='discount', data=df, alpha=0.5)
plt.title('Discount vs. Shipping Time', fontsize=16)
plt.xlabel('Shipping Time (Days)', fontsize=12)
plt.ylabel('Discount', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
plt.figure(figsize=(10, 6))
sns.scatterplot(x='shipping_time', y='profit_margin', data=df, alpha=0.5)
plt.title('Profit Margin vs. Shipping Time', fontsize=16)
plt.xlabel('Shipping Time (Days)', fontsize=12)
plt.ylabel('Profit Margin', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
plt.figure(figsize=(10, 6))
sns.scatterplot(x='shipping_time', y='discount', data=df, alpha=0.5)
plt.title('Discount vs. Shipping Time', fontsize=16)
plt.xlabel('Shipping Time (Days)', fontsize=12)
plt.ylabel('Discount', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
print("## Analysis of Shipping Efficiency and Potential Impact")

print("\n### Shipping Time and Profit Margin:")
print("The scatter plot of Profit Margin vs. Shipping Time does not show a clear linear correlation. While there are instances of negative profit margins across various shipping times, there isn't a distinct pattern indicating that longer shipping times directly lead to lower profit margins. Other factors likely play a more significant role in determining profit margin, such as product cost, sales price, and discount levels.")

print("\n### Shipping Time and Discount:")
print("The scatter plot of Discount vs. Shipping Time also does not reveal a strong correlation. Discounts appear to be applied across a range of shipping times, and there's no clear indication that higher discounts are systematically given for longer shipping times. This suggests that discounts are likely driven by factors other than shipping duration, such as promotional strategies, product category, or regional considerations.")

print("\n### Overall Assessment:")
print("Based on the analysis of shipping time against profit margin and discount, shipping duration does not appear to be a primary driver of profitability or a consistent factor in determining discount levels in this dataset. While efficient shipping is generally crucial for customer satisfaction and can indirectly impact a business, these direct correlations were not strongly evident in the visualizations. Further analysis considering other variables or a more sophisticated statistical approach might be needed to uncover more nuanced relationships.")
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Create a figure and a set of subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Create the bar chart for sales by region
sns.barplot(x='region', y='sales', hue='region', data=regional_performance, ax=axes[0], palette='viridis', legend=False)
axes[0].set_title('Total Sales by Region', fontsize=14)
axes[0].set_xlabel('Region', fontsize=12)
axes[0].set_ylabel('Total Sales', fontsize=12)

# Create the bar chart for profit by region
sns.barplot(x='region', y='profit', hue='region', data=regional_performance, ax=axes[1], palette='viridis', legend=False)
axes[1].set_title('Total Profit by Region', fontsize=14)
axes[1].set_xlabel('Region', fontsize=12)
axes[1].set_ylabel('Total Profit', fontsize=12)

# Set the overall title for the figure
fig.suptitle('Regional Performance Analysis', fontsize=16)

# Adjust layout
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Display the plot
plt.show()
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.scatterplot(x='shipping_time', y='profit_margin', data=df, alpha=0.5)
plt.title('Profit Margin vs. Shipping Time', fontsize=16)
plt.xlabel('Shipping Time (Days)', fontsize=12)
plt.ylabel('Profit Margin', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.scatterplot(x='shipping_time', y='discount', data=df, alpha=0.5)
plt.title('Discount vs. Shipping Time', fontsize=16)
plt.xlabel('Shipping Time (Days)', fontsize=12)
plt.ylabel('Discount', fontsize=12)
plt.tight_layout()
plt.show()
```

### From Regional:
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plot
sns.set_style('whitegrid')

# Create the box plot of shipping time by region
plt.figure(figsize=(10, 6))
sns.boxplot(x='region', y='shipping_time', hue='region', data=df, palette='viridis', legend=False)

# Add titles and labels
plt.title('Distribution of Shipping Time by Region', fontsize=16)
plt.xlabel('Region', fontsize=12)
plt.ylabel('Shipping Time (Days)', fontsize=12)
plt.tight_layout()

# Display the plot
plt.show()
```